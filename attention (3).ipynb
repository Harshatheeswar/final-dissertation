{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4397d4f057c34c8ab78d0d36193421e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_34357ebfac594b8f82dc26dfdcf7bee6"
          }
        },
        "d94b273db0344da1bc16a02072a37402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a33b536c0caa45daa8a3ad4a9a0ad2d1",
            "placeholder": "​",
            "style": "IPY_MODEL_ce656879d8c845eaa1dcbd3007fc9e65",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "ce2c5011a5db40b58ed5a8ce579dd84f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_439242bd5af84708b3d41df311649c59",
            "placeholder": "​",
            "style": "IPY_MODEL_c368b81d9c9147a7adcfe69d3c795ef3",
            "value": ""
          }
        },
        "3a193b8ca5c047348e2ecf4bf18a55ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_2e233c6beeba49558826f742ce613b47",
            "style": "IPY_MODEL_f466267bf6f043ee918c0489d15f9f0e",
            "value": true
          }
        },
        "b1b8cc32478c47a99275d2480481df1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_b325526b592646d599bc6c6ac7b88c6a",
            "style": "IPY_MODEL_3832f8cf91684e53a6a070fa7774aa7f",
            "tooltip": ""
          }
        },
        "0b8be592acfd4fa0824b7bc33ce59daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a58ac5926d1460889e337fd38ef65d4",
            "placeholder": "​",
            "style": "IPY_MODEL_a8a551fd0e6a4e738c393f0ab1cf48b5",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "34357ebfac594b8f82dc26dfdcf7bee6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "a33b536c0caa45daa8a3ad4a9a0ad2d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce656879d8c845eaa1dcbd3007fc9e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "439242bd5af84708b3d41df311649c59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c368b81d9c9147a7adcfe69d3c795ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e233c6beeba49558826f742ce613b47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f466267bf6f043ee918c0489d15f9f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b325526b592646d599bc6c6ac7b88c6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3832f8cf91684e53a6a070fa7774aa7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "6a58ac5926d1460889e337fd38ef65d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8a551fd0e6a4e738c393f0ab1cf48b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1ff00d57e7743198ff2d24d96d64842": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f80c703ecc014eff8271463faf838f37",
            "placeholder": "​",
            "style": "IPY_MODEL_7d7c3a4499644725b2f8a9849c8fa845",
            "value": "Connecting..."
          }
        },
        "f80c703ecc014eff8271463faf838f37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d7c3a4499644725b2f8a9849c8fa845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74c750e7b5b94278973396827ef48f1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9972bdd9db86491d9822dc2604103d4a",
              "IPY_MODEL_14beae659572453b86f181d676a236d1",
              "IPY_MODEL_ba1f998043974444989bd3e6d057807c"
            ],
            "layout": "IPY_MODEL_18498cc0d0ba4fe7b95953d8c6a0aab0"
          }
        },
        "9972bdd9db86491d9822dc2604103d4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9d334ef470d48be9340a5ac3e4b4240",
            "placeholder": "​",
            "style": "IPY_MODEL_546e369756594b799cd4330fed32ae75",
            "value": "events.out.tfevents.1732655951.b9dc60cf926e.1732.0: 100%"
          }
        },
        "14beae659572453b86f181d676a236d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ceec6f1635d44c586160983e222b93d",
            "max": 597788,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7beef36858aa49ada6a8da6a6200613f",
            "value": 597788
          }
        },
        "ba1f998043974444989bd3e6d057807c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63463b6d385f43f9be9bdfe97446e5ba",
            "placeholder": "​",
            "style": "IPY_MODEL_e6c8ed79f59f456c9fb6e4899388b987",
            "value": " 598k/598k [00:00&lt;00:00, 1.10MB/s]"
          }
        },
        "18498cc0d0ba4fe7b95953d8c6a0aab0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9d334ef470d48be9340a5ac3e4b4240": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "546e369756594b799cd4330fed32ae75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ceec6f1635d44c586160983e222b93d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7beef36858aa49ada6a8da6a6200613f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63463b6d385f43f9be9bdfe97446e5ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6c8ed79f59f456c9fb6e4899388b987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## chainging attention mechanism"
      ],
      "metadata": {
        "id": "pBnqG0EMUqNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzYBBtPWYwMQ",
        "outputId": "ffa20fc3-a521-426d-ec10-05cc62957818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/huggingface/transformers.git\n",
        "%cd transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKNpdEIbYyO4",
        "outputId": "854d1a1b-6280-4cf7-e0a0-287df912b572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 242277, done.\u001b[K\n",
            "remote: Counting objects: 100% (22120/22120), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1397/1397), done.\u001b[K\n",
            "remote: Total 242277 (delta 21663), reused 20797 (delta 20687), pack-reused 220157 (from 1)\u001b[K\n",
            "Receiving objects: 100% (242277/242277), 246.81 MiB | 26.68 MiB/s, done.\n",
            "Resolving deltas: 100% (178173/178173), done.\n",
            "/content/transformers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!src/transformers/models/llama/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSzw3LSBZDYI",
        "outputId": "ebea18fb-21e3-4c6e-ca05-876a8a26149e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: src/transformers/models/llama/: Is a directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/transformers')"
      ],
      "metadata": {
        "id": "UJr0j8ljBKwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.llama.modeling_llama import LlamaModel, LlamaConfig,LlamaRotaryEmbedding,apply_rotary_pos_emb,LlamaRMSNorm,LlamaMLP,Cache\n",
        "from transformers.models.llama.modeling_llama import LlamaRotaryEmbedding"
      ],
      "metadata": {
        "id": "99AY-e29BYh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from typing import List, Optional, Tuple, Union\n",
        "\n",
        "import torch\n",
        "import torch.utils.checkpoint\n",
        "from torch import nn\n",
        "\n",
        "from transformers.activations import ACT2FN\n",
        "from transformers.cache_utils import Cache, DynamicCache, StaticCache\n",
        "from transformers.generation import GenerationMixin\n",
        "from transformers.modeling_attn_mask_utils import AttentionMaskConverter\n",
        "from transformers.modeling_outputs import (\n",
        "    BaseModelOutputWithPast,\n",
        "    CausalLMOutputWithPast,\n",
        "    QuestionAnsweringModelOutput,\n",
        "    SequenceClassifierOutputWithPast,\n",
        "    TokenClassifierOutput,\n",
        ")\n",
        "from transformers.modeling_rope_utils import ROPE_INIT_FUNCTIONS\n",
        "from transformers.modeling_utils import PreTrainedModel\n",
        "from transformers.processing_utils import Unpack\n",
        "from transformers.pytorch_utils import ALL_LAYERNORM_LAYERS\n",
        "\n"
      ],
      "metadata": {
        "id": "SjIbgWst__JX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5y4TSCvnUpY0"
      },
      "outputs": [],
      "source": [
        "class Llama_C_Attention(nn.Module):\n",
        "    \"\"\"Multi-headed attention with Gaussian bias integration.\"\"\"\n",
        "\n",
        "    def __init__(self, config: LlamaConfig, layer_idx: Optional[int] = None):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.layer_idx = layer_idx\n",
        "        self.attention_dropout = config.attention_dropout\n",
        "        self.hidden_size = config.hidden_size\n",
        "        self.num_heads = config.num_attention_heads\n",
        "        self.head_dim = self.hidden_size // self.num_heads\n",
        "        self.q_proj = nn.Linear(self.hidden_size, self.num_heads * self.head_dim, bias=config.attention_bias)\n",
        "        self.k_proj = nn.Linear(self.hidden_size, self.num_heads * self.head_dim, bias=config.attention_bias)\n",
        "        self.v_proj = nn.Linear(self.hidden_size, self.num_heads * self.head_dim, bias=config.attention_bias)\n",
        "        self.o_proj = nn.Linear(self.num_heads * self.head_dim, self.hidden_size, bias=config.attention_bias)\n",
        "        self.rotary_emb = LlamaRotaryEmbedding(config=self.config)\n",
        "\n",
        "        # Fixed parameters for Gaussian bias\n",
        "        self.decay_rate = 82.86\n",
        "        self.alpha = 0.37\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.LongTensor] = None,\n",
        "        past_key_value: Optional[Cache] = None,\n",
        "        output_attentions: bool = False,\n",
        "        use_cache: bool = False,\n",
        "        cache_position: Optional[torch.LongTensor] = None,\n",
        "        position_embeddings: Optional[Tuple[torch.Tensor, torch.Tensor]] = None,\n",
        "        **kwargs,\n",
        "    ) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]:\n",
        "        bsz, q_len, _ = hidden_states.size()\n",
        "\n",
        "        query_states = self.q_proj(hidden_states)\n",
        "        key_states = self.k_proj(hidden_states)\n",
        "        value_states = self.v_proj(hidden_states)\n",
        "\n",
        "        query_states = query_states.view(bsz, q_len, -1, self.head_dim).transpose(1, 2)\n",
        "        key_states = key_states.view(bsz, q_len, -1, self.head_dim).transpose(1, 2)\n",
        "        value_states = value_states.view(bsz, q_len, -1, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        if position_embeddings is None:\n",
        "            cos, sin = self.rotary_emb(value_states, position_ids)\n",
        "        else:\n",
        "            cos, sin = position_embeddings\n",
        "        query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
        "\n",
        "        # Compute attention weights\n",
        "        attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
        "\n",
        "        # Add Gaussian bias\n",
        "        seq_len = query_states.size(-2)\n",
        "        indices = torch.arange(seq_len, device=query_states.device)\n",
        "        gaussian_bias = torch.exp(-torch.abs(indices[None, :] - indices[:, None]) * self.decay_rate)\n",
        "        attn_weights = (1 - self.alpha) * attn_weights + self.alpha * gaussian_bias\n",
        "\n",
        "        # Add attention mask\n",
        "        if attention_mask is not None:\n",
        "            attn_weights = attn_weights + attention_mask\n",
        "\n",
        "        attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n",
        "        attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
        "        attn_output = torch.matmul(attn_weights, value_states)\n",
        "\n",
        "        attn_output = attn_output.transpose(1, 2).contiguous().view(bsz, q_len, -1)\n",
        "        attn_output = self.o_proj(attn_output)\n",
        "\n",
        "        if not output_attentions:\n",
        "            attn_weights = None\n",
        "\n",
        "        return attn_output, attn_weights, past_key_value\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Llama_C_DecoderLayer(nn.Module):\n",
        "    def __init__(self, config: LlamaConfig, layer_idx: int):\n",
        "        super().__init__()\n",
        "        self.hidden_size = config.hidden_size\n",
        "\n",
        "        # Use the modified LlamaAttention directly\n",
        "        self.self_attn = Llama_C_Attention(config=config, layer_idx=layer_idx)\n",
        "\n",
        "        self.mlp = LlamaMLP(config)\n",
        "        self.input_layernorm = LlamaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n",
        "        self.post_attention_layernorm = LlamaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.LongTensor] = None,\n",
        "        past_key_value: Optional[Cache] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "        use_cache: Optional[bool] = False,\n",
        "        cache_position: Optional[torch.LongTensor] = None,\n",
        "        position_embeddings: Optional[Tuple[torch.Tensor, torch.Tensor]] = None,\n",
        "        **kwargs,\n",
        "    ) -> Tuple[torch.FloatTensor, Optional[Tuple[torch.FloatTensor, torch.FloatTensor]]]:\n",
        "\n",
        "        residual = hidden_states\n",
        "\n",
        "        # Normalize the input\n",
        "        hidden_states = self.input_layernorm(hidden_states)\n",
        "\n",
        "        # Apply self-attention\n",
        "        hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
        "            hidden_states=hidden_states,\n",
        "            attention_mask=attention_mask,\n",
        "            position_ids=position_ids,\n",
        "            past_key_value=past_key_value,\n",
        "            output_attentions=output_attentions,\n",
        "            use_cache=use_cache,\n",
        "            cache_position=cache_position,\n",
        "            position_embeddings=position_embeddings,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        # residual connection\n",
        "        hidden_states = residual + hidden_states\n",
        "\n",
        "        # Fully connected feed-forward network with layer normalization\n",
        "        residual = hidden_states\n",
        "        hidden_states = self.post_attention_layernorm(hidden_states)\n",
        "        hidden_states = self.mlp(hidden_states)\n",
        "        hidden_states = residual + hidden_states\n",
        "\n",
        "        # Prepare outputs\n",
        "        outputs = (hidden_states,)\n",
        "\n",
        "        if output_attentions:\n",
        "            outputs += (self_attn_weights,)\n",
        "\n",
        "        if use_cache:\n",
        "            outputs += (present_key_value,)\n",
        "\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "0yvxzjExVOfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomLlamaModel(LlamaModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        # Reconstruct the layers using the custom decoder layer\n",
        "        self.layers = nn.ModuleList([\n",
        "            Llama_C_DecoderLayer(config, i) for i in range(config.num_hidden_layers)\n",
        "        ])"
      ],
      "metadata": {
        "id": "-tJRkgGPVM6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PreTrainedModel\n",
        "from torch import nn\n",
        "from typing import Optional, Tuple, Union\n",
        "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
        "\n",
        "\n",
        "class LlamaForCausalLM(PreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        # using custom LlamaModel with modified decoder layers and attention\n",
        "        self.model = CustomLlamaModel(config)\n",
        "\n",
        "        # Language modeling head\n",
        "        self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n",
        "\n",
        "        # Initialize weights\n",
        "        self.post_init()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.LongTensor] = None,\n",
        "        labels: Optional[torch.LongTensor] = None,\n",
        "        past_key_values: Optional[Tuple[Tuple[torch.Tensor]]] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "    ) -> Union[Tuple, CausalLMOutputWithPast]:\n",
        "\n",
        "        # Get outputs from the custom LlamaModel\n",
        "        outputs = self.model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            position_ids=position_ids,\n",
        "            past_key_values=past_key_values,\n",
        "            use_cache=use_cache,\n",
        "        )\n",
        "\n",
        "        hidden_states = outputs[0]\n",
        "        logits = self.lm_head(hidden_states)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            # Shift logits and labels for causal language modeling loss\n",
        "            shift_logits = logits[..., :-1, :].contiguous()\n",
        "            shift_labels = labels[..., 1:].contiguous()\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
        "\n",
        "        if not self.config.use_return_dict:\n",
        "            return ((loss,) + (logits,) + outputs[1:]) if loss is not None else (logits,) + outputs[1:]\n",
        "\n",
        "        return CausalLMOutputWithPast(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            past_key_values=outputs.past_key_values,\n",
        "        )\n"
      ],
      "metadata": {
        "id": "nRG9RYUFpJiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F-xO31AbdxK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install huggingface_hub\n",
        "!pip install --upgrade pyarrow datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O3wYWsVXOO3N",
        "outputId": "9a8ae3d8-0abc-4241-c96e-73914b068696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.26.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (17.0.0)\n",
            "Collecting pyarrow\n",
            "  Downloading pyarrow-18.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading pyarrow-18.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyarrow\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 17.0.0\n",
            "    Uninstalling pyarrow-17.0.0:\n",
            "      Successfully uninstalled pyarrow-17.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.10.1 requires pyarrow<18.0.0a0,>=14.0.0, but you have pyarrow 18.1.0 which is incompatible.\n",
            "pylibcudf-cu12 24.10.1 requires pyarrow<18.0.0a0,>=14.0.0, but you have pyarrow 18.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pyarrow-18.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyarrow"
                ]
              },
              "id": "2d9b84faa776430e919d14b6def2924d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall pyarrow\n",
        "!pip install pyarrow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "atGbie7oMSKu",
        "outputId": "e3adcc0a-ea04-472b-8178-601d926b9145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pyarrow 18.1.0\n",
            "Uninstalling pyarrow-18.1.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/pyarrow-18.1.0.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/pyarrow/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled pyarrow-18.1.0\n",
            "Collecting pyarrow\n",
            "  Using cached pyarrow-18.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Using cached pyarrow-18.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.1 MB)\n",
            "Installing collected packages: pyarrow\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.10.1 requires pyarrow<18.0.0a0,>=14.0.0, but you have pyarrow 18.1.0 which is incompatible.\n",
            "pylibcudf-cu12 24.10.1 requires pyarrow<18.0.0a0,>=14.0.0, but you have pyarrow 18.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pyarrow-18.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyarrow"
                ]
              },
              "id": "9442247cf6d448b0b2c847123c2dd527"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h-sE9FkaPGP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "import re\n",
        "from transformers import GPT2Tokenizer\n",
        "from transformers import GPT2Config, GPT2LMHeadModel\n",
        "import torch\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from huggingface_hub import notebook_login\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import subprocess\n"
      ],
      "metadata": {
        "id": "3xZ2SL8UOJzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "4397d4f057c34c8ab78d0d36193421e4",
            "d94b273db0344da1bc16a02072a37402",
            "ce2c5011a5db40b58ed5a8ce579dd84f",
            "3a193b8ca5c047348e2ecf4bf18a55ab",
            "b1b8cc32478c47a99275d2480481df1f",
            "0b8be592acfd4fa0824b7bc33ce59daf",
            "34357ebfac594b8f82dc26dfdcf7bee6",
            "a33b536c0caa45daa8a3ad4a9a0ad2d1",
            "ce656879d8c845eaa1dcbd3007fc9e65",
            "439242bd5af84708b3d41df311649c59",
            "c368b81d9c9147a7adcfe69d3c795ef3",
            "2e233c6beeba49558826f742ce613b47",
            "f466267bf6f043ee918c0489d15f9f0e",
            "b325526b592646d599bc6c6ac7b88c6a",
            "3832f8cf91684e53a6a070fa7774aa7f",
            "6a58ac5926d1460889e337fd38ef65d4",
            "a8a551fd0e6a4e738c393f0ab1cf48b5",
            "b1ff00d57e7743198ff2d24d96d64842",
            "f80c703ecc014eff8271463faf838f37",
            "7d7c3a4499644725b2f8a9849c8fa845"
          ]
        },
        "id": "CZwpZAPIPxOW",
        "outputId": "e1b76761-9ef3-4f34-8a86-bc1680cd5ee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4397d4f057c34c8ab78d0d36193421e4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoConfig\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"babylm/babyllama-100m-2024\")\n",
        "\n",
        "# Load the model configuration without pretrained weights\n",
        "config = AutoConfig.from_pretrained(\"babylm/babyllama-100m-2024\")\n",
        "\n",
        "# Instantiate the custom model\n",
        "model = LlamaForCausalLM(config)\n"
      ],
      "metadata": {
        "id": "WPqo2WAV_ycN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFKy2SwSxcw3",
        "outputId": "55c7e756-f0e3-4e73-cfa3-46e4a752c601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaForCausalLM(\n",
              "  (model): CustomLlamaModel(\n",
              "    (embed_tokens): Embedding(16000, 512, padding_idx=0)\n",
              "    (layers): ModuleList(\n",
              "      (0-15): 16 x Llama_C_DecoderLayer(\n",
              "        (self_attn): Llama_C_Attention(\n",
              "          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (k_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (v_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (o_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear(in_features=512, out_features=1024, bias=False)\n",
              "          (up_proj): Linear(in_features=512, out_features=1024, bias=False)\n",
              "          (down_proj): Linear(in_features=1024, out_features=512, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm((512,), eps=1e-06)\n",
              "        (post_attention_layernorm): LlamaRMSNorm((512,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm((512,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=16000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQWUlHvWW5fB",
        "outputId": "d1ff5abe-a2cc-4258-c4ce-97e79db5eeb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaConfig {\n",
              "  \"_attn_implementation_autoset\": true,\n",
              "  \"_name_or_path\": \"babylm/babyllama-100m-2024\",\n",
              "  \"architectures\": [\n",
              "    \"LlamaForCausalLM\"\n",
              "  ],\n",
              "  \"attention_bias\": false,\n",
              "  \"attention_dropout\": 0.0,\n",
              "  \"bos_token_id\": 1,\n",
              "  \"eos_token_id\": 2,\n",
              "  \"head_dim\": 64,\n",
              "  \"hidden_act\": \"silu\",\n",
              "  \"hidden_size\": 512,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 1024,\n",
              "  \"max_position_embeddings\": 256,\n",
              "  \"mlp_bias\": false,\n",
              "  \"model_type\": \"llama\",\n",
              "  \"num_attention_heads\": 8,\n",
              "  \"num_hidden_layers\": 16,\n",
              "  \"num_key_value_heads\": 8,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"pretraining_tp\": 1,\n",
              "  \"rms_norm_eps\": 1e-06,\n",
              "  \"rope_scaling\": null,\n",
              "  \"rope_theta\": 10000.0,\n",
              "  \"tie_word_embeddings\": false,\n",
              "  \"torch_dtype\": \"float32\",\n",
              "  \"transformers_version\": \"4.46.2\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 16000\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(data):\n",
        "    # Step 1: Remove text within parentheses\n",
        "    data = re.sub(r'\\([^)]*\\)', '', data)\n",
        "\n",
        "    # Step 2: Remove all-uppercase words (likely sound effects)\n",
        "    data = re.sub(r'\\b[A-Z]+\\b', '', data)\n",
        "\n",
        "    # Step 3: Convert to lowercase\n",
        "    data = data.lower()\n",
        "\n",
        "    # Step 4: Normalize spaces\n",
        "    data = re.sub(r'\\s+', ' ', data).strip()\n",
        "\n",
        "    return data\n",
        "\n",
        "# Load the data\n",
        "file_path = '/content/drive/MyDrive/data/text_data.zip (Unzipped Files)/train_100M/open_subtitles.train'\n",
        "\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    raw_data = file.read()\n",
        "\n",
        "# Apply preprocessing\n",
        "cleaned_data = preprocess_text(raw_data)\n",
        "\n",
        "# Display a sample of the cleaned data\n",
        "print(cleaned_data[:500])\n"
      ],
      "metadata": {
        "id": "dy0FjGmuCejP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the model size\n",
        "model_size = sum(t.numel() for t in model.parameters())\n",
        "print(f\"babyllama size: {model_size/1000**2:.1f}M parameters\")\n",
        "# Check the maximum sequence length\n",
        "print(f\"Maximum input size for the model: {config.max_position_embeddings}\")\n"
      ],
      "metadata": {
        "id": "bjWThvr3ObhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHbf1a4Xxwmc",
        "outputId": "16253817-d748-43b8-a5d9-355dad80cfcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58.343936"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 256\n",
        "input_texts = [cleaned_data[i:i+max_length] for i in range(0, len(cleaned_data), max_length)]\n",
        "\n",
        "# Apply the tokenizer to each chunk\n",
        "tokenized_data = tokenizer(input_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# Display a sample of tokenized data\n",
        "print(tokenized_data[\"input_ids\"][:5])"
      ],
      "metadata": {
        "id": "3f4p2wktPmSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "\n",
        "dataset = Dataset.from_dict(tokenized_data)\n",
        "\n",
        "# Split the dataset into train and test sets (e.g., 90% train, 10% test)\n",
        "train_test_split = dataset.train_test_split(test_size=0.1)\n",
        "train_dataset = train_test_split['train']\n",
        "test_dataset = train_test_split['test']"
      ],
      "metadata": {
        "id": "9sbHe8sSPrZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ],
      "metadata": {
        "id": "N-TTxgIqPwM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "Xu0nI0VueAh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='Harshatheeswar',\n",
        "    hub_model_id='babylama-attentionchange_correct',\n",
        "    evaluation_strategy='epoch',\n",
        "    auto_find_batch_size=True,\n",
        "    num_train_epochs=5,\n",
        "    gradient_accumulation_steps=8,\n",
        "    weight_decay=0.1,\n",
        "    lr_scheduler_type='cosine',\n",
        "    learning_rate=5e-5,\n",
        "    fp16=True,\n",
        "    push_to_hub=True,\n",
        "    logging_steps=10\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Push the trained model to the Hugging Face Hub\n",
        "trainer.push_to_hub()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697,
          "referenced_widgets": [
            "74c750e7b5b94278973396827ef48f1e",
            "9972bdd9db86491d9822dc2604103d4a",
            "14beae659572453b86f181d676a236d1",
            "ba1f998043974444989bd3e6d057807c",
            "18498cc0d0ba4fe7b95953d8c6a0aab0",
            "a9d334ef470d48be9340a5ac3e4b4240",
            "546e369756594b799cd4330fed32ae75",
            "3ceec6f1635d44c586160983e222b93d",
            "7beef36858aa49ada6a8da6a6200613f",
            "63463b6d385f43f9be9bdfe97446e5ba",
            "e6c8ed79f59f456c9fb6e4899388b987"
          ]
        },
        "id": "0kUnrSeJP08K",
        "outputId": "1d78807b-c263-43b0-fb4f-341ed93ce1ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-23-cf20fad7871e>:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241126_211938-z99e7pw6</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/harshatheeswarsai99-city-university-of-london/huggingface/runs/z99e7pw6' target=\"_blank\">Harshatheeswar</a></strong> to <a href='https://wandb.ai/harshatheeswarsai99-city-university-of-london/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/harshatheeswarsai99-city-university-of-london/huggingface' target=\"_blank\">https://wandb.ai/harshatheeswarsai99-city-university-of-london/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/harshatheeswarsai99-city-university-of-london/huggingface/runs/z99e7pw6' target=\"_blank\">https://wandb.ai/harshatheeswarsai99-city-university-of-london/huggingface/runs/z99e7pw6</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1819' max='27795' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 1819/27795 19:06 < 4:33:11, 1.58 it/s, Epoch 0.33/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27795' max='27795' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27795/27795 5:06:23, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.300400</td>\n",
              "      <td>4.336871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.045500</td>\n",
              "      <td>4.089211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.912700</td>\n",
              "      <td>3.981016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.806200</td>\n",
              "      <td>3.939464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.781300</td>\n",
              "      <td>3.935231</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "events.out.tfevents.1732655951.b9dc60cf926e.1732.0:   0%|          | 0.00/598k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74c750e7b5b94278973396827ef48f1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Harshatheeswar/babylama-attentionchange_correct/commit/8f79efe5cfaa558c1414d1a9e5a79f2b8d47ed2b', commit_message='End of training', commit_description='', oid='8f79efe5cfaa558c1414d1a9e5a79f2b8d47ed2b', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Harshatheeswar/babylama-attentionchange_correct', endpoint='https://huggingface.co', repo_type='model', repo_id='Harshatheeswar/babylama-attentionchange_correct'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## evaluation"
      ],
      "metadata": {
        "id": "EAfbjVCI2Xpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/new_evaluation_pipeline\n"
      ],
      "metadata": {
        "id": "KGBr9vIZP9WB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e\n",
        "!pip install minicons\n",
        "!pip install --upgrade accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "g1A1goLDQBXY",
        "outputId": "81c6897d-b3b5-4f33-f8d8-f1c363e27fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "urllib3"
                ]
              },
              "id": "126cec3626544f8abf4434c0958ec372"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meoHaAfSQFJQ",
        "outputId": "abafaa9a-2938-4350-ee54-4def8289f6f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install sacrebleu\n",
        "!apt-get install -y libnvinfer8 libnvinfer-plugin8\n",
        "!apt-get install -y libnvparsers8 libnvonnxparsers8\n",
        "!pip install sqlitedict\n",
        "!pip install peft\n",
        "!pip install pytablewriter"
      ],
      "metadata": {
        "id": "B3h9YkkxQIlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bash eval_blimp.sh Harshatheeswar/babylama-attentionchange_correct"
      ],
      "metadata": {
        "id": "0phGCEizQPyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bash eval_ewok.sh Harshatheeswar/babylama-attentionchange_correct"
      ],
      "metadata": {
        "id": "U0K2SLu-QTEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Printing Samples"
      ],
      "metadata": {
        "id": "d1SSBSMxd2E5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "def load_jsonl_or_json_array(file_path, num_samples=2):\n",
        "    \"\"\"Loads a JSONL or JSON array file and returns a few samples.\"\"\"\n",
        "    samples = []\n",
        "    with open(file_path, 'r') as f:\n",
        "        first_char = f.read(1)\n",
        "        f.seek(0)\n",
        "\n",
        "        if first_char == '[':\n",
        "\n",
        "            try:\n",
        "                data = json.load(f)\n",
        "                samples = data[:num_samples]\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Error reading JSON array file {file_path}: {e}\")\n",
        "        else:\n",
        "\n",
        "            for i, line in enumerate(f):\n",
        "                if i >= num_samples:\n",
        "                    break\n",
        "                line = line.strip()\n",
        "                if line:\n",
        "                    try:\n",
        "                        samples.append(json.loads(line))\n",
        "                    except json.JSONDecodeError:\n",
        "                        print(f\"Skipping malformed line in {file_path}: {line}\")\n",
        "    return samples\n",
        "\n",
        "def print_blimp_samples(samples):\n",
        "    \"\"\"Prints a cleaner view of selected fields from blimp sample data.\"\"\"\n",
        "    for sample in samples:\n",
        "        doc = sample.get(\"doc\", {})\n",
        "        sentence_good = doc.get(\"sentence_good\", \"N/A\")\n",
        "        sentence_bad = doc.get(\"sentence_bad\", \"N/A\")\n",
        "        acc = sample.get(\"acc\", \"N/A\")\n",
        "        resps = sample.get(\"resps\", [])\n",
        "        filtered_resps = sample.get(\"filtered_resps\", [])\n",
        "\n",
        "        print(\"Sentence (Good):\", sentence_good)\n",
        "        print(\"Sentence (Bad):\", sentence_bad)\n",
        "        print(\"Accuracy:\", acc)\n",
        "\n",
        "        if resps:\n",
        "            print(\"Predictions (resps):\")\n",
        "            for i, resp in enumerate(resps):\n",
        "                score, correct = resp[0][0], resp[0][1]\n",
        "                print(f\"  Response {i + 1}: Score = {score}, Correct = {correct}\")\n",
        "\n",
        "        if filtered_resps:\n",
        "            print(\"Filtered Predictions (filtered_resps):\")\n",
        "            for i, filtered_resp in enumerate(filtered_resps):\n",
        "                score, correct = filtered_resp\n",
        "                print(f\"  Filtered Response {i + 1}: Score = {score}, Correct = {correct}\")\n",
        "\n",
        "        print(\"=\" * 40)\n",
        "\n",
        "def print_ewok_samples(samples):\n",
        "    \"\"\"Prints a cleaner view of selected fields from ewok sample data.\"\"\"\n",
        "    for sample in samples:\n",
        "        doc = sample.get(\"doc\", {})\n",
        "        domain = doc.get(\"Domain\", \"N/A\")\n",
        "        concept_a = doc.get(\"ConceptA\", \"N/A\")\n",
        "        concept_b = doc.get(\"ConceptB\", \"N/A\")\n",
        "        context1 = doc.get(\"Context1\", \"N/A\")\n",
        "        context2 = doc.get(\"Context2\", \"N/A\")\n",
        "        target1 = doc.get(\"Target1\", \"N/A\")\n",
        "        target2 = doc.get(\"Target2\", \"N/A\")\n",
        "        acc = sample.get(\"acc\", \"N/A\")\n",
        "        resps = sample.get(\"resps\", [])\n",
        "        filtered_resps = sample.get(\"filtered_resps\", [])\n",
        "\n",
        "        print(\"Domain:\", domain)\n",
        "        print(\"Concept A:\", concept_a)\n",
        "        print(\"Concept B:\", concept_b)\n",
        "        print(\"Context 1:\", context1)\n",
        "        print(\"Context 2:\", context2)\n",
        "        print(\"Target 1:\", target1)\n",
        "        print(\"Target 2:\", target2)\n",
        "        print(\"Accuracy:\", acc)\n",
        "\n",
        "        if resps:\n",
        "            print(\"Predictions (resps):\")\n",
        "            for i, resp in enumerate(resps):\n",
        "                score, correct = resp[0][0], resp[0][1]\n",
        "                print(f\"  Response {i + 1}: Score = {score}\")\n",
        "\n",
        "        if filtered_resps:\n",
        "            print(\"Filtered Predictions (filtered_resps):\")\n",
        "            for i, filtered_resp in enumerate(filtered_resps):\n",
        "                score, correct = filtered_resp\n",
        "                print(f\"  Filtered Response {i + 1}: Score = {score}\")\n",
        "\n",
        "        print(\"=\" * 40)\n"
      ],
      "metadata": {
        "id": "r3bWKr6Y38Me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "blimp_path = '/content/drive/MyDrive/new_evaluation_pipeline/results/blimp/babylama-attentionchange_correct'\n",
        "ewok_path = '/content/drive/MyDrive/new_evaluation_pipeline/results/ewok/babylama-attentionchange_correct'\n",
        "\n"
      ],
      "metadata": {
        "id": "j38khVQz4A7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process and print blimp samples\n",
        "print(\"Processing Blimp Tasks\\n\" + \"=\"*60)\n",
        "for subtask_file in os.listdir(blimp_path):\n",
        "    if subtask_file.endswith('.jsonl'):\n",
        "        file_path = os.path.join(blimp_path, subtask_file)\n",
        "        print(f\"\\nSubtask: {subtask_file}\")\n",
        "        samples = load_jsonl_or_json_array(file_path)\n",
        "        print_blimp_samples(samples)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiwPuvlQ4KV1",
        "outputId": "b5e68292-308c-42c3-ddf7-7b1de18bec5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Blimp Tasks\n",
            "============================================================\n",
            "\n",
            "Subtask: blimp_adjunct_island_filtered_results.jsonl\n",
            "Sentence (Good): Who should Derek hug after shocking Richard?\n",
            "Sentence (Bad): Who should Derek hug Richard after shocking?\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -106.24250793457031, Correct = False\n",
            "  Response 2: Score = -106.40333557128906, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -106.24250793457031, Correct = False\n",
            "  Filtered Response 2: Score = -106.40333557128906, Correct = False\n",
            "========================================\n",
            "Sentence (Good): What had Theresa walked through while talking about that high school?\n",
            "Sentence (Bad): What had Theresa walked through that high school while talking about?\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -121.53715515136719, Correct = False\n",
            "  Response 2: Score = -118.0936279296875, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -121.53715515136719, Correct = False\n",
            "  Filtered Response 2: Score = -118.0936279296875, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_anaphor_gender_agreement_filtered_results.jsonl\n",
            "Sentence (Good): Katherine can't help herself.\n",
            "Sentence (Bad): Katherine can't help himself.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -52.33869171142578, Correct = False\n",
            "  Response 2: Score = -52.98931121826172, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -52.33869171142578, Correct = False\n",
            "  Filtered Response 2: Score = -52.98931121826172, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Marie won't think about herself.\n",
            "Sentence (Bad): Marie won't think about itself.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -53.08155059814453, Correct = False\n",
            "  Response 2: Score = -51.886714935302734, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -53.08155059814453, Correct = False\n",
            "  Filtered Response 2: Score = -51.886714935302734, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_anaphor_number_agreement_filtered_results.jsonl\n",
            "Sentence (Good): Susan revealed herself.\n",
            "Sentence (Bad): Susan revealed themselves.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -45.25741195678711, Correct = False\n",
            "  Response 2: Score = -44.630958557128906, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -45.25741195678711, Correct = False\n",
            "  Filtered Response 2: Score = -44.630958557128906, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Renee hasn't hurt herself.\n",
            "Sentence (Bad): Renee hasn't hurt themselves.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -63.183815002441406, Correct = False\n",
            "  Response 2: Score = -62.02909851074219, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -63.183815002441406, Correct = False\n",
            "  Filtered Response 2: Score = -62.02909851074219, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_animate_subject_passive_filtered_results.jsonl\n",
            "Sentence (Good): Amanda was respected by some waitresses.\n",
            "Sentence (Bad): Amanda was respected by some picture.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -65.15655517578125, Correct = False\n",
            "  Response 2: Score = -62.02732467651367, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -65.15655517578125, Correct = False\n",
            "  Filtered Response 2: Score = -62.02732467651367, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Some lake was passed by some cashiers.\n",
            "Sentence (Bad): Some lake was passed by some phenomena.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -78.8900146484375, Correct = False\n",
            "  Response 2: Score = -73.51210021972656, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -78.8900146484375, Correct = False\n",
            "  Filtered Response 2: Score = -73.51210021972656, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_animate_subject_trans_filtered_results.jsonl\n",
            "Sentence (Good): Tina revealed Margaret.\n",
            "Sentence (Bad): The horse revealed Margaret.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -70.8104248046875, Correct = False\n",
            "  Response 2: Score = -69.51968383789062, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -70.8104248046875, Correct = False\n",
            "  Filtered Response 2: Score = -69.51968383789062, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Danielle visited Irene.\n",
            "Sentence (Bad): The eye visited Irene.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -82.14889526367188, Correct = False\n",
            "  Response 2: Score = -74.59551239013672, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -82.14889526367188, Correct = False\n",
            "  Filtered Response 2: Score = -74.59551239013672, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_causative_filtered_results.jsonl\n",
            "Sentence (Good): Aaron breaks the glass.\n",
            "Sentence (Bad): Aaron appeared the glass.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -47.66804504394531, Correct = False\n",
            "  Response 2: Score = -53.80850601196289, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -47.66804504394531, Correct = False\n",
            "  Filtered Response 2: Score = -53.80850601196289, Correct = False\n",
            "========================================\n",
            "Sentence (Good): April had dropped the truck.\n",
            "Sentence (Bad): April had existed the truck.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -50.2841682434082, Correct = False\n",
            "  Response 2: Score = -59.57054901123047, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -50.2841682434082, Correct = False\n",
            "  Filtered Response 2: Score = -59.57054901123047, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_complex_NP_island_filtered_results.jsonl\n",
            "Sentence (Good): Who aren't most hospitals that hadn't talked about most waitresses alarming?\n",
            "Sentence (Bad): Who aren't most waitresses alarming most hospitals that hadn't talked about?\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -117.25865936279297, Correct = False\n",
            "  Response 2: Score = -120.6151123046875, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -117.25865936279297, Correct = False\n",
            "  Filtered Response 2: Score = -120.6151123046875, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Who hasn't this sister of these dancers who shocked Cheryl attacked?\n",
            "Sentence (Bad): Who hasn't Cheryl attacked this sister of these dancers who shocked?\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -143.6206512451172, Correct = False\n",
            "  Response 2: Score = -138.062744140625, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -143.6206512451172, Correct = False\n",
            "  Filtered Response 2: Score = -138.062744140625, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_coordinate_structure_constraint_complex_left_branch_filtered_results.jsonl\n",
            "Sentence (Good): What senators was Alicia approaching and some teachers scaring?\n",
            "Sentence (Bad): What was Alicia approaching senators and some teachers scaring?\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -127.5733642578125, Correct = False\n",
            "  Response 2: Score = -128.36825561523438, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -127.5733642578125, Correct = False\n",
            "  Filtered Response 2: Score = -128.36825561523438, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Whose restaurants is Clyde exiting and Amelia talking about?\n",
            "Sentence (Bad): Whose is Clyde exiting restaurants and Amelia talking about?\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -140.45034790039062, Correct = False\n",
            "  Response 2: Score = -138.7520751953125, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -140.45034790039062, Correct = False\n",
            "  Filtered Response 2: Score = -138.7520751953125, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_coordinate_structure_constraint_object_extraction_filtered_results.jsonl\n",
            "Sentence (Good): Who were all men and Eric leaving?\n",
            "Sentence (Bad): Who were all men leaving and Eric?\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -76.98826599121094, Correct = False\n",
            "  Response 2: Score = -76.82994842529297, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -76.98826599121094, Correct = False\n",
            "  Filtered Response 2: Score = -76.82994842529297, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Who will Elizabeth and Gregory cure?\n",
            "Sentence (Bad): Who could Elizabeth cure and Gregory?\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -87.30122375488281, Correct = False\n",
            "  Response 2: Score = -91.17071533203125, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -87.30122375488281, Correct = False\n",
            "  Filtered Response 2: Score = -91.17071533203125, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_determiner_noun_agreement_1_filtered_results.jsonl\n",
            "Sentence (Good): Raymond is selling this sketch.\n",
            "Sentence (Bad): Raymond is selling this sketches.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -54.361839294433594, Correct = False\n",
            "  Response 2: Score = -54.68656921386719, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -54.361839294433594, Correct = False\n",
            "  Filtered Response 2: Score = -54.68656921386719, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Craig explored that grocery store.\n",
            "Sentence (Bad): Craig explored that grocery stores.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -60.24201202392578, Correct = False\n",
            "  Response 2: Score = -62.27366638183594, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -60.24201202392578, Correct = False\n",
            "  Filtered Response 2: Score = -62.27366638183594, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_determiner_noun_agreement_2_filtered_results.jsonl\n",
            "Sentence (Good): Some dog stunned this committee.\n",
            "Sentence (Bad): Some dog stunned these committee.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -65.34248352050781, Correct = False\n",
            "  Response 2: Score = -70.33766174316406, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -65.34248352050781, Correct = False\n",
            "  Filtered Response 2: Score = -70.33766174316406, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Tracy passed these art galleries.\n",
            "Sentence (Bad): Tracy passed this art galleries.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -71.896728515625, Correct = False\n",
            "  Response 2: Score = -72.46705627441406, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -71.896728515625, Correct = False\n",
            "  Filtered Response 2: Score = -72.46705627441406, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_determiner_noun_agreement_irregular_1_filtered_results.jsonl\n",
            "Sentence (Good): Laurie hasn't lifted those cacti.\n",
            "Sentence (Bad): Laurie hasn't lifted those cactus.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -72.30209350585938, Correct = False\n",
            "  Response 2: Score = -67.12171936035156, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -72.30209350585938, Correct = False\n",
            "  Filtered Response 2: Score = -67.12171936035156, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Adam hadn't discussed these analyses.\n",
            "Sentence (Bad): Adam hadn't discussed these analysis.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -65.32386016845703, Correct = False\n",
            "  Response 2: Score = -58.461585998535156, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -65.32386016845703, Correct = False\n",
            "  Filtered Response 2: Score = -58.461585998535156, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_determiner_noun_agreement_irregular_2_filtered_results.jsonl\n",
            "Sentence (Good): All boys boast about that child.\n",
            "Sentence (Bad): All boys boast about those child.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -65.83309936523438, Correct = False\n",
            "  Response 2: Score = -71.36420440673828, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -65.83309936523438, Correct = False\n",
            "  Filtered Response 2: Score = -71.36420440673828, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Candice has taken that axis.\n",
            "Sentence (Bad): Candice has taken those axis.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -65.97746276855469, Correct = False\n",
            "  Response 2: Score = -66.03604125976562, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -65.97746276855469, Correct = False\n",
            "  Filtered Response 2: Score = -66.03604125976562, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_determiner_noun_agreement_with_adj_2_filtered_results.jsonl\n",
            "Sentence (Good): Cynthia scans these hard books.\n",
            "Sentence (Bad): Cynthia scans this hard books.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -85.50643157958984, Correct = False\n",
            "  Response 2: Score = -88.04193115234375, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -85.50643157958984, Correct = False\n",
            "  Filtered Response 2: Score = -88.04193115234375, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Donna might hire this serious actress.\n",
            "Sentence (Bad): Donna might hire these serious actress.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -65.89327239990234, Correct = False\n",
            "  Response 2: Score = -71.21099853515625, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -65.89327239990234, Correct = False\n",
            "  Filtered Response 2: Score = -71.21099853515625, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_determiner_noun_agreement_with_adj_irregular_1_filtered_results.jsonl\n",
            "Sentence (Good): Some waiters broke this lost foot.\n",
            "Sentence (Bad): Some waiters broke this lost feet.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -72.70474243164062, Correct = False\n",
            "  Response 2: Score = -74.93659973144531, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -72.70474243164062, Correct = False\n",
            "  Filtered Response 2: Score = -74.93659973144531, Correct = False\n",
            "========================================\n",
            "Sentence (Good): The company talks about those big women.\n",
            "Sentence (Bad): The company talks about those big woman.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -65.49565124511719, Correct = False\n",
            "  Response 2: Score = -72.30670166015625, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -65.49565124511719, Correct = False\n",
            "  Filtered Response 2: Score = -72.30670166015625, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_determiner_noun_agreement_with_adj_irregular_2_filtered_results.jsonl\n",
            "Sentence (Good): Alexander didn't walk through that new oasis.\n",
            "Sentence (Bad): Alexander didn't walk through those new oasis.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -72.48495483398438, Correct = False\n",
            "  Response 2: Score = -74.80293273925781, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -72.48495483398438, Correct = False\n",
            "  Filtered Response 2: Score = -74.80293273925781, Correct = False\n",
            "========================================\n",
            "Sentence (Good): This hair irritates these old alumni.\n",
            "Sentence (Bad): This hair irritates this old alumni.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -79.69178771972656, Correct = False\n",
            "  Response 2: Score = -76.20899963378906, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -79.69178771972656, Correct = False\n",
            "  Filtered Response 2: Score = -76.20899963378906, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_determiner_noun_agreement_with_adjective_1_filtered_results.jsonl\n",
            "Sentence (Good): Rebecca was criticizing those good documentaries.\n",
            "Sentence (Bad): Rebecca was criticizing those good documentary.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -74.62443542480469, Correct = False\n",
            "  Response 2: Score = -78.4032211303711, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -74.62443542480469, Correct = False\n",
            "  Filtered Response 2: Score = -78.4032211303711, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Some college campus embarrassed those bad legislatures.\n",
            "Sentence (Bad): Some college campus embarrassed those bad legislature.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -98.13450622558594, Correct = False\n",
            "  Response 2: Score = -98.62118530273438, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -98.13450622558594, Correct = False\n",
            "  Filtered Response 2: Score = -98.62118530273438, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_distractor_agreement_relational_noun_filtered_results.jsonl\n",
            "Sentence (Good): A niece of most senators hasn't descended most slopes.\n",
            "Sentence (Bad): A niece of most senators haven't descended most slopes.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -108.59359741210938, Correct = False\n",
            "  Response 2: Score = -107.68812561035156, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -108.59359741210938, Correct = False\n",
            "  Filtered Response 2: Score = -107.68812561035156, Correct = False\n",
            "========================================\n",
            "Sentence (Good): The sketch of those trucks hasn't hurt Alan.\n",
            "Sentence (Bad): The sketch of those trucks haven't hurt Alan.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -96.84801483154297, Correct = False\n",
            "  Response 2: Score = -98.27021789550781, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -96.84801483154297, Correct = False\n",
            "  Filtered Response 2: Score = -98.27021789550781, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_distractor_agreement_relative_clause_filtered_results.jsonl\n",
            "Sentence (Good): This customer who had visited most children has worn some shoes.\n",
            "Sentence (Bad): This customer who had visited most children have worn some shoes.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -96.20101928710938, Correct = False\n",
            "  Response 2: Score = -95.72395324707031, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -96.20101928710938, Correct = False\n",
            "  Filtered Response 2: Score = -95.72395324707031, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Boys that aren't disturbing Natalie suffer.\n",
            "Sentence (Bad): Boys that aren't disturbing Natalie suffers.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -94.04853820800781, Correct = False\n",
            "  Response 2: Score = -96.20980834960938, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -94.04853820800781, Correct = False\n",
            "  Filtered Response 2: Score = -96.20980834960938, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_drop_argument_filtered_results.jsonl\n",
            "Sentence (Good): Travis is touring.\n",
            "Sentence (Bad): Travis is revealing.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -60.354618072509766, Correct = False\n",
            "  Response 2: Score = -55.66487121582031, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -60.354618072509766, Correct = False\n",
            "  Filtered Response 2: Score = -55.66487121582031, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Noah approached.\n",
            "Sentence (Bad): Noah works with.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -40.01236343383789, Correct = False\n",
            "  Response 2: Score = -40.86602783203125, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -40.01236343383789, Correct = False\n",
            "  Filtered Response 2: Score = -40.86602783203125, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_ellipsis_n_bar_1_filtered_results.jsonl\n",
            "Sentence (Good): Dawn's ex-husband wasn't going to one rough grocery store and Becca wasn't going to many.\n",
            "Sentence (Bad): Dawn's ex-husband wasn't going to one grocery store and Becca wasn't going to many rough.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -167.13327026367188, Correct = False\n",
            "  Response 2: Score = -169.916015625, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -167.13327026367188, Correct = False\n",
            "  Filtered Response 2: Score = -169.916015625, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Most men irritates two happy students and a snake irritates three.\n",
            "Sentence (Bad): Most men irritates two students and a snake irritates three happy.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -111.58558654785156, Correct = False\n",
            "  Response 2: Score = -113.92412567138672, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -111.58558654785156, Correct = False\n",
            "  Filtered Response 2: Score = -113.92412567138672, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_ellipsis_n_bar_2_filtered_results.jsonl\n",
            "Sentence (Good): A friend of Pamela hasn't attacked one person and Ann hasn't attacked more unsure person.\n",
            "Sentence (Bad): A friend of Pamela hasn't attacked one unemployed person and Ann hasn't attacked more unsure.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -170.9853515625, Correct = False\n",
            "  Response 2: Score = -176.71798706054688, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -170.9853515625, Correct = False\n",
            "  Filtered Response 2: Score = -176.71798706054688, Correct = False\n",
            "========================================\n",
            "Sentence (Good): That legislature has three peppers and Charles has at least as many small peppers.\n",
            "Sentence (Bad): That legislature has three hidden peppers and Charles has at least as many small.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -130.11038208007812, Correct = False\n",
            "  Response 2: Score = -132.49195861816406, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -130.11038208007812, Correct = False\n",
            "  Filtered Response 2: Score = -132.49195861816406, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_existential_there_object_raising_filtered_results.jsonl\n",
            "Sentence (Good): William has declared there to be no guests getting fired.\n",
            "Sentence (Bad): William has obliged there to be no guests getting fired.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -75.70649719238281, Correct = False\n",
            "  Response 2: Score = -80.94682312011719, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -75.70649719238281, Correct = False\n",
            "  Filtered Response 2: Score = -80.94682312011719, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Richard believed there to be many boxes stunning Ellen.\n",
            "Sentence (Bad): Richard sways there to be many boxes stunning Ellen.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -96.33834838867188, Correct = False\n",
            "  Response 2: Score = -106.48507690429688, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -96.33834838867188, Correct = False\n",
            "  Filtered Response 2: Score = -106.48507690429688, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_existential_there_quantifiers_1_filtered_results.jsonl\n",
            "Sentence (Good): There was a documentary about music irritating Allison.\n",
            "Sentence (Bad): There was each documentary about music irritating Allison.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -88.82119750976562, Correct = False\n",
            "  Response 2: Score = -100.31719207763672, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -88.82119750976562, Correct = False\n",
            "  Filtered Response 2: Score = -100.31719207763672, Correct = False\n",
            "========================================\n",
            "Sentence (Good): There were no legislatures working hard.\n",
            "Sentence (Bad): There were most legislatures working hard.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -73.45260620117188, Correct = False\n",
            "  Response 2: Score = -73.19002532958984, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -73.45260620117188, Correct = False\n",
            "  Filtered Response 2: Score = -73.19002532958984, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_existential_there_quantifiers_2_filtered_results.jsonl\n",
            "Sentence (Good): Every fish was there astounding Sally.\n",
            "Sentence (Bad): There was every fish astounding Sally.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -84.4352035522461, Correct = False\n",
            "  Response 2: Score = -85.92514038085938, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -84.4352035522461, Correct = False\n",
            "  Filtered Response 2: Score = -85.92514038085938, Correct = False\n",
            "========================================\n",
            "Sentence (Good): All sisters of Roger weren't there going to this school.\n",
            "Sentence (Bad): There weren't all sisters of Roger going to this school.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -94.03958129882812, Correct = False\n",
            "  Response 2: Score = -92.874755859375, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -94.03958129882812, Correct = False\n",
            "  Filtered Response 2: Score = -92.874755859375, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_existential_there_subject_raising_filtered_results.jsonl\n",
            "Sentence (Good): There is soon to be a cat existing.\n",
            "Sentence (Bad): There is willing to be a cat existing.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -68.55943298339844, Correct = False\n",
            "  Response 2: Score = -66.33033752441406, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -68.55943298339844, Correct = False\n",
            "  Filtered Response 2: Score = -66.33033752441406, Correct = False\n",
            "========================================\n",
            "Sentence (Good): There was bound to be a fish escaping.\n",
            "Sentence (Bad): There was unable to be a fish escaping.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -65.99024963378906, Correct = False\n",
            "  Response 2: Score = -66.74050903320312, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -65.99024963378906, Correct = False\n",
            "  Filtered Response 2: Score = -66.74050903320312, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_expletive_it_object_raising_filtered_results.jsonl\n",
            "Sentence (Good): Tara would ascertain it to be noteworthy that Kenneth didn't wash.\n",
            "Sentence (Bad): Tara wouldn't entice it to be noteworthy that Kenneth didn't wash.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -144.77490234375, Correct = False\n",
            "  Response 2: Score = -146.05270385742188, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -144.77490234375, Correct = False\n",
            "  Filtered Response 2: Score = -146.05270385742188, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Carla could declare it to be not so important that these doctors observe Rhonda.\n",
            "Sentence (Bad): Carla can convince it to be not so important that these doctors observe Rhonda.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -140.77500915527344, Correct = False\n",
            "  Response 2: Score = -138.8218994140625, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -140.77500915527344, Correct = False\n",
            "  Filtered Response 2: Score = -138.8218994140625, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_inchoative_filtered_results.jsonl\n",
            "Sentence (Good): Patricia had changed.\n",
            "Sentence (Bad): Patricia had forgotten.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -45.50153732299805, Correct = False\n",
            "  Response 2: Score = -46.889339447021484, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -45.50153732299805, Correct = False\n",
            "  Filtered Response 2: Score = -46.889339447021484, Correct = False\n",
            "========================================\n",
            "Sentence (Good): A lot of closets could fling open.\n",
            "Sentence (Bad): A lot of closets could buy.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -81.83525085449219, Correct = False\n",
            "  Response 2: Score = -66.54617309570312, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -81.83525085449219, Correct = False\n",
            "  Filtered Response 2: Score = -66.54617309570312, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_intransitive_filtered_results.jsonl\n",
            "Sentence (Good): Todd can't yawn.\n",
            "Sentence (Bad): Todd can't walk through.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -48.81060791015625, Correct = False\n",
            "  Response 2: Score = -44.46760559082031, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -48.81060791015625, Correct = False\n",
            "  Filtered Response 2: Score = -44.46760559082031, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Some guests hadn't left.\n",
            "Sentence (Bad): Some guests hadn't boasted about.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -55.806610107421875, Correct = False\n",
            "  Response 2: Score = -68.17799377441406, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -55.806610107421875, Correct = False\n",
            "  Filtered Response 2: Score = -68.17799377441406, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_irregular_past_participle_adjectives_filtered_results.jsonl\n",
            "Sentence (Good): The hidden offspring aren't confident.\n",
            "Sentence (Bad): The hid offspring aren't confident.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -68.16664123535156, Correct = False\n",
            "  Response 2: Score = -69.51165771484375, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -68.16664123535156, Correct = False\n",
            "  Filtered Response 2: Score = -69.51165771484375, Correct = False\n",
            "========================================\n",
            "Sentence (Good): The hidden bicycles weren't exposed.\n",
            "Sentence (Bad): The hid bicycles weren't exposed.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -71.7668228149414, Correct = False\n",
            "  Response 2: Score = -75.85794067382812, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -71.7668228149414, Correct = False\n",
            "  Filtered Response 2: Score = -75.85794067382812, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_irregular_past_participle_verbs_filtered_results.jsonl\n",
            "Sentence (Good): Teresa hid every senator.\n",
            "Sentence (Bad): Teresa hidden every senator.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -69.62696075439453, Correct = False\n",
            "  Response 2: Score = -68.99128723144531, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -69.62696075439453, Correct = False\n",
            "  Filtered Response 2: Score = -68.99128723144531, Correct = False\n",
            "========================================\n",
            "Sentence (Good): The mushroom went bad.\n",
            "Sentence (Bad): The mushroom gone bad.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -58.007728576660156, Correct = False\n",
            "  Response 2: Score = -58.92703628540039, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -58.007728576660156, Correct = False\n",
            "  Filtered Response 2: Score = -58.92703628540039, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_irregular_plural_subject_verb_agreement_1_filtered_results.jsonl\n",
            "Sentence (Good): Those radii have scared that teenager.\n",
            "Sentence (Bad): Those radii has scared that teenager.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -79.88048553466797, Correct = False\n",
            "  Response 2: Score = -80.74073791503906, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -79.88048553466797, Correct = False\n",
            "  Filtered Response 2: Score = -80.74073791503906, Correct = False\n",
            "========================================\n",
            "Sentence (Good): This goose isn't bothering Edward.\n",
            "Sentence (Bad): This goose weren't bothering Edward.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -75.85702514648438, Correct = False\n",
            "  Response 2: Score = -79.18751525878906, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -75.85702514648438, Correct = False\n",
            "  Filtered Response 2: Score = -79.18751525878906, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_irregular_plural_subject_verb_agreement_2_filtered_results.jsonl\n",
            "Sentence (Good): The women meet.\n",
            "Sentence (Bad): The woman meet.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -41.989097595214844, Correct = False\n",
            "  Response 2: Score = -44.719520568847656, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -41.989097595214844, Correct = False\n",
            "  Filtered Response 2: Score = -44.719520568847656, Correct = False\n",
            "========================================\n",
            "Sentence (Good): The child isn't attacking Becky.\n",
            "Sentence (Bad): The children isn't attacking Becky.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -75.97320556640625, Correct = False\n",
            "  Response 2: Score = -76.46659851074219, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -75.97320556640625, Correct = False\n",
            "  Filtered Response 2: Score = -76.46659851074219, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_left_branch_island_echo_question_filtered_results.jsonl\n",
            "Sentence (Good): Irene had messed up whose rug?\n",
            "Sentence (Bad): Whose had Irene messed up rug?\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -71.5123519897461, Correct = False\n",
            "  Response 2: Score = -98.6504898071289, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -71.5123519897461, Correct = False\n",
            "  Filtered Response 2: Score = -98.6504898071289, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Edward has returned to which customers?\n",
            "Sentence (Bad): Which has Edward returned to customers?\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -64.81007385253906, Correct = False\n",
            "  Response 2: Score = -81.39155578613281, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -64.81007385253906, Correct = False\n",
            "  Filtered Response 2: Score = -81.39155578613281, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_left_branch_island_simple_question_filtered_results.jsonl\n",
            "Sentence (Good): Whose museums had Dana alarmed?\n",
            "Sentence (Bad): Whose had Dana alarmed museums?\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -106.55633544921875, Correct = False\n",
            "  Response 2: Score = -109.71161651611328, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -106.55633544921875, Correct = False\n",
            "  Filtered Response 2: Score = -109.71161651611328, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Whose hat should Tonya wear?\n",
            "Sentence (Bad): Whose should Tonya wear hat?\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -96.6172103881836, Correct = False\n",
            "  Response 2: Score = -97.94251251220703, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -96.6172103881836, Correct = False\n",
            "  Filtered Response 2: Score = -97.94251251220703, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_matrix_question_npi_licensor_present_filtered_results.jsonl\n",
            "Sentence (Good): Had Bruce ever played?\n",
            "Sentence (Bad): Bruce had ever played.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -68.49990844726562, Correct = False\n",
            "  Response 2: Score = -45.58380126953125, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -68.49990844726562, Correct = False\n",
            "  Filtered Response 2: Score = -45.58380126953125, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Had Patrick ever answered?\n",
            "Sentence (Bad): Patrick had ever answered.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -66.31289672851562, Correct = False\n",
            "  Response 2: Score = -47.64580535888672, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -66.31289672851562, Correct = False\n",
            "  Filtered Response 2: Score = -47.64580535888672, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_npi_present_1_filtered_results.jsonl\n",
            "Sentence (Good): Even Suzanne has really joked around.\n",
            "Sentence (Bad): Even Suzanne has ever joked around.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -101.10802459716797, Correct = False\n",
            "  Response 2: Score = -98.91061401367188, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -101.10802459716797, Correct = False\n",
            "  Filtered Response 2: Score = -98.91061401367188, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Even many teenagers clearly boycott those legislatures.\n",
            "Sentence (Bad): Even many teenagers ever boycott those legislatures.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -105.35375213623047, Correct = False\n",
            "  Response 2: Score = -102.98509216308594, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -105.35375213623047, Correct = False\n",
            "  Filtered Response 2: Score = -102.98509216308594, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_npi_present_2_filtered_results.jsonl\n",
            "Sentence (Good): Tamara really exited those mountains.\n",
            "Sentence (Bad): Tamara ever exited those mountains.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -76.5179443359375, Correct = False\n",
            "  Response 2: Score = -74.89736938476562, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -76.5179443359375, Correct = False\n",
            "  Filtered Response 2: Score = -74.89736938476562, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Karen could certainly boycott this association.\n",
            "Sentence (Bad): Karen could ever boycott this association.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -80.6011962890625, Correct = False\n",
            "  Response 2: Score = -76.8817367553711, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -80.6011962890625, Correct = False\n",
            "  Filtered Response 2: Score = -76.8817367553711, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_only_npi_licensor_present_filtered_results.jsonl\n",
            "Sentence (Good): Only Bill would ever complain.\n",
            "Sentence (Bad): Even Bill would ever complain.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -67.8538818359375, Correct = False\n",
            "  Response 2: Score = -68.56678771972656, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -67.8538818359375, Correct = False\n",
            "  Filtered Response 2: Score = -68.56678771972656, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Only Lori had ever healed Carl.\n",
            "Sentence (Bad): Even Lori had ever healed Carl.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -108.43197631835938, Correct = False\n",
            "  Response 2: Score = -108.23783874511719, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -108.43197631835938, Correct = False\n",
            "  Filtered Response 2: Score = -108.23783874511719, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_only_npi_scope_filtered_results.jsonl\n",
            "Sentence (Good): Only that story about Monet that Mark would research does ever worry Richard.\n",
            "Sentence (Bad): That story about Monet that only Mark would research does ever worry Richard.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -158.64306640625, Correct = False\n",
            "  Response 2: Score = -165.82418823242188, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -158.64306640625, Correct = False\n",
            "  Filtered Response 2: Score = -165.82418823242188, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Only a popsicle that Danielle admires ever freezes.\n",
            "Sentence (Bad): A popsicle that only Danielle admires ever freezes.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -137.11541748046875, Correct = False\n",
            "  Response 2: Score = -145.34326171875, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -137.11541748046875, Correct = False\n",
            "  Filtered Response 2: Score = -145.34326171875, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_passive_1_filtered_results.jsonl\n",
            "Sentence (Good): Lucille's sisters are confused by Amy.\n",
            "Sentence (Bad): Lucille's sisters are communicated by Amy.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -84.67880249023438, Correct = False\n",
            "  Response 2: Score = -89.4566650390625, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -84.67880249023438, Correct = False\n",
            "  Filtered Response 2: Score = -89.4566650390625, Correct = False\n",
            "========================================\n",
            "Sentence (Good): A lot of hospitals were astounded by some actress.\n",
            "Sentence (Bad): A lot of hospitals were cooperated by some actress.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -90.12355041503906, Correct = False\n",
            "  Response 2: Score = -81.66249084472656, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -90.12355041503906, Correct = False\n",
            "  Filtered Response 2: Score = -81.66249084472656, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_passive_2_filtered_results.jsonl\n",
            "Sentence (Good): A lot of nieces of some actor aren't scared.\n",
            "Sentence (Bad): A lot of nieces of some actor aren't wept.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -95.46332550048828, Correct = False\n",
            "  Response 2: Score = -101.47856140136719, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -95.46332550048828, Correct = False\n",
            "  Filtered Response 2: Score = -101.47856140136719, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Mitchell's grandfathers are forgotten.\n",
            "Sentence (Bad): Mitchell's grandfathers are concurred.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -73.5687484741211, Correct = False\n",
            "  Response 2: Score = -81.0418472290039, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -73.5687484741211, Correct = False\n",
            "  Filtered Response 2: Score = -81.0418472290039, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_principle_A_c_command_filtered_results.jsonl\n",
            "Sentence (Good): A lot of patients who can sell some couch didn't investigate themselves.\n",
            "Sentence (Bad): A lot of patients who can sell some couch didn't investigate itself.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -105.59040832519531, Correct = False\n",
            "  Response 2: Score = -106.13020324707031, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -105.59040832519531, Correct = False\n",
            "  Filtered Response 2: Score = -106.13020324707031, Correct = False\n",
            "========================================\n",
            "Sentence (Good): A lot of actresses that thought about Alice healed themselves.\n",
            "Sentence (Bad): A lot of actresses that thought about Alice healed herself.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -107.79717254638672, Correct = False\n",
            "  Response 2: Score = -109.03462219238281, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -107.79717254638672, Correct = False\n",
            "  Filtered Response 2: Score = -109.03462219238281, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_principle_A_case_1_filtered_results.jsonl\n",
            "Sentence (Good): The teenagers explain that they aren't breaking all glasses.\n",
            "Sentence (Bad): The teenagers explain that themselves aren't breaking all glasses.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -87.97179412841797, Correct = False\n",
            "  Response 2: Score = -95.23438262939453, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -87.97179412841797, Correct = False\n",
            "  Filtered Response 2: Score = -95.23438262939453, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Carl can't imagine that he complained about Lisa.\n",
            "Sentence (Bad): Carl can't imagine that himself complained about Lisa.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -81.0728759765625, Correct = False\n",
            "  Response 2: Score = -88.68641662597656, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -81.0728759765625, Correct = False\n",
            "  Filtered Response 2: Score = -88.68641662597656, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_principle_A_case_2_filtered_results.jsonl\n",
            "Sentence (Good): Eric imagines himself taking every rug.\n",
            "Sentence (Bad): Eric imagines himself took every rug.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -73.68368530273438, Correct = False\n",
            "  Response 2: Score = -72.92921447753906, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -73.68368530273438, Correct = False\n",
            "  Filtered Response 2: Score = -72.92921447753906, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Stacy imagines herself praising this actress.\n",
            "Sentence (Bad): Stacy imagines herself praises this actress.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -90.71180725097656, Correct = False\n",
            "  Response 2: Score = -93.85507202148438, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -90.71180725097656, Correct = False\n",
            "  Filtered Response 2: Score = -93.85507202148438, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_principle_A_domain_1_filtered_results.jsonl\n",
            "Sentence (Good): Carla had explained that Samuel has discussed her.\n",
            "Sentence (Bad): Carla had explained that Samuel has discussed herself.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -88.8659439086914, Correct = False\n",
            "  Response 2: Score = -93.0076904296875, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -88.8659439086914, Correct = False\n",
            "  Filtered Response 2: Score = -93.0076904296875, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Alice hadn't said that some people weren't escaping from her.\n",
            "Sentence (Bad): Alice hadn't said that some people weren't escaping from herself.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -81.01936340332031, Correct = False\n",
            "  Response 2: Score = -83.12890625, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -81.01936340332031, Correct = False\n",
            "  Filtered Response 2: Score = -83.12890625, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_principle_A_domain_2_filtered_results.jsonl\n",
            "Sentence (Good): Donald can imagine those college campuses are boring themselves.\n",
            "Sentence (Bad): Donald can imagine those college campuses are boring himself.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -90.70895385742188, Correct = False\n",
            "  Response 2: Score = -93.23108673095703, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -90.70895385742188, Correct = False\n",
            "  Filtered Response 2: Score = -93.23108673095703, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Gerald was explaining Patricia was revealing herself.\n",
            "Sentence (Bad): Gerald was explaining Patricia was revealing himself.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -87.22140502929688, Correct = False\n",
            "  Response 2: Score = -88.61843872070312, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -87.22140502929688, Correct = False\n",
            "  Filtered Response 2: Score = -88.61843872070312, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_principle_A_domain_3_filtered_results.jsonl\n",
            "Sentence (Good): Steven explains Kayla won't hurt herself.\n",
            "Sentence (Bad): Kayla explains Steven won't hurt herself.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -98.70745086669922, Correct = False\n",
            "  Response 2: Score = -97.50936889648438, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -98.70745086669922, Correct = False\n",
            "  Filtered Response 2: Score = -97.50936889648438, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Gina explains Alan fires himself.\n",
            "Sentence (Bad): Alan explains Gina fires himself.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -79.02151489257812, Correct = False\n",
            "  Response 2: Score = -77.95092010498047, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -79.02151489257812, Correct = False\n",
            "  Filtered Response 2: Score = -77.95092010498047, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_principle_A_reconstruction_filtered_results.jsonl\n",
            "Sentence (Good): It's himself that this cashier attacked.\n",
            "Sentence (Bad): It's himself that attacked this cashier.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -78.08941650390625, Correct = False\n",
            "  Response 2: Score = -76.84782409667969, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -78.08941650390625, Correct = False\n",
            "  Filtered Response 2: Score = -76.84782409667969, Correct = False\n",
            "========================================\n",
            "Sentence (Good): It's herself that Andrea attacked.\n",
            "Sentence (Bad): It's herself that attacked Andrea.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -88.14544677734375, Correct = False\n",
            "  Response 2: Score = -84.3336410522461, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -88.14544677734375, Correct = False\n",
            "  Filtered Response 2: Score = -84.3336410522461, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_regular_plural_subject_verb_agreement_1_filtered_results.jsonl\n",
            "Sentence (Good): Paula references Robert.\n",
            "Sentence (Bad): Paula reference Robert.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -66.88331604003906, Correct = False\n",
            "  Response 2: Score = -63.06626892089844, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -66.88331604003906, Correct = False\n",
            "  Filtered Response 2: Score = -63.06626892089844, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Most legislatures haven't disliked children.\n",
            "Sentence (Bad): Most legislatures hasn't disliked children.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -80.3182373046875, Correct = False\n",
            "  Response 2: Score = -81.39430236816406, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -80.3182373046875, Correct = False\n",
            "  Filtered Response 2: Score = -81.39430236816406, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_regular_plural_subject_verb_agreement_2_filtered_results.jsonl\n",
            "Sentence (Good): The students perform.\n",
            "Sentence (Bad): The student perform.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -50.31257247924805, Correct = False\n",
            "  Response 2: Score = -49.876136779785156, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -50.31257247924805, Correct = False\n",
            "  Filtered Response 2: Score = -49.876136779785156, Correct = False\n",
            "========================================\n",
            "Sentence (Good): The associations talk about Stacey.\n",
            "Sentence (Bad): The association talk about Stacey.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -88.845703125, Correct = False\n",
            "  Response 2: Score = -89.40036010742188, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -88.845703125, Correct = False\n",
            "  Filtered Response 2: Score = -89.40036010742188, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_sentential_negation_npi_licensor_present_filtered_results.jsonl\n",
            "Sentence (Good): Teresa had not ever sold a movie theater.\n",
            "Sentence (Bad): Teresa had probably ever sold a movie theater.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -82.56043243408203, Correct = False\n",
            "  Response 2: Score = -85.1190185546875, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -82.56043243408203, Correct = False\n",
            "  Filtered Response 2: Score = -85.1190185546875, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Allison has not ever taken that ice cream.\n",
            "Sentence (Bad): Allison has fortunately ever taken that ice cream.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -63.479488372802734, Correct = False\n",
            "  Response 2: Score = -74.99406433105469, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -63.479488372802734, Correct = False\n",
            "  Filtered Response 2: Score = -74.99406433105469, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_sentential_negation_npi_scope_filtered_results.jsonl\n",
            "Sentence (Good): The associations that had worried Cynthia have not ever planned to shock every actress.\n",
            "Sentence (Bad): The associations that had not worried Cynthia have ever planned to shock every actress.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -151.6326904296875, Correct = False\n",
            "  Response 2: Score = -149.54188537597656, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -151.6326904296875, Correct = False\n",
            "  Filtered Response 2: Score = -149.54188537597656, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Every son of Jerry who has insulted Jerry can not ever die.\n",
            "Sentence (Bad): Every son of Jerry who has not insulted Jerry can ever die.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -123.37396240234375, Correct = False\n",
            "  Response 2: Score = -122.56330108642578, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -123.37396240234375, Correct = False\n",
            "  Filtered Response 2: Score = -122.56330108642578, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_sentential_subject_island_filtered_results.jsonl\n",
            "Sentence (Good): Who had the patients' cleaning those banks upset.\n",
            "Sentence (Bad): Who had the patients' cleaning upset those banks.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -91.73466491699219, Correct = False\n",
            "  Response 2: Score = -90.99134063720703, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -91.73466491699219, Correct = False\n",
            "  Filtered Response 2: Score = -90.99134063720703, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Who has the waitress's observing Christine bothered.\n",
            "Sentence (Bad): Who has the waitress's observing bothered Christine.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -97.79812622070312, Correct = False\n",
            "  Response 2: Score = -100.36564636230469, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -97.79812622070312, Correct = False\n",
            "  Filtered Response 2: Score = -100.36564636230469, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_superlative_quantifiers_1_filtered_results.jsonl\n",
            "Sentence (Good): No girl attacked fewer than two waiters.\n",
            "Sentence (Bad): No girl attacked at most two waiters.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -75.63323974609375, Correct = False\n",
            "  Response 2: Score = -75.02118682861328, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -75.63323974609375, Correct = False\n",
            "  Filtered Response 2: Score = -75.02118682861328, Correct = False\n",
            "========================================\n",
            "Sentence (Good): No person would bring fewer than three gates.\n",
            "Sentence (Bad): No person would bring at most three gates.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -74.45219421386719, Correct = False\n",
            "  Response 2: Score = -76.23206329345703, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -74.45219421386719, Correct = False\n",
            "  Filtered Response 2: Score = -76.23206329345703, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_superlative_quantifiers_2_filtered_results.jsonl\n",
            "Sentence (Good): The teenager does tour at most nine restaurants.\n",
            "Sentence (Bad): No teenager does tour at most nine restaurants.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -86.6944808959961, Correct = False\n",
            "  Response 2: Score = -87.39884948730469, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -86.6944808959961, Correct = False\n",
            "  Filtered Response 2: Score = -87.39884948730469, Correct = False\n",
            "========================================\n",
            "Sentence (Good): That car looks like at least seven prints.\n",
            "Sentence (Bad): No car looks like at least seven prints.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -71.51412963867188, Correct = False\n",
            "  Response 2: Score = -70.56303405761719, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -71.51412963867188, Correct = False\n",
            "  Filtered Response 2: Score = -70.56303405761719, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_supplement_hypernym_results.jsonl\n",
            "Sentence (Good): If she has a dog, it must be the case that she has a mammal.\n",
            "Sentence (Bad): If she has a dog, it must be the case that she has a chihuahua.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -93.67176055908203, Correct = False\n",
            "  Response 2: Score = -93.56779479980469, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -93.67176055908203, Correct = False\n",
            "  Filtered Response 2: Score = -93.56779479980469, Correct = False\n",
            "========================================\n",
            "Sentence (Good): She doesn't have a dog, so she doesn't have a chihuahua.\n",
            "Sentence (Bad): She doesn't have a chihuahua, so she doesn't have a dog.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -74.67704772949219, Correct = False\n",
            "  Response 2: Score = -72.95763397216797, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -74.67704772949219, Correct = False\n",
            "  Filtered Response 2: Score = -72.95763397216797, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_supplement_qa_congruence_easy_results.jsonl\n",
            "Sentence (Good): What did you get?\n",
            "I got a chair.\n",
            "Sentence (Bad): What did you get?\n",
            "I got a teacher.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -99.68988037109375, Correct = False\n",
            "  Response 2: Score = -102.55091857910156, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -99.68988037109375, Correct = False\n",
            "  Filtered Response 2: Score = -102.55091857910156, Correct = False\n",
            "========================================\n",
            "Sentence (Good): A: What did you sell?\n",
            "B: A chair.\n",
            "Sentence (Bad): A: What did you sell?\n",
            "B: Sarah.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -141.75009155273438, Correct = False\n",
            "  Response 2: Score = -133.50282287597656, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -141.75009155273438, Correct = False\n",
            "  Filtered Response 2: Score = -133.50282287597656, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_supplement_qa_congruence_tricky_results.jsonl\n",
            "Sentence (Good): Who cleaned?\n",
            "David cleaned.\n",
            "Sentence (Bad): Who cleaned?\n",
            "The patio cleaned.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -94.496826171875, Correct = False\n",
            "  Response 2: Score = -110.86768341064453, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -94.496826171875, Correct = False\n",
            "  Filtered Response 2: Score = -110.86768341064453, Correct = False\n",
            "========================================\n",
            "Sentence (Good): A: Who cleaned?\n",
            "B: Sarah.\n",
            "Sentence (Bad): A: Who cleaned?\n",
            "B: The patio.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -128.47120666503906, Correct = False\n",
            "  Response 2: Score = -144.8585205078125, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -128.47120666503906, Correct = False\n",
            "  Filtered Response 2: Score = -144.8585205078125, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_supplement_subject_aux_inversion_results.jsonl\n",
            "Sentence (Good): Is the novel he is putting away from the library?\n",
            "Sentence (Bad): Is the novel he putting away is from the library?\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -79.64588928222656, Correct = False\n",
            "  Response 2: Score = -89.3132095336914, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -79.64588928222656, Correct = False\n",
            "  Filtered Response 2: Score = -89.3132095336914, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Has every possibility she has ever tested failed miserably?\n",
            "Sentence (Bad): Has every possibility she ever tested has failed miserably?\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -93.45450592041016, Correct = False\n",
            "  Response 2: Score = -95.64685821533203, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -93.45450592041016, Correct = False\n",
            "  Filtered Response 2: Score = -95.64685821533203, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_supplement_turn_taking_results.jsonl\n",
            "Sentence (Good): David: Should you quit?\n",
            "Sarah: No, I shouldn't.\n",
            "Sentence (Bad): David: Should she quit?\n",
            "Sarah: No, I shouldn't.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -189.9068145751953, Correct = False\n",
            "  Response 2: Score = -190.42214965820312, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -189.9068145751953, Correct = False\n",
            "  Filtered Response 2: Score = -190.42214965820312, Correct = False\n",
            "========================================\n",
            "Sentence (Good): David: Should you meet him?\n",
            "Sarah: Yes, I should.\n",
            "Sentence (Bad): David: Should she meet him?\n",
            "Sarah: Yes, I should.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -188.89419555664062, Correct = False\n",
            "  Response 2: Score = -191.15989685058594, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -188.89419555664062, Correct = False\n",
            "  Filtered Response 2: Score = -191.15989685058594, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_tough_vs_raising_1_filtered_results.jsonl\n",
            "Sentence (Good): James is pleasant to flee from.\n",
            "Sentence (Bad): James is apt to flee from.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -59.92293930053711, Correct = False\n",
            "  Response 2: Score = -55.249664306640625, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -59.92293930053711, Correct = False\n",
            "  Filtered Response 2: Score = -55.249664306640625, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Samuel's lawyer was easy to reference.\n",
            "Sentence (Bad): Samuel's lawyer was certain to reference.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -66.7629165649414, Correct = False\n",
            "  Response 2: Score = -69.74275970458984, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -66.7629165649414, Correct = False\n",
            "  Filtered Response 2: Score = -69.74275970458984, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_tough_vs_raising_2_filtered_results.jsonl\n",
            "Sentence (Good): Every hospital isn't about to tempt Tiffany to reference Matt.\n",
            "Sentence (Bad): Every hospital isn't fun to tempt Tiffany to reference Matt.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -140.85333251953125, Correct = False\n",
            "  Response 2: Score = -143.96319580078125, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -140.85333251953125, Correct = False\n",
            "  Filtered Response 2: Score = -143.96319580078125, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Rachel was apt to talk to Alicia.\n",
            "Sentence (Bad): Rachel was exciting to talk to Alicia.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -79.88015747070312, Correct = False\n",
            "  Response 2: Score = -79.89312744140625, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -79.88015747070312, Correct = False\n",
            "  Filtered Response 2: Score = -79.89312744140625, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_transitive_filtered_results.jsonl\n",
            "Sentence (Good): Some turtles alarm Kimberley.\n",
            "Sentence (Bad): Some turtles come here Kimberley.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -94.29743957519531, Correct = False\n",
            "  Response 2: Score = -87.27279663085938, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -94.29743957519531, Correct = False\n",
            "  Filtered Response 2: Score = -87.27279663085938, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Diane watched Alan.\n",
            "Sentence (Bad): Diane screamed Alan.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -70.48436737060547, Correct = False\n",
            "  Response 2: Score = -70.6038818359375, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -70.48436737060547, Correct = False\n",
            "  Filtered Response 2: Score = -70.6038818359375, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_wh_island_filtered_results.jsonl\n",
            "Sentence (Good): Who have those men revealed they helped?\n",
            "Sentence (Bad): Who have those men revealed who helped?\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -71.6044692993164, Correct = False\n",
            "  Response 2: Score = -72.89979553222656, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -71.6044692993164, Correct = False\n",
            "  Filtered Response 2: Score = -72.89979553222656, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Who isn't Craig realizing he kisses?\n",
            "Sentence (Bad): Who isn't Craig realizing who kisses?\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -88.29621887207031, Correct = False\n",
            "  Response 2: Score = -88.23776245117188, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -88.29621887207031, Correct = False\n",
            "  Filtered Response 2: Score = -88.23776245117188, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_wh_questions_object_gap_filtered_results.jsonl\n",
            "Sentence (Good): Joel discovered the vase that Patricia might take.\n",
            "Sentence (Bad): Joel discovered what Patricia might take the vase.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -89.5552749633789, Correct = False\n",
            "  Response 2: Score = -93.3427505493164, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -89.5552749633789, Correct = False\n",
            "  Filtered Response 2: Score = -93.3427505493164, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Rodney thought about many paintings that Wendy had thought about.\n",
            "Sentence (Bad): Rodney thought about what Wendy had thought about many paintings.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -107.80812072753906, Correct = False\n",
            "  Response 2: Score = -110.01741027832031, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -107.80812072753906, Correct = False\n",
            "  Filtered Response 2: Score = -110.01741027832031, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_wh_questions_subject_gap_filtered_results.jsonl\n",
            "Sentence (Good): Brian had questioned an association that can astound Diana.\n",
            "Sentence (Bad): Brian had questioned who an association can astound Diana.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -105.96171569824219, Correct = False\n",
            "  Response 2: Score = -113.97056579589844, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -105.96171569824219, Correct = False\n",
            "  Filtered Response 2: Score = -113.97056579589844, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Leslie remembered some guest that has bothered women.\n",
            "Sentence (Bad): Leslie remembered who some guest has bothered women.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -81.32595825195312, Correct = False\n",
            "  Response 2: Score = -85.5857162475586, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -81.32595825195312, Correct = False\n",
            "  Filtered Response 2: Score = -85.5857162475586, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_wh_questions_subject_gap_long_distance_filtered_results.jsonl\n",
            "Sentence (Good): Dennis has seen this tooth that Kristin wasn't concealing that is astounding men.\n",
            "Sentence (Bad): Dennis has seen who this tooth that Kristin wasn't concealing is astounding men.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -138.26437377929688, Correct = False\n",
            "  Response 2: Score = -146.94151306152344, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -138.26437377929688, Correct = False\n",
            "  Filtered Response 2: Score = -146.94151306152344, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Renee investigates these offspring that some drivers boast about that would heal some dog.\n",
            "Sentence (Bad): Renee investigates what these offspring that some drivers boast about would heal some dog.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -145.93777465820312, Correct = False\n",
            "  Response 2: Score = -154.36880493164062, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -145.93777465820312, Correct = False\n",
            "  Filtered Response 2: Score = -154.36880493164062, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_wh_vs_that_no_gap_filtered_results.jsonl\n",
            "Sentence (Good): Mark figured out that most governments appreciate Steve.\n",
            "Sentence (Bad): Mark figured out who most governments appreciate Steve.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -91.11863708496094, Correct = False\n",
            "  Response 2: Score = -92.11111450195312, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -91.11863708496094, Correct = False\n",
            "  Filtered Response 2: Score = -92.11111450195312, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Danielle finds out that many organizations have alarmed Chad.\n",
            "Sentence (Bad): Danielle finds out who many organizations have alarmed Chad.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -115.82051849365234, Correct = False\n",
            "  Response 2: Score = -122.34614562988281, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -115.82051849365234, Correct = False\n",
            "  Filtered Response 2: Score = -122.34614562988281, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_wh_vs_that_no_gap_long_distance_filtered_results.jsonl\n",
            "Sentence (Good): Every association figured out that most drivers that forfeit investigated Irene.\n",
            "Sentence (Bad): Every association figured out who most drivers that forfeit investigated Irene.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -119.83308410644531, Correct = False\n",
            "  Response 2: Score = -121.69198608398438, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -119.83308410644531, Correct = False\n",
            "  Filtered Response 2: Score = -121.69198608398438, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Kathleen was revealing that this actress that can sit down was skated around this museum.\n",
            "Sentence (Bad): Kathleen was revealing what this actress that can sit down was skated around this museum.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -135.44326782226562, Correct = False\n",
            "  Response 2: Score = -139.48089599609375, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -135.44326782226562, Correct = False\n",
            "  Filtered Response 2: Score = -139.48089599609375, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_wh_vs_that_with_gap_filtered_results.jsonl\n",
            "Sentence (Good): A lady has remembered who the actors conceal.\n",
            "Sentence (Bad): A lady has remembered that the actors conceal.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -84.1434326171875, Correct = False\n",
            "  Response 2: Score = -80.8956298828125, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -84.1434326171875, Correct = False\n",
            "  Filtered Response 2: Score = -80.8956298828125, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Teenagers know what all ladies haven't examined.\n",
            "Sentence (Bad): Teenagers know that all ladies haven't examined.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -90.5377426147461, Correct = False\n",
            "  Response 2: Score = -87.26475524902344, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -90.5377426147461, Correct = False\n",
            "  Filtered Response 2: Score = -87.26475524902344, Correct = False\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_wh_vs_that_with_gap_long_distance_filtered_results.jsonl\n",
            "Sentence (Good): Kayla concealed who a lot of guests that were scaring many people complain about.\n",
            "Sentence (Bad): Kayla concealed that a lot of guests that were scaring many people complain about.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -116.4828872680664, Correct = False\n",
            "  Response 2: Score = -109.46919250488281, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -116.4828872680664, Correct = False\n",
            "  Filtered Response 2: Score = -109.46919250488281, Correct = False\n",
            "========================================\n",
            "Sentence (Good): Martin did find out what every cashier that shouldn't drink wore.\n",
            "Sentence (Bad): Martin did find out that every cashier that shouldn't drink wore.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -107.17111206054688, Correct = False\n",
            "  Response 2: Score = -106.23825073242188, Correct = False\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -107.17111206054688, Correct = False\n",
            "  Filtered Response 2: Score = -106.23825073242188, Correct = False\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process and print ewok samples\n",
        "print(\"\\nProcessing Ewok Tasks\\n\" + \"=\"*60)\n",
        "for subtask_file in os.listdir(ewok_path):\n",
        "    if subtask_file.endswith('.jsonl'):\n",
        "        file_path = os.path.join(ewok_path, subtask_file)\n",
        "        print(f\"\\nSubtask: {subtask_file}\")\n",
        "        samples = load_jsonl_or_json_array(file_path)\n",
        "        print_ewok_samples(samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0OGtYk74j9X",
        "outputId": "8a50f8fd-1356-4849-87d3-0681a4375304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing Ewok Tasks\n",
            "============================================================\n",
            "\n",
            "Subtask: ewok_agent-properties_filtered_results.jsonl\n",
            "Domain: agent-properties\n",
            "Concept A: believe\n",
            "Concept B: doubt\n",
            "Context 1: Ali is in the bakery. Ali sees the candle inside.\n",
            "Context 2: Ali is in the bakery. Ali sees the candle outside.\n",
            "Target 1: Ali believes that the candle is in the bakery.\n",
            "Target 2: Ali doubts that the candle is in the bakery.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -62.393123626708984\n",
            "  Response 2: Score = -70.64193725585938\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -62.393123626708984\n",
            "  Filtered Response 2: Score = -70.64193725585938\n",
            "========================================\n",
            "Domain: agent-properties\n",
            "Concept A: believe\n",
            "Concept B: doubt\n",
            "Context 1: Ali is in the bakery. Ali sees the candle outside.\n",
            "Context 2: Ali is in the bakery. Ali sees the candle inside.\n",
            "Target 1: Ali doubts that the candle is in the bakery.\n",
            "Target 2: Ali believes that the candle is in the bakery.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -71.09725952148438\n",
            "  Response 2: Score = -62.15871047973633\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -71.09725952148438\n",
            "  Filtered Response 2: Score = -62.15871047973633\n",
            "========================================\n",
            "\n",
            "Subtask: ewok_material-dynamics_filtered_results.jsonl\n",
            "Domain: material-dynamics\n",
            "Concept A: break\n",
            "Concept B: drip\n",
            "Context 1: Ali sees something that is rigid.\n",
            "Context 2: Ali sees something that is liquid.\n",
            "Target 1: It breaks.\n",
            "Target 2: It drips.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -35.07166290283203\n",
            "  Response 2: Score = -36.085182189941406\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -35.07166290283203\n",
            "  Filtered Response 2: Score = -36.085182189941406\n",
            "========================================\n",
            "Domain: material-dynamics\n",
            "Concept A: break\n",
            "Concept B: drip\n",
            "Context 1: Ali sees something that is liquid.\n",
            "Context 2: Ali sees something that is rigid.\n",
            "Target 1: It drips.\n",
            "Target 2: It breaks.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -35.097900390625\n",
            "  Response 2: Score = -34.28924560546875\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -35.097900390625\n",
            "  Filtered Response 2: Score = -34.28924560546875\n",
            "========================================\n",
            "\n",
            "Subtask: ewok_material-properties_filtered_results.jsonl\n",
            "Domain: material-properties\n",
            "Concept A: bouncy\n",
            "Concept B: not bouncy\n",
            "Context 1: Ali dropped the volleyball, and saw it jumping off the floor.\n",
            "Context 2: Ali dropped the volleyball, and saw it lying on the floor.\n",
            "Target 1: The volleyball is bouncy.\n",
            "Target 2: The volleyball is not bouncy.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -50.85443878173828\n",
            "  Response 2: Score = -53.19183349609375\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -50.85443878173828\n",
            "  Filtered Response 2: Score = -53.19183349609375\n",
            "========================================\n",
            "Domain: material-properties\n",
            "Concept A: bouncy\n",
            "Concept B: not bouncy\n",
            "Context 1: Ali dropped the volleyball, and saw it lying on the floor.\n",
            "Context 2: Ali dropped the volleyball, and saw it jumping off the floor.\n",
            "Target 1: The volleyball is not bouncy.\n",
            "Target 2: The volleyball is bouncy.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -53.13768768310547\n",
            "  Response 2: Score = -50.74155807495117\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -53.13768768310547\n",
            "  Filtered Response 2: Score = -50.74155807495117\n",
            "========================================\n",
            "\n",
            "Subtask: ewok_physical-dynamics_filtered_results.jsonl\n",
            "Domain: physical-dynamics\n",
            "Concept A: accelerate\n",
            "Concept B: slow down\n",
            "Context 1: The speed of the balloon is increasing.\n",
            "Context 2: The speed of the balloon is decreasing.\n",
            "Target 1: The balloon is accelerating.\n",
            "Target 2: The balloon is slowing down.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -41.028018951416016\n",
            "  Response 2: Score = -45.48561477661133\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -41.028018951416016\n",
            "  Filtered Response 2: Score = -45.48561477661133\n",
            "========================================\n",
            "Domain: physical-dynamics\n",
            "Concept A: accelerate\n",
            "Concept B: slow down\n",
            "Context 1: The speed of the balloon is decreasing.\n",
            "Context 2: The speed of the balloon is increasing.\n",
            "Target 1: The balloon is slowing down.\n",
            "Target 2: The balloon is accelerating.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -46.40997314453125\n",
            "  Response 2: Score = -41.70514678955078\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -46.40997314453125\n",
            "  Filtered Response 2: Score = -41.70514678955078\n",
            "========================================\n",
            "\n",
            "Subtask: ewok_physical-interactions_filtered_results.jsonl\n",
            "Domain: physical-interactions\n",
            "Concept A: attract\n",
            "Concept B: repel\n",
            "Context 1: The magnet is moving closer to the knife.\n",
            "Context 2: The magnet is moving away from the knife.\n",
            "Target 1: The knife is attracting the magnet.\n",
            "Target 2: The knife is repelling the magnet.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -59.96310806274414\n",
            "  Response 2: Score = -65.2157211303711\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -59.96310806274414\n",
            "  Filtered Response 2: Score = -65.2157211303711\n",
            "========================================\n",
            "Domain: physical-interactions\n",
            "Concept A: attract\n",
            "Concept B: repel\n",
            "Context 1: The magnet is moving away from the knife.\n",
            "Context 2: The magnet is moving closer to the knife.\n",
            "Target 1: The knife is repelling the magnet.\n",
            "Target 2: The knife is attracting the magnet.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -63.70286560058594\n",
            "  Response 2: Score = -58.368446350097656\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -63.70286560058594\n",
            "  Filtered Response 2: Score = -58.368446350097656\n",
            "========================================\n",
            "\n",
            "Subtask: ewok_physical-relations_filtered_results.jsonl\n",
            "Domain: physical-relations\n",
            "Concept A: attached\n",
            "Concept B: connected\n",
            "Context 1: The airplane is next to the rock.\n",
            "Context 2: The airplane is some distance away from the rock.\n",
            "Target 1: The airplane is attached to the rock.\n",
            "Target 2: The airplane is connected to the rock.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -55.64527893066406\n",
            "  Response 2: Score = -55.8875732421875\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -55.64527893066406\n",
            "  Filtered Response 2: Score = -55.8875732421875\n",
            "========================================\n",
            "Domain: physical-relations\n",
            "Concept A: attached\n",
            "Concept B: connected\n",
            "Context 1: The airplane is some distance away from the rock.\n",
            "Context 2: The airplane is next to the rock.\n",
            "Target 1: The airplane is connected to the rock.\n",
            "Target 2: The airplane is attached to the rock.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -56.56902313232422\n",
            "  Response 2: Score = -56.73488998413086\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -56.56902313232422\n",
            "  Filtered Response 2: Score = -56.73488998413086\n",
            "========================================\n",
            "\n",
            "Subtask: ewok_quantitative-properties_filtered_results.jsonl\n",
            "Domain: quantitative-properties\n",
            "Concept A: a lot of\n",
            "Concept B: a little\n",
            "Context 1: Ali has a large amount of ketchup.\n",
            "Context 2: Ali has a small amount of ketchup.\n",
            "Target 1: There is a lot of ketchup.\n",
            "Target 2: There is a little ketchup.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -42.73779296875\n",
            "  Response 2: Score = -44.001800537109375\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -42.73779296875\n",
            "  Filtered Response 2: Score = -44.001800537109375\n",
            "========================================\n",
            "Domain: quantitative-properties\n",
            "Concept A: a lot of\n",
            "Concept B: a little\n",
            "Context 1: Ali has a small amount of ketchup.\n",
            "Context 2: Ali has a large amount of ketchup.\n",
            "Target 1: There is a little ketchup.\n",
            "Target 2: There is a lot of ketchup.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -43.74058151245117\n",
            "  Response 2: Score = -42.68455505371094\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -43.74058151245117\n",
            "  Filtered Response 2: Score = -42.68455505371094\n",
            "========================================\n",
            "\n",
            "Subtask: ewok_social-interactions_filtered_results.jsonl\n",
            "Domain: social-interactions\n",
            "Concept A: cooperate\n",
            "Concept B: compete\n",
            "Context 1: Ali and Wei are helping each other.\n",
            "Context 2: Ali and Wei are hindering each other.\n",
            "Target 1: Ali is cooperating with Wei.\n",
            "Target 2: Ali is competing with Wei.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -65.144775390625\n",
            "  Response 2: Score = -65.2049560546875\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -65.144775390625\n",
            "  Filtered Response 2: Score = -65.2049560546875\n",
            "========================================\n",
            "Domain: social-interactions\n",
            "Concept A: cooperate\n",
            "Concept B: compete\n",
            "Context 1: Ali and Wei are hindering each other.\n",
            "Context 2: Ali and Wei are helping each other.\n",
            "Target 1: Ali is competing with Wei.\n",
            "Target 2: Ali is cooperating with Wei.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -66.35945129394531\n",
            "  Response 2: Score = -66.02223205566406\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -66.35945129394531\n",
            "  Filtered Response 2: Score = -66.02223205566406\n",
            "========================================\n",
            "\n",
            "Subtask: ewok_social-properties_filtered_results.jsonl\n",
            "Domain: social-properties\n",
            "Concept A: boastful\n",
            "Concept B: humble\n",
            "Context 1: Ali talks a lot about past accomplishments.\n",
            "Context 2: Ali talks little about past accomplishments.\n",
            "Target 1: Ali is boastful.\n",
            "Target 2: Ali is humble.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -38.97566223144531\n",
            "  Response 2: Score = -35.173343658447266\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -38.97566223144531\n",
            "  Filtered Response 2: Score = -35.173343658447266\n",
            "========================================\n",
            "Domain: social-properties\n",
            "Concept A: boastful\n",
            "Concept B: humble\n",
            "Context 1: Ali talks little about past accomplishments.\n",
            "Context 2: Ali talks a lot about past accomplishments.\n",
            "Target 1: Ali is humble.\n",
            "Target 2: Ali is boastful.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -35.75983810424805\n",
            "  Response 2: Score = -39.922550201416016\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -35.75983810424805\n",
            "  Filtered Response 2: Score = -39.922550201416016\n",
            "========================================\n",
            "\n",
            "Subtask: ewok_social-relations_filtered_results.jsonl\n",
            "Domain: social-relations\n",
            "Concept A: boss\n",
            "Concept B: subordinate\n",
            "Context 1: Ali gives orders to Wei.\n",
            "Context 2: Ali gets orders from Wei.\n",
            "Target 1: Ali is Wei's boss.\n",
            "Target 2: Ali is Wei's subordinate.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -64.763916015625\n",
            "  Response 2: Score = -71.17218017578125\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -64.763916015625\n",
            "  Filtered Response 2: Score = -71.17218017578125\n",
            "========================================\n",
            "Domain: social-relations\n",
            "Concept A: boss\n",
            "Concept B: subordinate\n",
            "Context 1: Ali gets orders from Wei.\n",
            "Context 2: Ali gives orders to Wei.\n",
            "Target 1: Ali is Wei's subordinate.\n",
            "Target 2: Ali is Wei's boss.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -71.93540954589844\n",
            "  Response 2: Score = -65.98991394042969\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -71.93540954589844\n",
            "  Filtered Response 2: Score = -65.98991394042969\n",
            "========================================\n",
            "\n",
            "Subtask: ewok_spatial-relations_filtered_results.jsonl\n",
            "Domain: spatial-relations\n",
            "Concept A: above\n",
            "Concept B: below\n",
            "Context 1: The baseball is below the candle.\n",
            "Context 2: The baseball is above the candle.\n",
            "Target 1: The candle is above the baseball.\n",
            "Target 2: The candle is below the baseball.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -58.64951705932617\n",
            "  Response 2: Score = -60.57783889770508\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -58.64951705932617\n",
            "  Filtered Response 2: Score = -60.57783889770508\n",
            "========================================\n",
            "Domain: spatial-relations\n",
            "Concept A: above\n",
            "Concept B: below\n",
            "Context 1: The baseball is above the candle.\n",
            "Context 2: The baseball is below the candle.\n",
            "Target 1: The candle is below the baseball.\n",
            "Target 2: The candle is above the baseball.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -59.31181335449219\n",
            "  Response 2: Score = -56.99898910522461\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -59.31181335449219\n",
            "  Filtered Response 2: Score = -56.99898910522461\n",
            "========================================\n"
          ]
        }
      ]
    }
  ]
}