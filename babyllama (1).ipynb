{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfHw1Okct5hG",
        "outputId": "6816cf2b-2707-48d1-80de-8d8730455bab",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.26.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (17.0.0)\n",
            "Collecting pyarrow\n",
            "  Downloading pyarrow-18.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Downloading pyarrow-18.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyarrow\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 17.0.0\n",
            "    Uninstalling pyarrow-17.0.0:\n",
            "      Successfully uninstalled pyarrow-17.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.10.1 requires pyarrow<18.0.0a0,>=14.0.0, but you have pyarrow 18.1.0 which is incompatible.\n",
            "pylibcudf-cu12 24.10.1 requires pyarrow<18.0.0a0,>=14.0.0, but you have pyarrow 18.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pyarrow-18.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install huggingface_hub\n",
        "!pip install --upgrade pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogb8XzUduDqn"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "import re\n",
        "from transformers import GPT2Tokenizer\n",
        "from transformers import GPT2Config, GPT2LMHeadModel\n",
        "import torch\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from huggingface_hub import notebook_login\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import subprocess\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## preprocessing"
      ],
      "metadata": {
        "id": "e2vVtD4wo637"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3kJ6PNluMGc",
        "outputId": "e74d4233-607b-48e9-ee0c-4749fef42944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Dad.\n",
            "- We're going right now, Martin, very far away\n",
            "(MARTIN PANTING)\n",
            "George, why are you waiting? \n",
            "Let's go.\n",
            "He's still in here.\n",
            "Peter, he's still here.\n",
            "Get the boy out of this house.\n",
            "Out of this house!\n",
            "Dad, I'm cold.\n",
            "George, I beg of you, let's go!\n",
            "I'm not finished, Peter.\n",
            "It's not over yet.\n",
            "Where's Mom and Carole?\n",
            "They're in a safe place.\n",
            "Martin?\n",
            "(SCREAMING)\n",
            "(CACKLING)\n",
            "(CACKLING)\n",
            "Peter.\n",
            "(DRAMATIC MUSIC PLAYING)\n",
            "(MUFFLED GHOSTLY VOICES)\n",
            "(DOOR CREAKS SHUT)\n",
            "Martin.\n",
            "(ELECTRICITY BUZZING)\n",
            "BETTE: \n"
          ]
        }
      ],
      "source": [
        "\n",
        "def preprocess_text(data):\n",
        "    # Step 1: Remove text within parentheses\n",
        "    data = re.sub(r'\\([^)]*\\)', '', data)\n",
        "\n",
        "    # Step 2: Remove all-uppercase words (likely sound effects)\n",
        "    data = re.sub(r'\\b[A-Z]+\\b', '', data)\n",
        "\n",
        "    # Step 3: Convert to lowercase\n",
        "    data = data.lower()\n",
        "\n",
        "    # Step 4: Normalize spaces\n",
        "    data = re.sub(r'\\s+', ' ', data).strip()\n",
        "\n",
        "    return data\n",
        "\n",
        "# Load the data\n",
        "file_path = '/content/drive/MyDrive/data/text_data.zip (Unzipped Files)/train_100M/open_subtitles.train'\n",
        "\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    raw_data = file.read()\n",
        "\n",
        "# Apply preprocessing\n",
        "cleaned_data = preprocess_text(raw_data)\n",
        "\n",
        "# Display a sample of the cleaned data\n",
        "print(raw_data[:500])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Subtitle Length Distribution\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "subtitles = raw_data.split('\\n')\n",
        "subtitle_lengths = [len(subtitle.split()) for subtitle in subtitles if subtitle.strip()]  # Token count per subtitle\n",
        "\n",
        "\n",
        "plt.hist(subtitle_lengths, bins=50, alpha=0.75, edgecolor='black')\n",
        "plt.title('Subtitle Length Distribution')\n",
        "plt.xlabel('Number of words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Calculate and display statistics for subtitle lengths\n",
        "mean_length = np.mean(subtitle_lengths)\n",
        "median_length = np.median(subtitle_lengths)\n",
        "max_length = np.max(subtitle_lengths)\n",
        "min_length = np.min(subtitle_lengths)\n",
        "\n",
        "print(f\"Mean Length: {mean_length}\")\n",
        "print(f\"Median Length: {median_length}\")\n",
        "print(f\"Max Length: {max_length}\")\n",
        "print(f\"Min Length: {min_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "NhG4zAtNRR5T",
        "outputId": "87525230-d840-4eae-97b0-020f010358fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Length: 5.718180401619402\n",
            "Median Length: 5.0\n",
            "Max Length: 124\n",
            "Min Length: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Analyze a sample of cleaned data\n",
        "sample_data = cleaned_data[:100000]\n",
        "doc = nlp(sample_data)\n",
        "\n",
        "# Sentence Structure Analysis\n",
        "pos_tags = [token.pos_ for token in doc]\n",
        "pos_counts = Counter(pos_tags)\n",
        "print(\"POS Tag Distribution:\", pos_counts)\n",
        "\n",
        "# Plot POS Tag Distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(pos_counts.keys(), pos_counts.values())\n",
        "plt.title(\"Part-of-Speech Tag Distribution\")\n",
        "plt.xlabel(\"POS Tag\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# Tense Analysis\n",
        "verb_tenses = []\n",
        "for token in doc:\n",
        "    if token.pos_ == \"VERB\":\n",
        "        tense = token.morph.get(\"Tense\")\n",
        "        if tense:\n",
        "            verb_tenses.extend(tense)\n",
        "\n",
        "tense_counts = Counter(verb_tenses)\n",
        "print(\"Tense Distribution:\", tense_counts)\n",
        "\n",
        "# Plot Tense Distribution\n",
        "plt.bar(tense_counts.keys(), tense_counts.values())\n",
        "plt.title(\"Tense Distribution\")\n",
        "plt.xlabel(\"Tense\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n",
        "\n",
        "# Colloquial Expression Analysis\n",
        "colloquialisms = [token.text for token in doc if token.text.lower() in {\"gonna\", \"wanna\", \"y'all\", \"ain't\"}]\n",
        "print(\"Colloquial Expressions Found:\", Counter(colloquialisms))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Cf_thmWyabhJ",
        "outputId": "faf58c2d-98af-40b3-90b1-a4dd6d143612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS Tag Distribution: Counter({'PUNCT': 4583, 'PRON': 3276, 'VERB': 3129, 'NOUN': 3048, 'AUX': 1912, 'ADP': 1559, 'DET': 1433, 'ADV': 999, 'PROPN': 984, 'ADJ': 969, 'PART': 863, 'CCONJ': 365, 'SCONJ': 339, 'INTJ': 306, 'NUM': 267, 'X': 86, 'SYM': 16})\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tense Distribution: Counter({'Pres': 944, 'Past': 801})\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colloquial Expressions Found: Counter({'wanna': 3})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tokenization"
      ],
      "metadata": {
        "id": "ifzgjbL8o_ig"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLCOn5KVwOCs",
        "outputId": "2c34cb7e-3787-4fc1-ad98-43dc3d4da574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"babylm/babyllama-100m-2024\")\n",
        "\n",
        "# Load the model configuration without pretrained weights\n",
        "config = AutoConfig.from_pretrained(\"babylm/babyllama-100m-2024\")\n",
        "model = AutoModelForCausalLM.from_config(config)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config._attn_implementation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "a5BDxO-kemJ7",
        "outputId": "258462e0-104d-4ff9-a86f-14fd9ba1d12e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eager'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_L6Gjbu8M1i",
        "outputId": "937f25bb-675f-4760-ad01-b95b341d6f4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaConfig {\n",
              "  \"_name_or_path\": \"babylm/babyllama-100m-2024\",\n",
              "  \"architectures\": [\n",
              "    \"LlamaForCausalLM\"\n",
              "  ],\n",
              "  \"attention_bias\": false,\n",
              "  \"attention_dropout\": 0.0,\n",
              "  \"bos_token_id\": 1,\n",
              "  \"eos_token_id\": 2,\n",
              "  \"head_dim\": 64,\n",
              "  \"hidden_act\": \"silu\",\n",
              "  \"hidden_size\": 512,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 1024,\n",
              "  \"max_position_embeddings\": 256,\n",
              "  \"mlp_bias\": false,\n",
              "  \"model_type\": \"llama\",\n",
              "  \"num_attention_heads\": 8,\n",
              "  \"num_hidden_layers\": 16,\n",
              "  \"num_key_value_heads\": 8,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"pretraining_tp\": 1,\n",
              "  \"rms_norm_eps\": 1e-06,\n",
              "  \"rope_scaling\": null,\n",
              "  \"rope_theta\": 10000.0,\n",
              "  \"tie_word_embeddings\": false,\n",
              "  \"torch_dtype\": \"float32\",\n",
              "  \"transformers_version\": \"4.46.2\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 16000\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oygPNREM4sSF",
        "outputId": "10d9f01a-d5fd-4714-b707-71b580e576d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "babyllama size: 58.3M parameters\n",
            "Maximum input size for the model: 256\n",
            "LlamaForCausalLM(\n",
            "  (model): LlamaModel(\n",
            "    (embed_tokens): Embedding(16000, 512, padding_idx=0)\n",
            "    (layers): ModuleList(\n",
            "      (0-15): 16 x LlamaDecoderLayer(\n",
            "        (self_attn): LlamaSdpaAttention(\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (o_proj): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (rotary_emb): LlamaRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): LlamaMLP(\n",
            "          (gate_proj): Linear(in_features=512, out_features=1024, bias=False)\n",
            "          (up_proj): Linear(in_features=512, out_features=1024, bias=False)\n",
            "          (down_proj): Linear(in_features=1024, out_features=512, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): LlamaRMSNorm((512,), eps=1e-06)\n",
            "        (post_attention_layernorm): LlamaRMSNorm((512,), eps=1e-06)\n",
            "      )\n",
            "    )\n",
            "    (norm): LlamaRMSNorm((512,), eps=1e-06)\n",
            "    (rotary_emb): LlamaRotaryEmbedding()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=512, out_features=16000, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Print the model size\n",
        "model_size = sum(t.numel() for t in model.parameters())\n",
        "print(f\"babyllama size: {model_size/1000**2:.1f}M parameters\")\n",
        "# Check the maximum sequence length\n",
        "print(f\"Maximum input size for the model: {config.max_position_embeddings}\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c7YWIsQ1eyD",
        "outputId": "7a0b7aa5-2646-49b9-c6a1-9d5fc5d9aeac",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   15,  2280,    16,   338,   261,   411,   537,   466,   471,    14,\n",
            "          9794,   193,    14,   557,  1039,   751,  3950, 15690,    14,   744,\n",
            "           329,   220,  2481,    33,   585,   243,   314,    16,   239,   243,\n",
            "           854,   237,   427,    16,   225,  1321,    14,   239,   243,   854,\n",
            "           427,    16,   401,   196,   875,   390,   235,   321,   824,    16,\n",
            "           390,   235,   321,   824,     3,  2280,    14,   539,    79,  1852,\n",
            "            16,  3950, 15690,    14,  1003,   235,   220,    14,   585,   243,\n",
            "           314,     3,   539,    79,   320,  2039,    14,   225,  1321,    16,\n",
            "          1708,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [   86,   243,   320,   551,  1254,    16,   515,   243,   866,   231,\n",
            "           652,  1444,    33,   337,   411,   237,   192,  2531,   961,    16,\n",
            "          9794,   193,    33,   225,  1321,    16,  9794,   193,    16, 11061,\n",
            "           544,    14,  1968,    14,  3950, 15690,    16,  3411,   220,    14,\n",
            "           237,   196,   911,   235,   196,  6483,   367,  2773,   365, 10217,\n",
            "           217,   365,  4360,    16,   220,   540,   880,  1156,   387,  5995,\n",
            "           302,   519,   373,   321,   548,    16,   231,   285,   307,    33,\n",
            "           220,   154,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [   89,   347,   217,   416,    14,   220,   462,   217,  1592,    16,\n",
            "           539,    79,   427,   217,   855,   220,    16,   387,   657,    14,\n",
            "           220,   838,  1590,   291,    16,  8383,  5127,   365,  3159,   231,\n",
            "          1443,  1476,  1716,    16,  1443,  1476,   658,  1288,    16,  6483,\n",
            "           354,   223,   256,    14,   835,   302,   196,  4490,   217,  6524,\n",
            "            16,   373,   220,   326,   217,   276,   260,  4335,   248,   581,\n",
            "           278,   231,   248,   795,   512,   258,  1607,   217,   196,  3019,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [12773,   235,  1452,    16,   345,  4448,   260,  1597, 13864,  1789,\n",
            "            16,   480,   220, 15055,   486,    14,   220,   512,   326, 12148,\n",
            "          4074,  5783,   425,    16,   220,   512,   258,   192,  7003,   217,\n",
            "          5358,    16,  1840,  8150,   454,   512,   416,   830,   330,  2691,\n",
            "           967,   550,  1081,  1183,    16,   220,   512,  1592,   196,  7630,\n",
            "           524,   235,  1006,   231,  1796,    16,   307,   329,   220,   154,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [14856,   213,   285,    33,  4335,   248,   581,   278,    16,   480,\n",
            "           220,  4335,   248,   581,   278,    14,  3950, 15690,    14,   220,\n",
            "           512,   326,   196,  8419,   220,  3855,   285,    16,   330,     3,\n",
            "          1475,   217,  1452,    16,  3411,   220,    14, 13864,    80,   220,\n",
            "           237,   196,   911,   235,   354,   223,   256,  8979,    14,   692,\n",
            "          6483,    16,  9794,   193,    16,   261,   540,   447,   217,  4101,\n",
            "            14,   401,   751,   413,   427,    16,   362,   272,   585,   440,\n",
            "          4893,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0]])\n"
          ]
        }
      ],
      "source": [
        "# Tokenize the data\n",
        "\n",
        "max_length = 256\n",
        "input_texts = [cleaned_data[i:i+max_length] for i in range(0, len(cleaned_data), max_length)]\n",
        "\n",
        "# Apply the tokenizer to each chunk\n",
        "tokenized_data = tokenizer(input_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# Display a sample of tokenized data\n",
        "print(tokenized_data[\"input_ids\"][:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpmADSvI7Lfe"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "dataset = Dataset.from_dict(tokenized_data)\n",
        "\n",
        "# Splitting the dataset into train and test sets\n",
        "train_test_split = dataset.train_test_split(test_size=0.1)\n",
        "train_dataset = train_test_split['train']\n",
        "test_dataset = train_test_split['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxdxSW084-zQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cN_b7LXS5MIp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "XT_fg0DxpHFs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "800f7e81fd5a4f0da26be8bd1ca04e76",
            "a7d073b4e0814af19d97bf5c8910ff7a",
            "92f3c9bbd7104e43bd1f9e94184f0c2c",
            "d143f2d43a09432485242b9acf7ff298",
            "736f1ac1122c45359837461f453cc450",
            "4cc18c895a5e4f8990055aa333c2e703",
            "6c9443fe9b9645d782860495bb788f33",
            "a938e227e7ad426e9549c2bb135bf208",
            "28e90b8800784b1a945807016c5f6e76",
            "2d36c46da9434f4abca468002f3cf107",
            "9d7f19c4ed24427f940150e7df564baa",
            "444f1ee5626742c6b62092e97f43dad0",
            "d1fd7faa8c224ca29459277f4d7e927a",
            "b4408ae9e5324e4aa74abeaf3a4c50b3",
            "7e787def179a4f3aab09e49b1f800ed6",
            "f20757e38c57446db4022ed2cba5afd5",
            "2612db66d16d49e095e02502205b224c",
            "214610c284534e75abd424dec12bf4e7",
            "59757a1390934b92b2917e61dd3382a8",
            "ed8c814f6b344b818817a4025d3567f1",
            "5280d294d81047469d55a6db353ee2b6",
            "862436529e4341499c5b5a173a9d26bb",
            "16fd2be83c6741d99bf8fb55996f366d",
            "89b25bf9c5d54e7fa1870b015830802f",
            "573d206df27940d5aced2c17d4f7bed5",
            "30db22f2f9d84a9cacc2671075493a7f",
            "9da301dd2f984aca9cf67ee3723fef8d",
            "8a143c24b7d04cdcbb62ad45dc724ad7",
            "1ce76d26d6714498b7a3a4294e9c0b6b",
            "0e0f6cd89c4e4eeaaf5c771ee2bb5ac7",
            "337ba98e152b45669a99999c519b8591",
            "f20bb026676d4eb181584f44ce6b5071"
          ]
        },
        "id": "WHO8y9Ne-EZa",
        "outputId": "3063d23f-0301-459f-89f9-1279de3d3589"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "800f7e81fd5a4f0da26be8bd1ca04e76"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554,
          "referenced_widgets": [
            "0a8310f95a3845089e3b963371e9c5fc",
            "3ad9bdb5e67b44f4bdc109087d55b68a",
            "51fe802be83a43fcaaec3ae04dc991e8",
            "c935b720382d4a4cbe682bf92bc820b6",
            "0ffc16e45f814d8dbaf562ae09aaa158",
            "0947e7fc3575485085f427f086d6f737",
            "1cac48fce61144db8caa79baf043dcea",
            "5795c850cf2b4e65b9293ce2c84bf94d",
            "9cea12baec374ea48f88f2d6a4e371a7",
            "2caace1316db4adcbf1c3fec17a0ae65",
            "1a3110f4d2664a3ba93e0bf04c97821f"
          ]
        },
        "id": "s9ic1ZXix212",
        "outputId": "96c1147e-aeb3-417d-b452-67cb29a71336"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241105_155241-o78svbg4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/harshatheeswarsai99-city-university-of-london/huggingface/runs/o78svbg4' target=\"_blank\">Harshatheeswar</a></strong> to <a href='https://wandb.ai/harshatheeswarsai99-city-university-of-london/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/harshatheeswarsai99-city-university-of-london/huggingface' target=\"_blank\">https://wandb.ai/harshatheeswarsai99-city-university-of-london/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/harshatheeswarsai99-city-university-of-london/huggingface/runs/o78svbg4' target=\"_blank\">https://wandb.ai/harshatheeswarsai99-city-university-of-london/huggingface/runs/o78svbg4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27795' max='27795' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27795/27795 4:09:57, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.303800</td>\n",
              "      <td>4.316248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.049500</td>\n",
              "      <td>4.065654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.889400</td>\n",
              "      <td>3.957891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.730000</td>\n",
              "      <td>3.914025</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "events.out.tfevents.1730821957.c6e2ac2101d4.6774.0:   0%|          | 0.00/598k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a8310f95a3845089e3b963371e9c5fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Harshatheeswar/babylama-scratch/commit/cad59ecb2e467b27c10b9e03c8131995f218fc53', commit_message='End of training', commit_description='', oid='cad59ecb2e467b27c10b9e03c8131995f218fc53', pr_url=None, pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='Harshatheeswar',\n",
        "    hub_model_id='babylama-scratch',\n",
        "    evaluation_strategy='epoch',\n",
        "    auto_find_batch_size=True,\n",
        "    num_train_epochs=5,\n",
        "    gradient_accumulation_steps=8,\n",
        "    weight_decay=0.1,\n",
        "    lr_scheduler_type='cosine',\n",
        "    learning_rate=5e-5,\n",
        "    fp16=True,\n",
        "    push_to_hub=True,\n",
        "    logging_steps=10\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Push the trained model to the Hugging Face Hub\n",
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## evaluation"
      ],
      "metadata": {
        "id": "eFDJXyE4pL02"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0M7FBlj5YsP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6df7c89d-71c4-4ab7-96e3-90ed2ae101a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "Cloning into 'new_evaluation_pipeline'...\n",
            "remote: Enumerating objects: 26187, done.\u001b[K\n",
            "remote: Total 26187 (delta 0), reused 0 (delta 0), pack-reused 26187 (from 1)\u001b[K\n",
            "Receiving objects: 100% (26187/26187), 51.28 MiB | 19.24 MiB/s, done.\n",
            "Resolving deltas: 100% (17625/17625), done.\n",
            "Updating files: 100% (3329/3329), done.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "%cd /content/drive/MyDrive/\n",
        "\n",
        "!git clone https://github.com/babylm/evaluation-pipeline-2024 new_evaluation_pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLYokxHU5YoW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ebcabb5-553e-4850-8b98-850c7f3d0a7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/new_evaluation_pipeline\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/new_evaluation_pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YO2RXuEW5YmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f45ede2-4534-4d31-d400-0e241f07284a",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "-e option requires 1 argument\n",
            "Collecting minicons\n",
            "  Downloading minicons-0.2.50-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: accelerate>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from minicons) (0.34.2)\n",
            "Collecting openai<0.29.0,>=0.28.0 (from minicons)\n",
            "  Downloading openai-0.28.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pandas==2.2.0 (from minicons)\n",
            "  Downloading pandas-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: pillow<11.0.0,>=10.2.0 in /usr/local/lib/python3.10/dist-packages (from minicons) (10.4.0)\n",
            "Collecting tenacity<9.0.0,>=8.2.3 (from minicons)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from minicons) (2.5.0+cu121)\n",
            "Requirement already satisfied: transformers>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from minicons) (4.44.2)\n",
            "Collecting urllib3<2.0.0,>=1.26.7 (from minicons)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wonderwords<3.0.0,>=2.2.0 (from minicons)\n",
            "  Downloading wonderwords-2.2.0-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.0->minicons) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.0->minicons) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.0->minicons) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.0->minicons) (2024.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.25.0->minicons) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.25.0->minicons) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.25.0->minicons) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.25.0->minicons) (0.24.7)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.25.0->minicons) (0.4.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai<0.29.0,>=0.28.0->minicons) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai<0.29.0,>=0.28.0->minicons) (4.66.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai<0.29.0,>=0.28.0->minicons) (3.10.10)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->minicons) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->minicons) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->minicons) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->minicons) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->minicons) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->minicons) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3.0.0,>=2.0.0->minicons) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->minicons) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->minicons) (0.19.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.0->minicons) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<0.29.0,>=0.28.0->minicons) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<0.29.0,>=0.28.0->minicons) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<0.29.0,>=0.28.0->minicons) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.29.0,>=0.28.0->minicons) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.29.0,>=0.28.0->minicons) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.29.0,>=0.28.0->minicons) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.29.0,>=0.28.0->minicons) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.29.0,>=0.28.0->minicons) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.29.0,>=0.28.0->minicons) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.29.0,>=0.28.0->minicons) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0.0,>=2.0.0->minicons) (3.0.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->openai<0.29.0,>=0.28.0->minicons) (0.2.0)\n",
            "Downloading minicons-0.2.50-py3-none-any.whl (35 kB)\n",
            "Downloading pandas-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m125.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wonderwords-2.2.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wonderwords, urllib3, tenacity, pandas, openai, minicons\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.2.3\n",
            "    Uninstalling urllib3-2.2.3:\n",
            "      Successfully uninstalled urllib3-2.2.3\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.52.2\n",
            "    Uninstalling openai-1.52.2:\n",
            "      Successfully uninstalled openai-1.52.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed minicons-0.2.50 openai-0.28.1 pandas-2.2.0 tenacity-8.5.0 urllib3-1.26.20 wonderwords-2.2.0\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-1.1.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.24.7)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
            "Downloading accelerate-1.1.0-py3-none-any.whl (333 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.2/333.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.34.2\n",
            "    Uninstalling accelerate-0.34.2:\n",
            "      Successfully uninstalled accelerate-0.34.2\n",
            "Successfully installed accelerate-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -e\n",
        "!pip install minicons\n",
        "!pip install --upgrade accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4DfFvbA5YkN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8970857-5f25-4535-dddc-a6d6d329e860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdpabTt65Yh2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc0d9999-fe82-4596-aa4a-85e50a728724"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/new_evaluation_pipeline/ewok/dl_and_filter.py\", line 18, in <module>\n",
            "    dataset = load_dataset(\"ewok-core/ewok-core-1.0\", split=\"test\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 2132, in load_dataset\n",
            "    builder_instance = load_dataset_builder(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 1853, in load_dataset_builder\n",
            "    dataset_module = dataset_module_factory(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 1717, in dataset_module_factory\n",
            "    raise e1 from None\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 1701, in dataset_module_factory\n",
            "    raise DatasetNotFoundError(message) from e\n",
            "datasets.exceptions.DatasetNotFoundError: Dataset 'ewok-core/ewok-core-1.0' is a gated dataset on the Hub. You must be authenticated to access it.\n"
          ]
        }
      ],
      "source": [
        "!python ewok/dl_and_filter.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BhvE0S1-2xo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa79c13e-13be-4ec7-f219-e7a526efd396",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.4.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2.10.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.9.11)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.26.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (5.3.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libnvinfer8 is already the newest version (8.6.1.6-1+cuda12.0).\n",
            "libnvinfer-plugin8 is already the newest version (8.6.1.6-1+cuda12.0).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libnvonnxparsers8 is already the newest version (8.6.1.6-1+cuda12.0).\n",
            "libnvparsers8 is already the newest version (8.6.1.6-1+cuda12.0).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Requirement already satisfied: sqlitedict in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.5.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.6)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (1.1.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2024.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\n",
            "Requirement already satisfied: pytablewriter in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter) (75.1.0)\n",
            "Requirement already satisfied: DataProperty<2,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pytablewriter) (1.0.1)\n",
            "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter) (1.1.3)\n",
            "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter) (3.2.1)\n",
            "Requirement already satisfied: tabledata<2,>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from pytablewriter) (1.3.3)\n",
            "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from pytablewriter) (0.1.6)\n",
            "Requirement already satisfied: typepy<2,>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter) (1.3.2)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter) (5.2.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter) (2024.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter) (24.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.8.0->typepy[datetime]<2,>=1.3.2->pytablewriter) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate\n",
        "!pip install sacrebleu\n",
        "!apt-get install -y libnvinfer8 libnvinfer-plugin8\n",
        "!apt-get install -y libnvparsers8 libnvonnxparsers8\n",
        "!pip install sqlitedict\n",
        "!pip install peft\n",
        "!pip install pytablewriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHgd3LP7-2vo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e72639e-e5f8-4136-bddf-75dcc59b49e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-06 00:17:55.497356: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-06 00:17:55.511729: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-06 00:17:55.515778: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-06 00:17:55.525968: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-06:00:18:00,163 INFO     [__main__.py:263] Verbosity set to INFO\n",
            "2024-11-06:00:18:18,788 INFO     [__main__.py:349] Selected Tasks: ['blimp_filtered', 'blimp_supplement']\n",
            "pretrained=Harshatheeswar/babylama-scratch,backend=causal\n",
            "2024-11-06:00:18:18,794 INFO     [evaluator.py:133] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-11-06:00:18:18,794 INFO     [evaluator.py:181] Initializing hf model, with arguments: {'pretrained': 'Harshatheeswar/babylama-scratch', 'backend': 'causal'}\n",
            "2024-11-06:00:18:18,800 INFO     [huggingface.py:204] Device not specified\n",
            "2024-11-06:00:18:18,800 INFO     [huggingface.py:205] Cuda Available? False\n",
            "2024-11-06:00:18:19,006 INFO     [huggingface.py:489] Overrode HF model backend type, and using type 'causal'\n",
            "2024-11-06:00:18:19,965 WARNING  [task.py:788] [Task: blimp_adjunct_island_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:19,965 WARNING  [task.py:800] [Task: blimp_adjunct_island_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 928 examples [00:00, 106417.16 examples/s]\n",
            "2024-11-06:00:18:21,556 WARNING  [task.py:788] [Task: blimp_anaphor_gender_agreement_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:21,556 WARNING  [task.py:800] [Task: blimp_anaphor_gender_agreement_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 971 examples [00:00, 120933.25 examples/s]\n",
            "2024-11-06:00:18:22,694 WARNING  [task.py:788] [Task: blimp_anaphor_number_agreement_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:22,694 WARNING  [task.py:800] [Task: blimp_anaphor_number_agreement_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 931 examples [00:00, 123171.21 examples/s]\n",
            "2024-11-06:00:18:23,994 WARNING  [task.py:788] [Task: blimp_animate_subject_passive_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:23,995 WARNING  [task.py:800] [Task: blimp_animate_subject_passive_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 895 examples [00:00, 109153.62 examples/s]\n",
            "2024-11-06:00:18:25,202 WARNING  [task.py:788] [Task: blimp_animate_subject_trans_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:25,202 WARNING  [task.py:800] [Task: blimp_animate_subject_trans_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 923 examples [00:00, 131432.44 examples/s]\n",
            "2024-11-06:00:18:26,264 WARNING  [task.py:788] [Task: blimp_causative_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:26,264 WARNING  [task.py:800] [Task: blimp_causative_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 818 examples [00:00, 109688.31 examples/s]\n",
            "2024-11-06:00:18:27,342 WARNING  [task.py:788] [Task: blimp_complex_NP_island_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:27,342 WARNING  [task.py:800] [Task: blimp_complex_NP_island_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 846 examples [00:00, 102161.67 examples/s]\n",
            "2024-11-06:00:18:28,435 WARNING  [task.py:788] [Task: blimp_coordinate_structure_constraint_complex_left_branch_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:28,436 WARNING  [task.py:800] [Task: blimp_coordinate_structure_constraint_complex_left_branch_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 906 examples [00:00, 145835.65 examples/s]\n",
            "2024-11-06:00:18:29,524 WARNING  [task.py:788] [Task: blimp_coordinate_structure_constraint_object_extraction_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:29,524 WARNING  [task.py:800] [Task: blimp_coordinate_structure_constraint_object_extraction_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 949 examples [00:00, 149179.02 examples/s]\n",
            "2024-11-06:00:18:30,594 WARNING  [task.py:788] [Task: blimp_determiner_noun_agreement_1_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:30,594 WARNING  [task.py:800] [Task: blimp_determiner_noun_agreement_1_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 929 examples [00:00, 120586.40 examples/s]\n",
            "2024-11-06:00:18:31,726 WARNING  [task.py:788] [Task: blimp_determiner_noun_agreement_2_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:31,726 WARNING  [task.py:800] [Task: blimp_determiner_noun_agreement_2_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 931 examples [00:00, 154045.41 examples/s]\n",
            "2024-11-06:00:18:33,146 WARNING  [task.py:788] [Task: blimp_determiner_noun_agreement_irregular_1_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:33,146 WARNING  [task.py:800] [Task: blimp_determiner_noun_agreement_irregular_1_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 681 examples [00:00, 105290.51 examples/s]\n",
            "2024-11-06:00:18:34,195 WARNING  [task.py:788] [Task: blimp_determiner_noun_agreement_irregular_2_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:34,195 WARNING  [task.py:800] [Task: blimp_determiner_noun_agreement_irregular_2_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 820 examples [00:00, 125381.11 examples/s]\n",
            "2024-11-06:00:18:35,294 WARNING  [task.py:788] [Task: blimp_determiner_noun_agreement_with_adj_2_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:35,294 WARNING  [task.py:800] [Task: blimp_determiner_noun_agreement_with_adj_2_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 941 examples [00:00, 133596.45 examples/s]\n",
            "2024-11-06:00:18:36,371 WARNING  [task.py:788] [Task: blimp_determiner_noun_agreement_with_adj_irregular_1_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:36,372 WARNING  [task.py:800] [Task: blimp_determiner_noun_agreement_with_adj_irregular_1_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 718 examples [00:00, 104002.98 examples/s]\n",
            "2024-11-06:00:18:37,438 WARNING  [task.py:788] [Task: blimp_determiner_noun_agreement_with_adj_irregular_2_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:37,438 WARNING  [task.py:800] [Task: blimp_determiner_noun_agreement_with_adj_irregular_2_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 840 examples [00:00, 116185.71 examples/s]\n",
            "2024-11-06:00:18:38,538 WARNING  [task.py:788] [Task: blimp_determiner_noun_agreement_with_adjective_1_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:38,539 WARNING  [task.py:800] [Task: blimp_determiner_noun_agreement_with_adjective_1_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 933 examples [00:00, 112444.27 examples/s]\n",
            "2024-11-06:00:18:39,743 WARNING  [task.py:788] [Task: blimp_distractor_agreement_relational_noun_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:39,743 WARNING  [task.py:800] [Task: blimp_distractor_agreement_relational_noun_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 788 examples [00:00, 133750.62 examples/s]\n",
            "2024-11-06:00:18:40,810 WARNING  [task.py:788] [Task: blimp_distractor_agreement_relative_clause_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:40,810 WARNING  [task.py:800] [Task: blimp_distractor_agreement_relative_clause_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 871 examples [00:00, 118162.78 examples/s]\n",
            "2024-11-06:00:18:41,960 WARNING  [task.py:788] [Task: blimp_drop_argument_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:41,960 WARNING  [task.py:800] [Task: blimp_drop_argument_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 920 examples [00:00, 143726.15 examples/s]\n",
            "2024-11-06:00:18:43,025 WARNING  [task.py:788] [Task: blimp_ellipsis_n_bar_1_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:43,025 WARNING  [task.py:800] [Task: blimp_ellipsis_n_bar_1_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 802 examples [00:00, 100575.01 examples/s]\n",
            "2024-11-06:00:18:44,105 WARNING  [task.py:788] [Task: blimp_ellipsis_n_bar_2_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:44,106 WARNING  [task.py:800] [Task: blimp_ellipsis_n_bar_2_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 828 examples [00:00, 115133.39 examples/s]\n",
            "2024-11-06:00:18:45,155 WARNING  [task.py:788] [Task: blimp_existential_there_object_raising_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:45,155 WARNING  [task.py:800] [Task: blimp_existential_there_object_raising_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 812 examples [00:00, 111928.97 examples/s]\n",
            "2024-11-06:00:18:46,219 WARNING  [task.py:788] [Task: blimp_existential_there_quantifiers_1_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:46,220 WARNING  [task.py:800] [Task: blimp_existential_there_quantifiers_1_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 930 examples [00:00, 138726.18 examples/s]\n",
            "2024-11-06:00:18:47,359 WARNING  [task.py:788] [Task: blimp_existential_there_quantifiers_2_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:47,359 WARNING  [task.py:800] [Task: blimp_existential_there_quantifiers_2_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 911 examples [00:00, 130063.69 examples/s]\n",
            "2024-11-06:00:18:48,468 WARNING  [task.py:788] [Task: blimp_existential_there_subject_raising_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:48,468 WARNING  [task.py:800] [Task: blimp_existential_there_subject_raising_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 924 examples [00:00, 128019.58 examples/s]\n",
            "2024-11-06:00:18:49,592 WARNING  [task.py:788] [Task: blimp_expletive_it_object_raising_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:49,592 WARNING  [task.py:800] [Task: blimp_expletive_it_object_raising_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 759 examples [00:00, 104568.28 examples/s]\n",
            "2024-11-06:00:18:50,655 WARNING  [task.py:788] [Task: blimp_inchoative_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:50,655 WARNING  [task.py:800] [Task: blimp_inchoative_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 855 examples [00:00, 129791.17 examples/s]\n",
            "2024-11-06:00:18:51,748 WARNING  [task.py:788] [Task: blimp_intransitive_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:51,748 WARNING  [task.py:800] [Task: blimp_intransitive_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 868 examples [00:00, 115848.53 examples/s]\n",
            "2024-11-06:00:18:52,951 WARNING  [task.py:788] [Task: blimp_irregular_past_participle_adjectives_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:52,951 WARNING  [task.py:800] [Task: blimp_irregular_past_participle_adjectives_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 961 examples [00:00, 135710.12 examples/s]\n",
            "2024-11-06:00:18:54,136 WARNING  [task.py:788] [Task: blimp_irregular_past_participle_verbs_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:54,136 WARNING  [task.py:800] [Task: blimp_irregular_past_participle_verbs_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 942 examples [00:00, 129622.86 examples/s]\n",
            "2024-11-06:00:18:55,248 WARNING  [task.py:788] [Task: blimp_irregular_plural_subject_verb_agreement_1_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:55,248 WARNING  [task.py:800] [Task: blimp_irregular_plural_subject_verb_agreement_1_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 804 examples [00:00, 101356.15 examples/s]\n",
            "2024-11-06:00:18:56,400 WARNING  [task.py:788] [Task: blimp_irregular_plural_subject_verb_agreement_2_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:56,400 WARNING  [task.py:800] [Task: blimp_irregular_plural_subject_verb_agreement_2_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 892 examples [00:00, 36302.34 examples/s]\n",
            "2024-11-06:00:18:57,518 WARNING  [task.py:788] [Task: blimp_left_branch_island_echo_question_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:57,518 WARNING  [task.py:800] [Task: blimp_left_branch_island_echo_question_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 947 examples [00:00, 126921.42 examples/s]\n",
            "2024-11-06:00:18:58,612 WARNING  [task.py:788] [Task: blimp_left_branch_island_simple_question_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:58,612 WARNING  [task.py:800] [Task: blimp_left_branch_island_simple_question_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 951 examples [00:00, 111899.88 examples/s]\n",
            "2024-11-06:00:18:59,724 WARNING  [task.py:788] [Task: blimp_matrix_question_npi_licensor_present_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:18:59,724 WARNING  [task.py:800] [Task: blimp_matrix_question_npi_licensor_present_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 929 examples [00:00, 138547.45 examples/s]\n",
            "2024-11-06:00:19:00,821 WARNING  [task.py:788] [Task: blimp_npi_present_1_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:00,821 WARNING  [task.py:800] [Task: blimp_npi_present_1_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 909 examples [00:00, 123601.84 examples/s]\n",
            "2024-11-06:00:19:01,941 WARNING  [task.py:788] [Task: blimp_npi_present_2_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:01,942 WARNING  [task.py:800] [Task: blimp_npi_present_2_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 914 examples [00:00, 148032.35 examples/s]\n",
            "2024-11-06:00:19:03,104 WARNING  [task.py:788] [Task: blimp_only_npi_licensor_present_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:03,104 WARNING  [task.py:800] [Task: blimp_only_npi_licensor_present_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 882 examples [00:00, 128063.70 examples/s]\n",
            "2024-11-06:00:19:04,217 WARNING  [task.py:788] [Task: blimp_only_npi_scope_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:04,217 WARNING  [task.py:800] [Task: blimp_only_npi_scope_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 837 examples [00:00, 92263.66 examples/s]\n",
            "2024-11-06:00:19:05,317 WARNING  [task.py:788] [Task: blimp_passive_1_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:05,317 WARNING  [task.py:800] [Task: blimp_passive_1_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 840 examples [00:00, 120316.07 examples/s]\n",
            "2024-11-06:00:19:06,443 WARNING  [task.py:788] [Task: blimp_passive_2_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:06,443 WARNING  [task.py:800] [Task: blimp_passive_2_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 903 examples [00:00, 129132.51 examples/s]\n",
            "2024-11-06:00:19:07,589 WARNING  [task.py:788] [Task: blimp_principle_A_c_command_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:07,589 WARNING  [task.py:800] [Task: blimp_principle_A_c_command_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 946 examples [00:00, 46986.38 examples/s]\n",
            "2024-11-06:00:19:08,696 WARNING  [task.py:788] [Task: blimp_principle_A_case_1_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:08,696 WARNING  [task.py:800] [Task: blimp_principle_A_case_1_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 912 examples [00:00, 138283.76 examples/s]\n",
            "2024-11-06:00:19:09,871 WARNING  [task.py:788] [Task: blimp_principle_A_case_2_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:09,871 WARNING  [task.py:800] [Task: blimp_principle_A_case_2_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 915 examples [00:00, 117597.31 examples/s]\n",
            "2024-11-06:00:19:11,008 WARNING  [task.py:788] [Task: blimp_principle_A_domain_1_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:11,008 WARNING  [task.py:800] [Task: blimp_principle_A_domain_1_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 914 examples [00:00, 125149.97 examples/s]\n",
            "2024-11-06:00:19:12,118 WARNING  [task.py:788] [Task: blimp_principle_A_domain_2_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:12,118 WARNING  [task.py:800] [Task: blimp_principle_A_domain_2_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 915 examples [00:00, 133637.03 examples/s]\n",
            "2024-11-06:00:19:13,203 WARNING  [task.py:788] [Task: blimp_principle_A_domain_3_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:13,203 WARNING  [task.py:800] [Task: blimp_principle_A_domain_3_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 941 examples [00:00, 129612.82 examples/s]\n",
            "2024-11-06:00:19:14,275 WARNING  [task.py:788] [Task: blimp_principle_A_reconstruction_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:14,275 WARNING  [task.py:800] [Task: blimp_principle_A_reconstruction_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 967 examples [00:00, 128517.76 examples/s]\n",
            "2024-11-06:00:19:15,372 WARNING  [task.py:788] [Task: blimp_regular_plural_subject_verb_agreement_1_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:15,373 WARNING  [task.py:800] [Task: blimp_regular_plural_subject_verb_agreement_1_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 890 examples [00:00, 127543.07 examples/s]\n",
            "2024-11-06:00:19:16,418 WARNING  [task.py:788] [Task: blimp_regular_plural_subject_verb_agreement_2_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:16,419 WARNING  [task.py:800] [Task: blimp_regular_plural_subject_verb_agreement_2_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 945 examples [00:00, 130240.77 examples/s]\n",
            "2024-11-06:00:19:17,477 WARNING  [task.py:788] [Task: blimp_sentential_negation_npi_licensor_present_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:17,477 WARNING  [task.py:800] [Task: blimp_sentential_negation_npi_licensor_present_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 919 examples [00:00, 127184.00 examples/s]\n",
            "2024-11-06:00:19:18,562 WARNING  [task.py:788] [Task: blimp_sentential_negation_npi_scope_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:18,562 WARNING  [task.py:800] [Task: blimp_sentential_negation_npi_scope_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 871 examples [00:00, 111501.61 examples/s]\n",
            "2024-11-06:00:19:19,662 WARNING  [task.py:788] [Task: blimp_sentential_subject_island_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:19,662 WARNING  [task.py:800] [Task: blimp_sentential_subject_island_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 961 examples [00:00, 124133.11 examples/s]\n",
            "2024-11-06:00:19:20,742 WARNING  [task.py:788] [Task: blimp_superlative_quantifiers_1_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:20,742 WARNING  [task.py:800] [Task: blimp_superlative_quantifiers_1_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 979 examples [00:00, 129057.54 examples/s]\n",
            "2024-11-06:00:19:21,878 WARNING  [task.py:788] [Task: blimp_superlative_quantifiers_2_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:21,878 WARNING  [task.py:800] [Task: blimp_superlative_quantifiers_2_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 986 examples [00:00, 130930.91 examples/s]\n",
            "2024-11-06:00:19:22,961 WARNING  [task.py:788] [Task: blimp_tough_vs_raising_1_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:22,961 WARNING  [task.py:800] [Task: blimp_tough_vs_raising_1_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 948 examples [00:00, 133447.45 examples/s]\n",
            "2024-11-06:00:19:24,011 WARNING  [task.py:788] [Task: blimp_tough_vs_raising_2_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:24,011 WARNING  [task.py:800] [Task: blimp_tough_vs_raising_2_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 920 examples [00:00, 110661.30 examples/s]\n",
            "2024-11-06:00:19:25,204 WARNING  [task.py:788] [Task: blimp_transitive_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:25,204 WARNING  [task.py:800] [Task: blimp_transitive_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 868 examples [00:00, 140424.90 examples/s]\n",
            "2024-11-06:00:19:26,253 WARNING  [task.py:788] [Task: blimp_wh_island_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:26,253 WARNING  [task.py:800] [Task: blimp_wh_island_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 960 examples [00:00, 114716.01 examples/s]\n",
            "2024-11-06:00:19:27,470 WARNING  [task.py:788] [Task: blimp_wh_questions_object_gap_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:27,470 WARNING  [task.py:800] [Task: blimp_wh_questions_object_gap_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 859 examples [00:00, 119539.06 examples/s]\n",
            "2024-11-06:00:19:28,622 WARNING  [task.py:788] [Task: blimp_wh_questions_subject_gap_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:28,622 WARNING  [task.py:800] [Task: blimp_wh_questions_subject_gap_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 898 examples [00:00, 38231.05 examples/s]\n",
            "2024-11-06:00:19:29,813 WARNING  [task.py:788] [Task: blimp_wh_questions_subject_gap_long_distance_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:29,813 WARNING  [task.py:800] [Task: blimp_wh_questions_subject_gap_long_distance_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 857 examples [00:00, 118948.96 examples/s]\n",
            "2024-11-06:00:19:30,973 WARNING  [task.py:788] [Task: blimp_wh_vs_that_no_gap_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:30,974 WARNING  [task.py:800] [Task: blimp_wh_vs_that_no_gap_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 861 examples [00:00, 95539.45 examples/s]\n",
            "2024-11-06:00:19:32,036 WARNING  [task.py:788] [Task: blimp_wh_vs_that_no_gap_long_distance_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:32,036 WARNING  [task.py:800] [Task: blimp_wh_vs_that_no_gap_long_distance_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 875 examples [00:00, 131254.82 examples/s]\n",
            "2024-11-06:00:19:33,075 WARNING  [task.py:788] [Task: blimp_wh_vs_that_with_gap_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:33,075 WARNING  [task.py:800] [Task: blimp_wh_vs_that_with_gap_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 919 examples [00:00, 116385.32 examples/s]\n",
            "2024-11-06:00:19:34,241 WARNING  [task.py:788] [Task: blimp_wh_vs_that_with_gap_long_distance_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:34,241 WARNING  [task.py:800] [Task: blimp_wh_vs_that_with_gap_long_distance_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 910 examples [00:00, 103093.12 examples/s]\n",
            "2024-11-06:00:19:35,327 WARNING  [task.py:788] [Task: blimp_supplement_hypernym] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:35,328 WARNING  [task.py:800] [Task: blimp_supplement_hypernym] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 842 examples [00:00, 145621.14 examples/s]\n",
            "2024-11-06:00:19:36,370 WARNING  [task.py:788] [Task: blimp_supplement_qa_congruence_easy] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:36,370 WARNING  [task.py:800] [Task: blimp_supplement_qa_congruence_easy] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 64 examples [00:00, 16658.52 examples/s]\n",
            "2024-11-06:00:19:37,399 WARNING  [task.py:788] [Task: blimp_supplement_qa_congruence_tricky] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:37,400 WARNING  [task.py:800] [Task: blimp_supplement_qa_congruence_tricky] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 165 examples [00:00, 29804.49 examples/s]\n",
            "2024-11-06:00:19:38,416 WARNING  [task.py:788] [Task: blimp_supplement_subject_aux_inversion] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:38,416 WARNING  [task.py:800] [Task: blimp_supplement_subject_aux_inversion] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 3867 examples [00:00, 4032.95 examples/s]\n",
            "2024-11-06:00:19:42,002 WARNING  [task.py:788] [Task: blimp_supplement_turn_taking] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:19:42,002 WARNING  [task.py:800] [Task: blimp_supplement_turn_taking] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 280 examples [00:00, 57302.03 examples/s]\n",
            "2024-11-06:00:19:43,250 INFO     [task.py:417] Building contexts for blimp_supplement_turn_taking on rank 0...\n",
            "100% 280/280 [00:00<00:00, 1702.68it/s]\n",
            "2024-11-06:00:19:43,426 INFO     [task.py:417] Building contexts for blimp_supplement_subject_aux_inversion on rank 0...\n",
            "100% 3867/3867 [00:02<00:00, 1711.35it/s]\n",
            "2024-11-06:00:19:45,838 INFO     [task.py:417] Building contexts for blimp_supplement_qa_congruence_tricky on rank 0...\n",
            "100% 165/165 [00:00<00:00, 1640.52it/s]\n",
            "2024-11-06:00:19:45,945 INFO     [task.py:417] Building contexts for blimp_supplement_qa_congruence_easy on rank 0...\n",
            "100% 64/64 [00:00<00:00, 1678.88it/s]\n",
            "2024-11-06:00:19:45,987 INFO     [task.py:417] Building contexts for blimp_supplement_hypernym on rank 0...\n",
            "100% 842/842 [00:00<00:00, 1716.85it/s]\n",
            "2024-11-06:00:19:46,502 INFO     [task.py:417] Building contexts for blimp_wh_vs_that_with_gap_long_distance_filtered on rank 0...\n",
            "100% 910/910 [00:00<00:00, 1663.45it/s]\n",
            "2024-11-06:00:19:47,100 INFO     [task.py:417] Building contexts for blimp_wh_vs_that_with_gap_filtered on rank 0...\n",
            "100% 919/919 [00:00<00:00, 1667.32it/s]\n",
            "2024-11-06:00:19:47,704 INFO     [task.py:417] Building contexts for blimp_wh_vs_that_no_gap_long_distance_filtered on rank 0...\n",
            "100% 875/875 [00:00<00:00, 1702.10it/s]\n",
            "2024-11-06:00:19:48,269 INFO     [task.py:417] Building contexts for blimp_wh_vs_that_no_gap_filtered on rank 0...\n",
            "100% 861/861 [00:00<00:00, 1658.62it/s]\n",
            "2024-11-06:00:19:48,838 INFO     [task.py:417] Building contexts for blimp_wh_questions_subject_gap_long_distance_filtered on rank 0...\n",
            "100% 857/857 [00:00<00:00, 1689.61it/s]\n",
            "2024-11-06:00:19:49,394 INFO     [task.py:417] Building contexts for blimp_wh_questions_subject_gap_filtered on rank 0...\n",
            "100% 898/898 [00:00<00:00, 1709.22it/s]\n",
            "2024-11-06:00:19:49,972 INFO     [task.py:417] Building contexts for blimp_wh_questions_object_gap_filtered on rank 0...\n",
            "100% 859/859 [00:00<00:00, 1676.44it/s]\n",
            "2024-11-06:00:19:50,533 INFO     [task.py:417] Building contexts for blimp_wh_island_filtered on rank 0...\n",
            "100% 960/960 [00:00<00:00, 1698.09it/s]\n",
            "2024-11-06:00:19:51,152 INFO     [task.py:417] Building contexts for blimp_transitive_filtered on rank 0...\n",
            "100% 868/868 [00:00<00:00, 1683.35it/s]\n",
            "2024-11-06:00:19:51,715 INFO     [task.py:417] Building contexts for blimp_tough_vs_raising_2_filtered on rank 0...\n",
            "100% 920/920 [00:00<00:00, 1699.79it/s]\n",
            "2024-11-06:00:19:52,309 INFO     [task.py:417] Building contexts for blimp_tough_vs_raising_1_filtered on rank 0...\n",
            "100% 948/948 [00:00<00:00, 1713.86it/s]\n",
            "2024-11-06:00:19:52,920 INFO     [task.py:417] Building contexts for blimp_superlative_quantifiers_2_filtered on rank 0...\n",
            "100% 986/986 [00:00<00:00, 1656.28it/s]\n",
            "2024-11-06:00:19:53,571 INFO     [task.py:417] Building contexts for blimp_superlative_quantifiers_1_filtered on rank 0...\n",
            "100% 979/979 [00:00<00:00, 1703.59it/s]\n",
            "2024-11-06:00:19:54,201 INFO     [task.py:417] Building contexts for blimp_sentential_subject_island_filtered on rank 0...\n",
            "100% 961/961 [00:00<00:00, 1711.10it/s]\n",
            "2024-11-06:00:19:54,816 INFO     [task.py:417] Building contexts for blimp_sentential_negation_npi_scope_filtered on rank 0...\n",
            "100% 871/871 [00:00<00:00, 1695.77it/s]\n",
            "2024-11-06:00:19:55,381 INFO     [task.py:417] Building contexts for blimp_sentential_negation_npi_licensor_present_filtered on rank 0...\n",
            "100% 919/919 [00:00<00:00, 1047.58it/s]\n",
            "2024-11-06:00:19:56,310 INFO     [task.py:417] Building contexts for blimp_regular_plural_subject_verb_agreement_2_filtered on rank 0...\n",
            "100% 945/945 [00:00<00:00, 1715.17it/s]\n",
            "2024-11-06:00:19:56,915 INFO     [task.py:417] Building contexts for blimp_regular_plural_subject_verb_agreement_1_filtered on rank 0...\n",
            "100% 890/890 [00:00<00:00, 1692.29it/s]\n",
            "2024-11-06:00:19:57,491 INFO     [task.py:417] Building contexts for blimp_principle_A_reconstruction_filtered on rank 0...\n",
            "100% 967/967 [00:00<00:00, 1720.14it/s]\n",
            "2024-11-06:00:19:58,107 INFO     [task.py:417] Building contexts for blimp_principle_A_domain_3_filtered on rank 0...\n",
            "100% 941/941 [00:00<00:00, 1688.27it/s]\n",
            "2024-11-06:00:19:58,717 INFO     [task.py:417] Building contexts for blimp_principle_A_domain_2_filtered on rank 0...\n",
            "100% 915/915 [00:00<00:00, 1660.33it/s]\n",
            "2024-11-06:00:19:59,322 INFO     [task.py:417] Building contexts for blimp_principle_A_domain_1_filtered on rank 0...\n",
            "100% 914/914 [00:00<00:00, 1651.57it/s]\n",
            "2024-11-06:00:19:59,929 INFO     [task.py:417] Building contexts for blimp_principle_A_case_2_filtered on rank 0...\n",
            "100% 915/915 [00:00<00:00, 1628.02it/s]\n",
            "2024-11-06:00:20:00,545 INFO     [task.py:417] Building contexts for blimp_principle_A_case_1_filtered on rank 0...\n",
            "100% 912/912 [00:00<00:00, 1708.19it/s]\n",
            "2024-11-06:00:20:01,132 INFO     [task.py:417] Building contexts for blimp_principle_A_c_command_filtered on rank 0...\n",
            "100% 946/946 [00:00<00:00, 1706.65it/s]\n",
            "2024-11-06:00:20:01,740 INFO     [task.py:417] Building contexts for blimp_passive_2_filtered on rank 0...\n",
            "100% 903/903 [00:00<00:00, 1697.30it/s]\n",
            "2024-11-06:00:20:02,322 INFO     [task.py:417] Building contexts for blimp_passive_1_filtered on rank 0...\n",
            "100% 840/840 [00:00<00:00, 1724.46it/s]\n",
            "2024-11-06:00:20:02,860 INFO     [task.py:417] Building contexts for blimp_only_npi_scope_filtered on rank 0...\n",
            "100% 837/837 [00:00<00:00, 1681.26it/s]\n",
            "2024-11-06:00:20:03,405 INFO     [task.py:417] Building contexts for blimp_only_npi_licensor_present_filtered on rank 0...\n",
            "100% 882/882 [00:00<00:00, 1687.64it/s]\n",
            "2024-11-06:00:20:03,977 INFO     [task.py:417] Building contexts for blimp_npi_present_2_filtered on rank 0...\n",
            "100% 914/914 [00:00<00:00, 1661.40it/s]\n",
            "2024-11-06:00:20:04,578 INFO     [task.py:417] Building contexts for blimp_npi_present_1_filtered on rank 0...\n",
            "100% 909/909 [00:00<00:00, 1707.84it/s]\n",
            "2024-11-06:00:20:05,166 INFO     [task.py:417] Building contexts for blimp_matrix_question_npi_licensor_present_filtered on rank 0...\n",
            "100% 929/929 [00:00<00:00, 1697.97it/s]\n",
            "2024-11-06:00:20:05,765 INFO     [task.py:417] Building contexts for blimp_left_branch_island_simple_question_filtered on rank 0...\n",
            "100% 951/951 [00:00<00:00, 1711.69it/s]\n",
            "2024-11-06:00:20:06,373 INFO     [task.py:417] Building contexts for blimp_left_branch_island_echo_question_filtered on rank 0...\n",
            "100% 947/947 [00:00<00:00, 1722.10it/s]\n",
            "2024-11-06:00:20:06,975 INFO     [task.py:417] Building contexts for blimp_irregular_plural_subject_verb_agreement_2_filtered on rank 0...\n",
            "100% 892/892 [00:00<00:00, 1702.21it/s]\n",
            "2024-11-06:00:20:07,549 INFO     [task.py:417] Building contexts for blimp_irregular_plural_subject_verb_agreement_1_filtered on rank 0...\n",
            "100% 804/804 [00:00<00:00, 1717.12it/s]\n",
            "2024-11-06:00:20:08,065 INFO     [task.py:417] Building contexts for blimp_irregular_past_participle_verbs_filtered on rank 0...\n",
            "100% 942/942 [00:00<00:00, 1710.42it/s]\n",
            "2024-11-06:00:20:08,670 INFO     [task.py:417] Building contexts for blimp_irregular_past_participle_adjectives_filtered on rank 0...\n",
            "100% 961/961 [00:00<00:00, 1729.28it/s]\n",
            "2024-11-06:00:20:09,281 INFO     [task.py:417] Building contexts for blimp_intransitive_filtered on rank 0...\n",
            "100% 868/868 [00:00<00:00, 1693.70it/s]\n",
            "2024-11-06:00:20:09,846 INFO     [task.py:417] Building contexts for blimp_inchoative_filtered on rank 0...\n",
            "100% 855/855 [00:00<00:00, 1705.19it/s]\n",
            "2024-11-06:00:20:10,395 INFO     [task.py:417] Building contexts for blimp_expletive_it_object_raising_filtered on rank 0...\n",
            "100% 759/759 [00:00<00:00, 1639.79it/s]\n",
            "2024-11-06:00:20:10,901 INFO     [task.py:417] Building contexts for blimp_existential_there_subject_raising_filtered on rank 0...\n",
            "100% 924/924 [00:00<00:00, 1600.00it/s]\n",
            "2024-11-06:00:20:11,531 INFO     [task.py:417] Building contexts for blimp_existential_there_quantifiers_2_filtered on rank 0...\n",
            "100% 911/911 [00:00<00:00, 943.54it/s]\n",
            "2024-11-06:00:20:12,554 INFO     [task.py:417] Building contexts for blimp_existential_there_quantifiers_1_filtered on rank 0...\n",
            "100% 930/930 [00:00<00:00, 1723.77it/s]\n",
            "2024-11-06:00:20:13,146 INFO     [task.py:417] Building contexts for blimp_existential_there_object_raising_filtered on rank 0...\n",
            "100% 812/812 [00:00<00:00, 1693.12it/s]\n",
            "2024-11-06:00:20:13,671 INFO     [task.py:417] Building contexts for blimp_ellipsis_n_bar_2_filtered on rank 0...\n",
            "100% 828/828 [00:00<00:00, 1707.11it/s]\n",
            "2024-11-06:00:20:14,208 INFO     [task.py:417] Building contexts for blimp_ellipsis_n_bar_1_filtered on rank 0...\n",
            "100% 802/802 [00:00<00:00, 1661.26it/s]\n",
            "2024-11-06:00:20:14,735 INFO     [task.py:417] Building contexts for blimp_drop_argument_filtered on rank 0...\n",
            "100% 920/920 [00:00<00:00, 1688.02it/s]\n",
            "2024-11-06:00:20:15,332 INFO     [task.py:417] Building contexts for blimp_distractor_agreement_relative_clause_filtered on rank 0...\n",
            "100% 871/871 [00:00<00:00, 1684.09it/s]\n",
            "2024-11-06:00:20:15,909 INFO     [task.py:417] Building contexts for blimp_distractor_agreement_relational_noun_filtered on rank 0...\n",
            "100% 788/788 [00:00<00:00, 1706.66it/s]\n",
            "2024-11-06:00:20:16,416 INFO     [task.py:417] Building contexts for blimp_determiner_noun_agreement_with_adjective_1_filtered on rank 0...\n",
            "100% 933/933 [00:00<00:00, 1712.21it/s]\n",
            "2024-11-06:00:20:17,017 INFO     [task.py:417] Building contexts for blimp_determiner_noun_agreement_with_adj_irregular_2_filtered on rank 0...\n",
            "100% 840/840 [00:00<00:00, 1696.37it/s]\n",
            "2024-11-06:00:20:17,561 INFO     [task.py:417] Building contexts for blimp_determiner_noun_agreement_with_adj_irregular_1_filtered on rank 0...\n",
            "100% 718/718 [00:00<00:00, 1710.91it/s]\n",
            "2024-11-06:00:20:18,021 INFO     [task.py:417] Building contexts for blimp_determiner_noun_agreement_with_adj_2_filtered on rank 0...\n",
            "100% 941/941 [00:00<00:00, 1710.00it/s]\n",
            "2024-11-06:00:20:18,623 INFO     [task.py:417] Building contexts for blimp_determiner_noun_agreement_irregular_2_filtered on rank 0...\n",
            "100% 820/820 [00:00<00:00, 1734.64it/s]\n",
            "2024-11-06:00:20:19,141 INFO     [task.py:417] Building contexts for blimp_determiner_noun_agreement_irregular_1_filtered on rank 0...\n",
            "100% 681/681 [00:00<00:00, 1736.42it/s]\n",
            "2024-11-06:00:20:19,572 INFO     [task.py:417] Building contexts for blimp_determiner_noun_agreement_2_filtered on rank 0...\n",
            "100% 931/931 [00:00<00:00, 1705.73it/s]\n",
            "2024-11-06:00:20:20,169 INFO     [task.py:417] Building contexts for blimp_determiner_noun_agreement_1_filtered on rank 0...\n",
            "100% 929/929 [00:00<00:00, 1719.01it/s]\n",
            "2024-11-06:00:20:20,762 INFO     [task.py:417] Building contexts for blimp_coordinate_structure_constraint_object_extraction_filtered on rank 0...\n",
            "100% 949/949 [00:00<00:00, 1703.80it/s]\n",
            "2024-11-06:00:20:21,373 INFO     [task.py:417] Building contexts for blimp_coordinate_structure_constraint_complex_left_branch_filtered on rank 0...\n",
            "100% 906/906 [00:00<00:00, 1697.57it/s]\n",
            "2024-11-06:00:20:21,958 INFO     [task.py:417] Building contexts for blimp_complex_NP_island_filtered on rank 0...\n",
            "100% 846/846 [00:00<00:00, 1673.22it/s]\n",
            "2024-11-06:00:20:22,514 INFO     [task.py:417] Building contexts for blimp_causative_filtered on rank 0...\n",
            "100% 818/818 [00:00<00:00, 1651.83it/s]\n",
            "2024-11-06:00:20:23,055 INFO     [task.py:417] Building contexts for blimp_animate_subject_trans_filtered on rank 0...\n",
            "100% 923/923 [00:00<00:00, 1639.75it/s]\n",
            "2024-11-06:00:20:23,675 INFO     [task.py:417] Building contexts for blimp_animate_subject_passive_filtered on rank 0...\n",
            "100% 895/895 [00:00<00:00, 1639.75it/s]\n",
            "2024-11-06:00:20:24,280 INFO     [task.py:417] Building contexts for blimp_anaphor_number_agreement_filtered on rank 0...\n",
            "100% 931/931 [00:00<00:00, 1686.29it/s]\n",
            "2024-11-06:00:20:24,889 INFO     [task.py:417] Building contexts for blimp_anaphor_gender_agreement_filtered on rank 0...\n",
            "100% 971/971 [00:00<00:00, 1695.05it/s]\n",
            "2024-11-06:00:20:25,517 INFO     [task.py:417] Building contexts for blimp_adjunct_island_filtered on rank 0...\n",
            "100% 928/928 [00:00<00:00, 1695.61it/s]\n",
            "2024-11-06:00:20:26,120 INFO     [evaluator.py:385] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0% 0/130186 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
            "Running loglikelihood requests: 100% 130186/130186 [59:07<00:00, 36.70it/s]\n",
            "hf (pretrained=Harshatheeswar/babylama-scratch,backend=causal), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 1\n",
            "|                                Tasks                                |Version|Filter|n-shot|Metric|Value |   |Stderr|\n",
            "|---------------------------------------------------------------------|-------|------|-----:|------|-----:|---|-----:|\n",
            "|blimp_supplement                                                     |N/A    |none  |     0|acc   |0.5475|±  |0.0066|\n",
            "| - blimp_supplement_hypernym                                         |      1|none  |     0|acc   |0.5024|±  |0.0172|\n",
            "| - blimp_supplement_qa_congruence_easy                               |      1|none  |     0|acc   |0.5000|±  |0.0630|\n",
            "| - blimp_supplement_qa_congruence_tricky                             |      1|none  |     0|acc   |0.4424|±  |0.0388|\n",
            "| - blimp_supplement_subject_aux_inversion                            |      1|none  |     0|acc   |0.6711|±  |0.0076|\n",
            "| - blimp_supplement_turn_taking                                      |      1|none  |     0|acc   |0.6214|±  |0.0290|\n",
            "|blimp_filtered                                                       |N/A    |none  |     0|acc   |0.6398|±  |0.0018|\n",
            "| - blimp_adjunct_island_filtered                                     |      1|none  |     0|acc   |0.6315|±  |0.0158|\n",
            "| - blimp_anaphor_gender_agreement_filtered                           |      1|none  |     0|acc   |0.4789|±  |0.0160|\n",
            "| - blimp_anaphor_number_agreement_filtered                           |      1|none  |     0|acc   |0.7605|±  |0.0140|\n",
            "| - blimp_animate_subject_passive_filtered                            |      1|none  |     0|acc   |0.6737|±  |0.0157|\n",
            "| - blimp_animate_subject_trans_filtered                              |      1|none  |     0|acc   |0.7226|±  |0.0147|\n",
            "| - blimp_causative_filtered                                          |      1|none  |     0|acc   |0.5844|±  |0.0172|\n",
            "| - blimp_complex_NP_island_filtered                                  |      1|none  |     0|acc   |0.4149|±  |0.0169|\n",
            "| - blimp_coordinate_structure_constraint_complex_left_branch_filtered|      1|none  |     0|acc   |0.2947|±  |0.0152|\n",
            "| - blimp_coordinate_structure_constraint_object_extraction_filtered  |      1|none  |     0|acc   |0.5743|±  |0.0161|\n",
            "| - blimp_determiner_noun_agreement_1_filtered                        |      1|none  |     0|acc   |0.8913|±  |0.0102|\n",
            "| - blimp_determiner_noun_agreement_2_filtered                        |      1|none  |     0|acc   |0.9345|±  |0.0081|\n",
            "| - blimp_determiner_noun_agreement_irregular_1_filtered              |      1|none  |     0|acc   |0.7313|±  |0.0170|\n",
            "| - blimp_determiner_noun_agreement_irregular_2_filtered              |      1|none  |     0|acc   |0.8476|±  |0.0126|\n",
            "| - blimp_determiner_noun_agreement_with_adj_2_filtered               |      1|none  |     0|acc   |0.8895|±  |0.0102|\n",
            "| - blimp_determiner_noun_agreement_with_adj_irregular_1_filtered     |      1|none  |     0|acc   |0.7855|±  |0.0153|\n",
            "| - blimp_determiner_noun_agreement_with_adj_irregular_2_filtered     |      1|none  |     0|acc   |0.7976|±  |0.0139|\n",
            "| - blimp_determiner_noun_agreement_with_adjective_1_filtered         |      1|none  |     0|acc   |0.8435|±  |0.0119|\n",
            "| - blimp_distractor_agreement_relational_noun_filtered               |      1|none  |     0|acc   |0.3858|±  |0.0174|\n",
            "| - blimp_distractor_agreement_relative_clause_filtered               |      1|none  |     0|acc   |0.3651|±  |0.0163|\n",
            "| - blimp_drop_argument_filtered                                      |      1|none  |     0|acc   |0.7087|±  |0.0150|\n",
            "| - blimp_ellipsis_n_bar_1_filtered                                   |      1|none  |     0|acc   |0.7893|±  |0.0144|\n",
            "| - blimp_ellipsis_n_bar_2_filtered                                   |      1|none  |     0|acc   |0.5278|±  |0.0174|\n",
            "| - blimp_existential_there_object_raising_filtered                   |      1|none  |     0|acc   |0.7081|±  |0.0160|\n",
            "| - blimp_existential_there_quantifiers_1_filtered                    |      1|none  |     0|acc   |0.6667|±  |0.0155|\n",
            "| - blimp_existential_there_quantifiers_2_filtered                    |      1|none  |     0|acc   |0.4040|±  |0.0163|\n",
            "| - blimp_existential_there_subject_raising_filtered                  |      1|none  |     0|acc   |0.6580|±  |0.0156|\n",
            "| - blimp_expletive_it_object_raising_filtered                        |      1|none  |     0|acc   |0.6825|±  |0.0169|\n",
            "| - blimp_inchoative_filtered                                         |      1|none  |     0|acc   |0.4444|±  |0.0170|\n",
            "| - blimp_intransitive_filtered                                       |      1|none  |     0|acc   |0.6094|±  |0.0166|\n",
            "| - blimp_irregular_past_participle_adjectives_filtered               |      1|none  |     0|acc   |0.6015|±  |0.0158|\n",
            "| - blimp_irregular_past_participle_verbs_filtered                    |      1|none  |     0|acc   |0.6444|±  |0.0156|\n",
            "| - blimp_irregular_plural_subject_verb_agreement_1_filtered          |      1|none  |     0|acc   |0.5995|±  |0.0173|\n",
            "| - blimp_irregular_plural_subject_verb_agreement_2_filtered          |      1|none  |     0|acc   |0.6850|±  |0.0156|\n",
            "| - blimp_left_branch_island_echo_question_filtered                   |      1|none  |     0|acc   |0.8585|±  |0.0113|\n",
            "| - blimp_left_branch_island_simple_question_filtered                 |      1|none  |     0|acc   |0.4332|±  |0.0161|\n",
            "| - blimp_matrix_question_npi_licensor_present_filtered               |      1|none  |     0|acc   |0.1055|±  |0.0101|\n",
            "| - blimp_npi_present_1_filtered                                      |      1|none  |     0|acc   |0.3113|±  |0.0154|\n",
            "| - blimp_npi_present_2_filtered                                      |      1|none  |     0|acc   |0.3534|±  |0.0158|\n",
            "| - blimp_only_npi_licensor_present_filtered                          |      1|none  |     0|acc   |0.8401|±  |0.0123|\n",
            "| - blimp_only_npi_scope_filtered                                     |      1|none  |     0|acc   |0.4695|±  |0.0173|\n",
            "| - blimp_passive_1_filtered                                          |      1|none  |     0|acc   |0.8226|±  |0.0132|\n",
            "| - blimp_passive_2_filtered                                          |      1|none  |     0|acc   |0.8106|±  |0.0130|\n",
            "| - blimp_principle_A_c_command_filtered                              |      1|none  |     0|acc   |0.7410|±  |0.0143|\n",
            "| - blimp_principle_A_case_1_filtered                                 |      1|none  |     0|acc   |1.0000|±  |0.0000|\n",
            "| - blimp_principle_A_case_2_filtered                                 |      1|none  |     0|acc   |0.8044|±  |0.0131|\n",
            "| - blimp_principle_A_domain_1_filtered                               |      1|none  |     0|acc   |0.9683|±  |0.0058|\n",
            "| - blimp_principle_A_domain_2_filtered                               |      1|none  |     0|acc   |0.5464|±  |0.0165|\n",
            "| - blimp_principle_A_domain_3_filtered                               |      1|none  |     0|acc   |0.4485|±  |0.0162|\n",
            "| - blimp_principle_A_reconstruction_filtered                         |      1|none  |     0|acc   |0.4312|±  |0.0159|\n",
            "| - blimp_regular_plural_subject_verb_agreement_1_filtered            |      1|none  |     0|acc   |0.7258|±  |0.0150|\n",
            "| - blimp_regular_plural_subject_verb_agreement_2_filtered            |      1|none  |     0|acc   |0.6720|±  |0.0153|\n",
            "| - blimp_sentential_negation_npi_licensor_present_filtered           |      1|none  |     0|acc   |0.9967|±  |0.0019|\n",
            "| - blimp_sentential_negation_npi_scope_filtered                      |      1|none  |     0|acc   |0.3318|±  |0.0160|\n",
            "| - blimp_sentential_subject_island_filtered                          |      1|none  |     0|acc   |0.3517|±  |0.0154|\n",
            "| - blimp_superlative_quantifiers_1_filtered                          |      1|none  |     0|acc   |0.8223|±  |0.0122|\n",
            "| - blimp_superlative_quantifiers_2_filtered                          |      1|none  |     0|acc   |0.4807|±  |0.0159|\n",
            "| - blimp_tough_vs_raising_1_filtered                                 |      1|none  |     0|acc   |0.4842|±  |0.0162|\n",
            "| - blimp_tough_vs_raising_2_filtered                                 |      1|none  |     0|acc   |0.6152|±  |0.0160|\n",
            "| - blimp_transitive_filtered                                         |      1|none  |     0|acc   |0.6843|±  |0.0158|\n",
            "| - blimp_wh_island_filtered                                          |      1|none  |     0|acc   |0.4740|±  |0.0161|\n",
            "| - blimp_wh_questions_object_gap_filtered                            |      1|none  |     0|acc   |0.7753|±  |0.0142|\n",
            "| - blimp_wh_questions_subject_gap_filtered                           |      1|none  |     0|acc   |0.9020|±  |0.0099|\n",
            "| - blimp_wh_questions_subject_gap_long_distance_filtered             |      1|none  |     0|acc   |0.8938|±  |0.0105|\n",
            "| - blimp_wh_vs_that_no_gap_filtered                                  |      1|none  |     0|acc   |0.9489|±  |0.0075|\n",
            "| - blimp_wh_vs_that_no_gap_long_distance_filtered                    |      1|none  |     0|acc   |0.9360|±  |0.0083|\n",
            "| - blimp_wh_vs_that_with_gap_filtered                                |      1|none  |     0|acc   |0.3264|±  |0.0155|\n",
            "| - blimp_wh_vs_that_with_gap_long_distance_filtered                  |      1|none  |     0|acc   |0.1626|±  |0.0122|\n",
            "\n",
            "|     Groups     |Version|Filter|n-shot|Metric|Value |   |Stderr|\n",
            "|----------------|-------|------|-----:|------|-----:|---|-----:|\n",
            "|blimp_supplement|N/A    |none  |     0|acc   |0.5475|±  |0.0066|\n",
            "|blimp_filtered  |N/A    |none  |     0|acc   |0.6398|±  |0.0018|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!bash eval_blimp.sh Harshatheeswar/babylama-scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPuLHyAi-2tI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ecf69b9-fb2f-4aa4-9570-520a07a1a2e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-06 00:10:58.923063: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-06 00:10:58.937220: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-06 00:10:58.941368: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-06 00:10:58.954989: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-06:00:11:03,857 INFO     [__main__.py:263] Verbosity set to INFO\n",
            "2024-11-06:00:11:22,947 INFO     [__main__.py:349] Selected Tasks: ['ewok_filtered']\n",
            "pretrained=Harshatheeswar/babylama-scratch,backend=causal\n",
            "2024-11-06:00:11:22,954 INFO     [evaluator.py:133] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-11-06:00:11:22,954 INFO     [evaluator.py:181] Initializing hf model, with arguments: {'pretrained': 'Harshatheeswar/babylama-scratch', 'backend': 'causal'}\n",
            "2024-11-06:00:11:22,960 INFO     [huggingface.py:204] Device not specified\n",
            "2024-11-06:00:11:22,960 INFO     [huggingface.py:205] Cuda Available? False\n",
            "2024-11-06:00:11:23,175 INFO     [huggingface.py:489] Overrode HF model backend type, and using type 'causal'\n",
            "2024-11-06:00:11:24,501 WARNING  [task.py:788] [Task: ewok_agent-properties_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:11:24,501 WARNING  [task.py:800] [Task: ewok_agent-properties_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 2210 examples [00:00, 54329.09 examples/s]\n",
            "2024-11-06:00:11:26,000 WARNING  [task.py:788] [Task: ewok_material-dynamics_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:11:26,001 WARNING  [task.py:800] [Task: ewok_material-dynamics_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 770 examples [00:00, 89836.27 examples/s]\n",
            "2024-11-06:00:11:27,140 WARNING  [task.py:788] [Task: ewok_material-properties_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:11:27,140 WARNING  [task.py:800] [Task: ewok_material-properties_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 170 examples [00:00, 33716.27 examples/s]\n",
            "2024-11-06:00:11:28,067 WARNING  [task.py:788] [Task: ewok_physical-dynamics_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:11:28,067 WARNING  [task.py:800] [Task: ewok_physical-dynamics_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 120 examples [00:00, 22572.27 examples/s]\n",
            "2024-11-06:00:11:29,025 WARNING  [task.py:788] [Task: ewok_physical-interactions_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:11:29,025 WARNING  [task.py:800] [Task: ewok_physical-interactions_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 556 examples [00:00, 79196.94 examples/s]\n",
            "2024-11-06:00:11:30,080 WARNING  [task.py:788] [Task: ewok_physical-relations_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:11:30,081 WARNING  [task.py:800] [Task: ewok_physical-relations_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 818 examples [00:00, 104745.56 examples/s]\n",
            "2024-11-06:00:11:31,061 WARNING  [task.py:788] [Task: ewok_quantitative-properties_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:11:31,061 WARNING  [task.py:800] [Task: ewok_quantitative-properties_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 314 examples [00:00, 56626.17 examples/s]\n",
            "2024-11-06:00:11:32,076 WARNING  [task.py:788] [Task: ewok_social-interactions_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:11:32,076 WARNING  [task.py:800] [Task: ewok_social-interactions_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 294 examples [00:00, 60916.14 examples/s]\n",
            "2024-11-06:00:11:33,128 WARNING  [task.py:788] [Task: ewok_social-properties_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:11:33,128 WARNING  [task.py:800] [Task: ewok_social-properties_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 328 examples [00:00, 48492.48 examples/s]\n",
            "2024-11-06:00:11:34,131 WARNING  [task.py:788] [Task: ewok_social-relations_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:11:34,131 WARNING  [task.py:800] [Task: ewok_social-relations_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 1548 examples [00:00, 171083.31 examples/s]\n",
            "2024-11-06:00:11:35,262 WARNING  [task.py:788] [Task: ewok_spatial-relations_filtered] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-11-06:00:11:35,262 WARNING  [task.py:800] [Task: ewok_spatial-relations_filtered] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Generating train split: 490 examples [00:00, 75484.22 examples/s]\n",
            "2024-11-06:00:11:36,374 INFO     [task.py:417] Building contexts for ewok_spatial-relations_filtered on rank 0...\n",
            "100% 490/490 [00:00<00:00, 1476.98it/s]\n",
            "2024-11-06:00:11:36,734 INFO     [task.py:417] Building contexts for ewok_social-relations_filtered on rank 0...\n",
            "100% 1548/1548 [00:01<00:00, 1474.38it/s]\n",
            "2024-11-06:00:11:37,869 INFO     [task.py:417] Building contexts for ewok_social-properties_filtered on rank 0...\n",
            "100% 328/328 [00:00<00:00, 1478.28it/s]\n",
            "2024-11-06:00:11:38,110 INFO     [task.py:417] Building contexts for ewok_social-interactions_filtered on rank 0...\n",
            "100% 294/294 [00:00<00:00, 1485.51it/s]\n",
            "2024-11-06:00:11:38,326 INFO     [task.py:417] Building contexts for ewok_quantitative-properties_filtered on rank 0...\n",
            "100% 314/314 [00:00<00:00, 1466.83it/s]\n",
            "2024-11-06:00:11:38,559 INFO     [task.py:417] Building contexts for ewok_physical-relations_filtered on rank 0...\n",
            "100% 818/818 [00:00<00:00, 1466.00it/s]\n",
            "2024-11-06:00:11:39,163 INFO     [task.py:417] Building contexts for ewok_physical-interactions_filtered on rank 0...\n",
            "100% 556/556 [00:00<00:00, 1449.75it/s]\n",
            "2024-11-06:00:11:39,578 INFO     [task.py:417] Building contexts for ewok_physical-dynamics_filtered on rank 0...\n",
            "100% 120/120 [00:00<00:00, 1493.68it/s]\n",
            "2024-11-06:00:11:39,667 INFO     [task.py:417] Building contexts for ewok_material-properties_filtered on rank 0...\n",
            "100% 170/170 [00:00<00:00, 1474.23it/s]\n",
            "2024-11-06:00:11:39,793 INFO     [task.py:417] Building contexts for ewok_material-dynamics_filtered on rank 0...\n",
            "100% 770/770 [00:00<00:00, 1406.72it/s]\n",
            "2024-11-06:00:11:40,384 INFO     [task.py:417] Building contexts for ewok_agent-properties_filtered on rank 0...\n",
            "100% 2210/2210 [00:01<00:00, 1451.67it/s]\n",
            "2024-11-06:00:11:42,031 INFO     [evaluator.py:385] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0% 0/15236 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
            "Running loglikelihood requests: 100% 15236/15236 [05:59<00:00, 42.35it/s]\n",
            "hf (pretrained=Harshatheeswar/babylama-scratch,backend=causal), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 128\n",
            "|                 Tasks                  |Version|Filter|n-shot|Metric|Value |   |Stderr|\n",
            "|----------------------------------------|-------|------|-----:|------|-----:|---|-----:|\n",
            "|ewok_filtered                           |N/A    |none  |     0|acc   |0.5036|±  |0.0057|\n",
            "| - ewok_agent-properties_filtered       |      1|none  |     0|acc   |0.5009|±  |0.0106|\n",
            "| - ewok_material-dynamics_filtered      |      1|none  |     0|acc   |0.5143|±  |0.0180|\n",
            "| - ewok_material-properties_filtered    |      1|none  |     0|acc   |0.4941|±  |0.0385|\n",
            "| - ewok_physical-dynamics_filtered      |      1|none  |     0|acc   |0.4833|±  |0.0458|\n",
            "| - ewok_physical-interactions_filtered  |      1|none  |     0|acc   |0.5180|±  |0.0212|\n",
            "| - ewok_physical-relations_filtered     |      1|none  |     0|acc   |0.5086|±  |0.0175|\n",
            "| - ewok_quantitative-properties_filtered|      1|none  |     0|acc   |0.4968|±  |0.0283|\n",
            "| - ewok_social-interactions_filtered    |      1|none  |     0|acc   |0.5170|±  |0.0292|\n",
            "| - ewok_social-properties_filtered      |      1|none  |     0|acc   |0.4970|±  |0.0276|\n",
            "| - ewok_social-relations_filtered       |      1|none  |     0|acc   |0.4929|±  |0.0127|\n",
            "| - ewok_spatial-relations_filtered      |      1|none  |     0|acc   |0.5163|±  |0.0226|\n",
            "\n",
            "|   Groups    |Version|Filter|n-shot|Metric|Value |   |Stderr|\n",
            "|-------------|-------|------|-----:|------|-----:|---|-----:|\n",
            "|ewok_filtered|N/A    |none  |     0|acc   |0.5036|±  |0.0057|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!bash eval_ewok.sh Harshatheeswar/babylama-scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## printing sample examples\n",
        "\n"
      ],
      "metadata": {
        "id": "EmwRBIc4mo8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "def load_jsonl_or_json_array(file_path, num_samples=2):\n",
        "\n",
        "    samples = []\n",
        "    with open(file_path, 'r') as f:\n",
        "        first_char = f.read(1)\n",
        "        f.seek(0)\n",
        "\n",
        "        if first_char == '[':\n",
        "\n",
        "            try:\n",
        "                data = json.load(f)\n",
        "                samples = data[:num_samples]\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Error reading JSON array file {file_path}: {e}\")\n",
        "        else:\n",
        "\n",
        "            for i, line in enumerate(f):\n",
        "                if i >= num_samples:\n",
        "                    break\n",
        "                line = line.strip()\n",
        "                if line:\n",
        "                    try:\n",
        "                        samples.append(json.loads(line))\n",
        "                    except json.JSONDecodeError:\n",
        "                        print(f\"Skipping malformed line in {file_path}: {line}\")\n",
        "    return samples\n"
      ],
      "metadata": {
        "id": "P7xM_DyumgRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qnpj6iw-2nv"
      },
      "outputs": [],
      "source": [
        "def print_samples(samples):\n",
        "\n",
        "    for sample in samples:\n",
        "        doc = sample.get(\"doc\", {})\n",
        "        sentence_good = doc.get(\"sentence_good\", \"N/A\")\n",
        "        sentence_bad = doc.get(\"sentence_bad\", \"N/A\")\n",
        "        acc = sample.get(\"acc\", \"N/A\")\n",
        "\n",
        "        # Display prediction scores and correctness for each sentence\n",
        "        resps = sample.get(\"resps\", [])\n",
        "        filtered_resps = sample.get(\"filtered_resps\", [])\n",
        "\n",
        "        print(\"Sentence (Good):\", sentence_good)\n",
        "        print(\"Sentence (Bad):\", sentence_bad)\n",
        "        print(\"Accuracy:\", acc)\n",
        "\n",
        "\n",
        "        if resps:\n",
        "            print(\"Predictions (resps):\")\n",
        "            for i, resp in enumerate(resps):\n",
        "                score, correct = resp[0][0], resp[0][1]\n",
        "                print(f\"  Response {i + 1}: Score = {score}\")\n",
        "\n",
        "        # Print filtered prediction scores if available\n",
        "        if filtered_resps:\n",
        "            print(\"Filtered Predictions (filtered_resps):\")\n",
        "            for i, filtered_resp in enumerate(filtered_resps):\n",
        "                score, correct = filtered_resp\n",
        "                print(f\"  Filtered Response {i + 1}: Score = {score}\")\n",
        "\n",
        "        print(\"=\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j95aNxlv-2ku"
      },
      "outputs": [],
      "source": [
        "base_path = '/content/drive/MyDrive/new_evaluation_pipeline/results'\n",
        "tasks = {\n",
        "    'blimp': os.path.join(base_path, 'blimp/babylama-scratch')\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for task_name, task_path in tasks.items():\n",
        "    print(f\"Task: {task_name}\")\n",
        "    for subtask_file in os.listdir(task_path):\n",
        "        if subtask_file.endswith('.jsonl'):\n",
        "            file_path = os.path.join(task_path, subtask_file)\n",
        "            print(f\"\\nSubtask: {subtask_file}\")\n",
        "            samples = load_jsonl_or_json_array(file_path)\n",
        "            print_samples(samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZBSq1ctfWUn",
        "outputId": "d1c6a0b0-183a-4ea2-b3b5-2c73e4eb0df3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task: blimp\n",
            "\n",
            "Subtask: blimp_adjunct_island_filtered_results.jsonl\n",
            "Sentence (Good): Who should Derek hug after shocking Richard?\n",
            "Sentence (Bad): Who should Derek hug Richard after shocking?\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -103.2327880859375\n",
            "  Response 2: Score = -102.16051483154297\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -103.2327880859375\n",
            "  Filtered Response 2: Score = -102.16051483154297\n",
            "========================================\n",
            "Sentence (Good): What had Theresa walked through while talking about that high school?\n",
            "Sentence (Bad): What had Theresa walked through that high school while talking about?\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -108.98979187011719\n",
            "  Response 2: Score = -108.75389099121094\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -108.98979187011719\n",
            "  Filtered Response 2: Score = -108.75389099121094\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_anaphor_gender_agreement_filtered_results.jsonl\n",
            "Sentence (Good): Katherine can't help herself.\n",
            "Sentence (Bad): Katherine can't help himself.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -53.03114318847656\n",
            "  Response 2: Score = -54.20348358154297\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -53.03114318847656\n",
            "  Filtered Response 2: Score = -54.20348358154297\n",
            "========================================\n",
            "Sentence (Good): Marie won't think about herself.\n",
            "Sentence (Bad): Marie won't think about itself.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -50.720577239990234\n",
            "  Response 2: Score = -49.172245025634766\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -50.720577239990234\n",
            "  Filtered Response 2: Score = -49.172245025634766\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_anaphor_number_agreement_filtered_results.jsonl\n",
            "Sentence (Good): Susan revealed herself.\n",
            "Sentence (Bad): Susan revealed themselves.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -44.374027252197266\n",
            "  Response 2: Score = -42.976356506347656\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -44.374027252197266\n",
            "  Filtered Response 2: Score = -42.976356506347656\n",
            "========================================\n",
            "Sentence (Good): Renee hasn't hurt herself.\n",
            "Sentence (Bad): Renee hasn't hurt themselves.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -62.153175354003906\n",
            "  Response 2: Score = -61.948936462402344\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -62.153175354003906\n",
            "  Filtered Response 2: Score = -61.948936462402344\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_animate_subject_passive_filtered_results.jsonl\n",
            "Sentence (Good): Amanda was respected by some waitresses.\n",
            "Sentence (Bad): Amanda was respected by some picture.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -63.05095291137695\n",
            "  Response 2: Score = -58.08427429199219\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -63.05095291137695\n",
            "  Filtered Response 2: Score = -58.08427429199219\n",
            "========================================\n",
            "Sentence (Good): Some lake was passed by some cashiers.\n",
            "Sentence (Bad): Some lake was passed by some phenomena.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -71.07591247558594\n",
            "  Response 2: Score = -68.61975860595703\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -71.07591247558594\n",
            "  Filtered Response 2: Score = -68.61975860595703\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_animate_subject_trans_filtered_results.jsonl\n",
            "Sentence (Good): Tina revealed Margaret.\n",
            "Sentence (Bad): The horse revealed Margaret.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -67.14756774902344\n",
            "  Response 2: Score = -64.80010986328125\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -67.14756774902344\n",
            "  Filtered Response 2: Score = -64.80010986328125\n",
            "========================================\n",
            "Sentence (Good): Danielle visited Irene.\n",
            "Sentence (Bad): The eye visited Irene.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -78.10968780517578\n",
            "  Response 2: Score = -71.2882080078125\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -78.10968780517578\n",
            "  Filtered Response 2: Score = -71.2882080078125\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_causative_filtered_results.jsonl\n",
            "Sentence (Good): Aaron breaks the glass.\n",
            "Sentence (Bad): Aaron appeared the glass.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -47.090126037597656\n",
            "  Response 2: Score = -52.29072189331055\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -47.090126037597656\n",
            "  Filtered Response 2: Score = -52.29072189331055\n",
            "========================================\n",
            "Sentence (Good): April had dropped the truck.\n",
            "Sentence (Bad): April had existed the truck.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -47.8455696105957\n",
            "  Response 2: Score = -58.436195373535156\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -47.8455696105957\n",
            "  Filtered Response 2: Score = -58.436195373535156\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_complex_NP_island_filtered_results.jsonl\n",
            "Sentence (Good): Who aren't most hospitals that hadn't talked about most waitresses alarming?\n",
            "Sentence (Bad): Who aren't most waitresses alarming most hospitals that hadn't talked about?\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -122.97958374023438\n",
            "  Response 2: Score = -123.41478729248047\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -122.97958374023438\n",
            "  Filtered Response 2: Score = -123.41478729248047\n",
            "========================================\n",
            "Sentence (Good): Who hasn't this sister of these dancers who shocked Cheryl attacked?\n",
            "Sentence (Bad): Who hasn't Cheryl attacked this sister of these dancers who shocked?\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -131.2361297607422\n",
            "  Response 2: Score = -134.92172241210938\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -131.2361297607422\n",
            "  Filtered Response 2: Score = -134.92172241210938\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_coordinate_structure_constraint_complex_left_branch_filtered_results.jsonl\n",
            "Sentence (Good): What senators was Alicia approaching and some teachers scaring?\n",
            "Sentence (Bad): What was Alicia approaching senators and some teachers scaring?\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -130.29556274414062\n",
            "  Response 2: Score = -126.47265625\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -130.29556274414062\n",
            "  Filtered Response 2: Score = -126.47265625\n",
            "========================================\n",
            "Sentence (Good): Whose restaurants is Clyde exiting and Amelia talking about?\n",
            "Sentence (Bad): Whose is Clyde exiting restaurants and Amelia talking about?\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -138.97349548339844\n",
            "  Response 2: Score = -136.4945068359375\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -138.97349548339844\n",
            "  Filtered Response 2: Score = -136.4945068359375\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_coordinate_structure_constraint_object_extraction_filtered_results.jsonl\n",
            "Sentence (Good): Who were all men and Eric leaving?\n",
            "Sentence (Bad): Who were all men leaving and Eric?\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -75.54769134521484\n",
            "  Response 2: Score = -78.74105834960938\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -75.54769134521484\n",
            "  Filtered Response 2: Score = -78.74105834960938\n",
            "========================================\n",
            "Sentence (Good): Who will Elizabeth and Gregory cure?\n",
            "Sentence (Bad): Who could Elizabeth cure and Gregory?\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -87.36549377441406\n",
            "  Response 2: Score = -89.03614044189453\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -87.36549377441406\n",
            "  Filtered Response 2: Score = -89.03614044189453\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_determiner_noun_agreement_1_filtered_results.jsonl\n",
            "Sentence (Good): Raymond is selling this sketch.\n",
            "Sentence (Bad): Raymond is selling this sketches.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -53.79633331298828\n",
            "  Response 2: Score = -56.05717849731445\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -53.79633331298828\n",
            "  Filtered Response 2: Score = -56.05717849731445\n",
            "========================================\n",
            "Sentence (Good): Craig explored that grocery store.\n",
            "Sentence (Bad): Craig explored that grocery stores.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -62.49322509765625\n",
            "  Response 2: Score = -65.47412872314453\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -62.49322509765625\n",
            "  Filtered Response 2: Score = -65.47412872314453\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_determiner_noun_agreement_2_filtered_results.jsonl\n",
            "Sentence (Good): Some dog stunned this committee.\n",
            "Sentence (Bad): Some dog stunned these committee.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -65.84656524658203\n",
            "  Response 2: Score = -71.20519256591797\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -65.84656524658203\n",
            "  Filtered Response 2: Score = -71.20519256591797\n",
            "========================================\n",
            "Sentence (Good): Tracy passed these art galleries.\n",
            "Sentence (Bad): Tracy passed this art galleries.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -67.49996185302734\n",
            "  Response 2: Score = -68.54092407226562\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -67.49996185302734\n",
            "  Filtered Response 2: Score = -68.54092407226562\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_determiner_noun_agreement_irregular_1_filtered_results.jsonl\n",
            "Sentence (Good): Laurie hasn't lifted those cacti.\n",
            "Sentence (Bad): Laurie hasn't lifted those cactus.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -71.7410888671875\n",
            "  Response 2: Score = -60.884830474853516\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -71.7410888671875\n",
            "  Filtered Response 2: Score = -60.884830474853516\n",
            "========================================\n",
            "Sentence (Good): Adam hadn't discussed these analyses.\n",
            "Sentence (Bad): Adam hadn't discussed these analysis.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -62.13485336303711\n",
            "  Response 2: Score = -56.70856857299805\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -62.13485336303711\n",
            "  Filtered Response 2: Score = -56.70856857299805\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_determiner_noun_agreement_irregular_2_filtered_results.jsonl\n",
            "Sentence (Good): All boys boast about that child.\n",
            "Sentence (Bad): All boys boast about those child.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -60.62528991699219\n",
            "  Response 2: Score = -65.03822326660156\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -60.62528991699219\n",
            "  Filtered Response 2: Score = -65.03822326660156\n",
            "========================================\n",
            "Sentence (Good): Candice has taken that axis.\n",
            "Sentence (Bad): Candice has taken those axis.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -67.05216217041016\n",
            "  Response 2: Score = -66.81275177001953\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -67.05216217041016\n",
            "  Filtered Response 2: Score = -66.81275177001953\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_determiner_noun_agreement_with_adj_2_filtered_results.jsonl\n",
            "Sentence (Good): Cynthia scans these hard books.\n",
            "Sentence (Bad): Cynthia scans this hard books.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -86.11959838867188\n",
            "  Response 2: Score = -87.64860534667969\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -86.11959838867188\n",
            "  Filtered Response 2: Score = -87.64860534667969\n",
            "========================================\n",
            "Sentence (Good): Donna might hire this serious actress.\n",
            "Sentence (Bad): Donna might hire these serious actress.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -63.321128845214844\n",
            "  Response 2: Score = -71.0591812133789\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -63.321128845214844\n",
            "  Filtered Response 2: Score = -71.0591812133789\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_determiner_noun_agreement_with_adj_irregular_1_filtered_results.jsonl\n",
            "Sentence (Good): Some waiters broke this lost foot.\n",
            "Sentence (Bad): Some waiters broke this lost feet.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -72.6175308227539\n",
            "  Response 2: Score = -75.6087417602539\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -72.6175308227539\n",
            "  Filtered Response 2: Score = -75.6087417602539\n",
            "========================================\n",
            "Sentence (Good): The company talks about those big women.\n",
            "Sentence (Bad): The company talks about those big woman.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -62.09988021850586\n",
            "  Response 2: Score = -66.62650299072266\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -62.09988021850586\n",
            "  Filtered Response 2: Score = -66.62650299072266\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_determiner_noun_agreement_with_adj_irregular_2_filtered_results.jsonl\n",
            "Sentence (Good): Alexander didn't walk through that new oasis.\n",
            "Sentence (Bad): Alexander didn't walk through those new oasis.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -67.54911804199219\n",
            "  Response 2: Score = -68.90502166748047\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -67.54911804199219\n",
            "  Filtered Response 2: Score = -68.90502166748047\n",
            "========================================\n",
            "Sentence (Good): This hair irritates these old alumni.\n",
            "Sentence (Bad): This hair irritates this old alumni.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -73.0437240600586\n",
            "  Response 2: Score = -73.25508880615234\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -73.0437240600586\n",
            "  Filtered Response 2: Score = -73.25508880615234\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_determiner_noun_agreement_with_adjective_1_filtered_results.jsonl\n",
            "Sentence (Good): Rebecca was criticizing those good documentaries.\n",
            "Sentence (Bad): Rebecca was criticizing those good documentary.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -72.50897979736328\n",
            "  Response 2: Score = -77.13291931152344\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -72.50897979736328\n",
            "  Filtered Response 2: Score = -77.13291931152344\n",
            "========================================\n",
            "Sentence (Good): Some college campus embarrassed those bad legislatures.\n",
            "Sentence (Bad): Some college campus embarrassed those bad legislature.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -98.63931274414062\n",
            "  Response 2: Score = -97.54975128173828\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -98.63931274414062\n",
            "  Filtered Response 2: Score = -97.54975128173828\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_distractor_agreement_relational_noun_filtered_results.jsonl\n",
            "Sentence (Good): A niece of most senators hasn't descended most slopes.\n",
            "Sentence (Bad): A niece of most senators haven't descended most slopes.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -106.96408081054688\n",
            "  Response 2: Score = -107.36480712890625\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -106.96408081054688\n",
            "  Filtered Response 2: Score = -107.36480712890625\n",
            "========================================\n",
            "Sentence (Good): The sketch of those trucks hasn't hurt Alan.\n",
            "Sentence (Bad): The sketch of those trucks haven't hurt Alan.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -92.20588684082031\n",
            "  Response 2: Score = -92.3485336303711\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -92.20588684082031\n",
            "  Filtered Response 2: Score = -92.3485336303711\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_distractor_agreement_relative_clause_filtered_results.jsonl\n",
            "Sentence (Good): This customer who had visited most children has worn some shoes.\n",
            "Sentence (Bad): This customer who had visited most children have worn some shoes.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -91.47005462646484\n",
            "  Response 2: Score = -91.57172393798828\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -91.47005462646484\n",
            "  Filtered Response 2: Score = -91.57172393798828\n",
            "========================================\n",
            "Sentence (Good): Boys that aren't disturbing Natalie suffer.\n",
            "Sentence (Bad): Boys that aren't disturbing Natalie suffers.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -93.41608428955078\n",
            "  Response 2: Score = -95.3275375366211\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -93.41608428955078\n",
            "  Filtered Response 2: Score = -95.3275375366211\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_drop_argument_filtered_results.jsonl\n",
            "Sentence (Good): Travis is touring.\n",
            "Sentence (Bad): Travis is revealing.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -53.807003021240234\n",
            "  Response 2: Score = -53.41844177246094\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -53.807003021240234\n",
            "  Filtered Response 2: Score = -53.41844177246094\n",
            "========================================\n",
            "Sentence (Good): Noah approached.\n",
            "Sentence (Bad): Noah works with.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -36.1730842590332\n",
            "  Response 2: Score = -41.219051361083984\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -36.1730842590332\n",
            "  Filtered Response 2: Score = -41.219051361083984\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_ellipsis_n_bar_1_filtered_results.jsonl\n",
            "Sentence (Good): Dawn's ex-husband wasn't going to one rough grocery store and Becca wasn't going to many.\n",
            "Sentence (Bad): Dawn's ex-husband wasn't going to one grocery store and Becca wasn't going to many rough.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -159.13278198242188\n",
            "  Response 2: Score = -163.35220336914062\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -159.13278198242188\n",
            "  Filtered Response 2: Score = -163.35220336914062\n",
            "========================================\n",
            "Sentence (Good): Most men irritates two happy students and a snake irritates three.\n",
            "Sentence (Bad): Most men irritates two students and a snake irritates three happy.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -106.2270736694336\n",
            "  Response 2: Score = -110.20185089111328\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -106.2270736694336\n",
            "  Filtered Response 2: Score = -110.20185089111328\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_ellipsis_n_bar_2_filtered_results.jsonl\n",
            "Sentence (Good): A friend of Pamela hasn't attacked one person and Ann hasn't attacked more unsure person.\n",
            "Sentence (Bad): A friend of Pamela hasn't attacked one unemployed person and Ann hasn't attacked more unsure.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -168.3055419921875\n",
            "  Response 2: Score = -171.82144165039062\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -168.3055419921875\n",
            "  Filtered Response 2: Score = -171.82144165039062\n",
            "========================================\n",
            "Sentence (Good): That legislature has three peppers and Charles has at least as many small peppers.\n",
            "Sentence (Bad): That legislature has three hidden peppers and Charles has at least as many small.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -127.70059204101562\n",
            "  Response 2: Score = -127.1512222290039\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -127.70059204101562\n",
            "  Filtered Response 2: Score = -127.1512222290039\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_existential_there_object_raising_filtered_results.jsonl\n",
            "Sentence (Good): William has declared there to be no guests getting fired.\n",
            "Sentence (Bad): William has obliged there to be no guests getting fired.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -75.63134765625\n",
            "  Response 2: Score = -81.259521484375\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -75.63134765625\n",
            "  Filtered Response 2: Score = -81.259521484375\n",
            "========================================\n",
            "Sentence (Good): Richard believed there to be many boxes stunning Ellen.\n",
            "Sentence (Bad): Richard sways there to be many boxes stunning Ellen.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -95.7725601196289\n",
            "  Response 2: Score = -106.72960662841797\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -95.7725601196289\n",
            "  Filtered Response 2: Score = -106.72960662841797\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_existential_there_quantifiers_1_filtered_results.jsonl\n",
            "Sentence (Good): There was a documentary about music irritating Allison.\n",
            "Sentence (Bad): There was each documentary about music irritating Allison.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -87.55553436279297\n",
            "  Response 2: Score = -96.47587585449219\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -87.55553436279297\n",
            "  Filtered Response 2: Score = -96.47587585449219\n",
            "========================================\n",
            "Sentence (Good): There were no legislatures working hard.\n",
            "Sentence (Bad): There were most legislatures working hard.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -72.4055404663086\n",
            "  Response 2: Score = -75.45701599121094\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -72.4055404663086\n",
            "  Filtered Response 2: Score = -75.45701599121094\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_existential_there_quantifiers_2_filtered_results.jsonl\n",
            "Sentence (Good): Every fish was there astounding Sally.\n",
            "Sentence (Bad): There was every fish astounding Sally.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -81.23126983642578\n",
            "  Response 2: Score = -79.10398864746094\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -81.23126983642578\n",
            "  Filtered Response 2: Score = -79.10398864746094\n",
            "========================================\n",
            "Sentence (Good): All sisters of Roger weren't there going to this school.\n",
            "Sentence (Bad): There weren't all sisters of Roger going to this school.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -97.93501281738281\n",
            "  Response 2: Score = -94.7609634399414\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -97.93501281738281\n",
            "  Filtered Response 2: Score = -94.7609634399414\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_existential_there_subject_raising_filtered_results.jsonl\n",
            "Sentence (Good): There is soon to be a cat existing.\n",
            "Sentence (Bad): There is willing to be a cat existing.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -66.2083511352539\n",
            "  Response 2: Score = -65.66854095458984\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -66.2083511352539\n",
            "  Filtered Response 2: Score = -65.66854095458984\n",
            "========================================\n",
            "Sentence (Good): There was bound to be a fish escaping.\n",
            "Sentence (Bad): There was unable to be a fish escaping.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -61.305694580078125\n",
            "  Response 2: Score = -62.74300003051758\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -61.305694580078125\n",
            "  Filtered Response 2: Score = -62.74300003051758\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_expletive_it_object_raising_filtered_results.jsonl\n",
            "Sentence (Good): Tara would ascertain it to be noteworthy that Kenneth didn't wash.\n",
            "Sentence (Bad): Tara wouldn't entice it to be noteworthy that Kenneth didn't wash.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -139.77687072753906\n",
            "  Response 2: Score = -143.87759399414062\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -139.77687072753906\n",
            "  Filtered Response 2: Score = -143.87759399414062\n",
            "========================================\n",
            "Sentence (Good): Carla could declare it to be not so important that these doctors observe Rhonda.\n",
            "Sentence (Bad): Carla can convince it to be not so important that these doctors observe Rhonda.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -134.46267700195312\n",
            "  Response 2: Score = -135.997802734375\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -134.46267700195312\n",
            "  Filtered Response 2: Score = -135.997802734375\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_inchoative_filtered_results.jsonl\n",
            "Sentence (Good): Patricia had changed.\n",
            "Sentence (Bad): Patricia had forgotten.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -50.430667877197266\n",
            "  Response 2: Score = -51.81504440307617\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -50.430667877197266\n",
            "  Filtered Response 2: Score = -51.81504440307617\n",
            "========================================\n",
            "Sentence (Good): A lot of closets could fling open.\n",
            "Sentence (Bad): A lot of closets could buy.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -78.02945709228516\n",
            "  Response 2: Score = -63.49509811401367\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -78.02945709228516\n",
            "  Filtered Response 2: Score = -63.49509811401367\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_intransitive_filtered_results.jsonl\n",
            "Sentence (Good): Todd can't yawn.\n",
            "Sentence (Bad): Todd can't walk through.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -44.80096435546875\n",
            "  Response 2: Score = -39.25130081176758\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -44.80096435546875\n",
            "  Filtered Response 2: Score = -39.25130081176758\n",
            "========================================\n",
            "Sentence (Good): Some guests hadn't left.\n",
            "Sentence (Bad): Some guests hadn't boasted about.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -54.83964920043945\n",
            "  Response 2: Score = -66.37108612060547\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -54.83964920043945\n",
            "  Filtered Response 2: Score = -66.37108612060547\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_irregular_past_participle_adjectives_filtered_results.jsonl\n",
            "Sentence (Good): The hidden offspring aren't confident.\n",
            "Sentence (Bad): The hid offspring aren't confident.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -65.18224334716797\n",
            "  Response 2: Score = -70.42965698242188\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -65.18224334716797\n",
            "  Filtered Response 2: Score = -70.42965698242188\n",
            "========================================\n",
            "Sentence (Good): The hidden bicycles weren't exposed.\n",
            "Sentence (Bad): The hid bicycles weren't exposed.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -70.40579986572266\n",
            "  Response 2: Score = -73.68698120117188\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -70.40579986572266\n",
            "  Filtered Response 2: Score = -73.68698120117188\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_irregular_past_participle_verbs_filtered_results.jsonl\n",
            "Sentence (Good): Teresa hid every senator.\n",
            "Sentence (Bad): Teresa hidden every senator.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -63.87178039550781\n",
            "  Response 2: Score = -66.89855194091797\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -63.87178039550781\n",
            "  Filtered Response 2: Score = -66.89855194091797\n",
            "========================================\n",
            "Sentence (Good): The mushroom went bad.\n",
            "Sentence (Bad): The mushroom gone bad.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -51.892677307128906\n",
            "  Response 2: Score = -53.58387756347656\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -51.892677307128906\n",
            "  Filtered Response 2: Score = -53.58387756347656\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_irregular_plural_subject_verb_agreement_1_filtered_results.jsonl\n",
            "Sentence (Good): Those radii have scared that teenager.\n",
            "Sentence (Bad): Those radii has scared that teenager.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -80.40309143066406\n",
            "  Response 2: Score = -80.16614532470703\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -80.40309143066406\n",
            "  Filtered Response 2: Score = -80.16614532470703\n",
            "========================================\n",
            "Sentence (Good): This goose isn't bothering Edward.\n",
            "Sentence (Bad): This goose weren't bothering Edward.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -71.4814682006836\n",
            "  Response 2: Score = -76.02880096435547\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -71.4814682006836\n",
            "  Filtered Response 2: Score = -76.02880096435547\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_irregular_plural_subject_verb_agreement_2_filtered_results.jsonl\n",
            "Sentence (Good): The women meet.\n",
            "Sentence (Bad): The woman meet.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -45.95988845825195\n",
            "  Response 2: Score = -45.28618621826172\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -45.95988845825195\n",
            "  Filtered Response 2: Score = -45.28618621826172\n",
            "========================================\n",
            "Sentence (Good): The child isn't attacking Becky.\n",
            "Sentence (Bad): The children isn't attacking Becky.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -70.80554962158203\n",
            "  Response 2: Score = -70.06837463378906\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -70.80554962158203\n",
            "  Filtered Response 2: Score = -70.06837463378906\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_left_branch_island_echo_question_filtered_results.jsonl\n",
            "Sentence (Good): Irene had messed up whose rug?\n",
            "Sentence (Bad): Whose had Irene messed up rug?\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -63.92177200317383\n",
            "  Response 2: Score = -93.1418228149414\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -63.92177200317383\n",
            "  Filtered Response 2: Score = -93.1418228149414\n",
            "========================================\n",
            "Sentence (Good): Edward has returned to which customers?\n",
            "Sentence (Bad): Which has Edward returned to customers?\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -58.48808670043945\n",
            "  Response 2: Score = -75.4960708618164\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -58.48808670043945\n",
            "  Filtered Response 2: Score = -75.4960708618164\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_left_branch_island_simple_question_filtered_results.jsonl\n",
            "Sentence (Good): Whose museums had Dana alarmed?\n",
            "Sentence (Bad): Whose had Dana alarmed museums?\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -109.42967987060547\n",
            "  Response 2: Score = -111.91963195800781\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -109.42967987060547\n",
            "  Filtered Response 2: Score = -111.91963195800781\n",
            "========================================\n",
            "Sentence (Good): Whose hat should Tonya wear?\n",
            "Sentence (Bad): Whose should Tonya wear hat?\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -91.13148498535156\n",
            "  Response 2: Score = -90.8215103149414\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -91.13148498535156\n",
            "  Filtered Response 2: Score = -90.8215103149414\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_matrix_question_npi_licensor_present_filtered_results.jsonl\n",
            "Sentence (Good): Had Bruce ever played?\n",
            "Sentence (Bad): Bruce had ever played.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -60.53173828125\n",
            "  Response 2: Score = -44.970760345458984\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -60.53173828125\n",
            "  Filtered Response 2: Score = -44.970760345458984\n",
            "========================================\n",
            "Sentence (Good): Had Patrick ever answered?\n",
            "Sentence (Bad): Patrick had ever answered.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -62.28032302856445\n",
            "  Response 2: Score = -43.41282272338867\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -62.28032302856445\n",
            "  Filtered Response 2: Score = -43.41282272338867\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_npi_present_1_filtered_results.jsonl\n",
            "Sentence (Good): Even Suzanne has really joked around.\n",
            "Sentence (Bad): Even Suzanne has ever joked around.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -93.25896453857422\n",
            "  Response 2: Score = -91.89635467529297\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -93.25896453857422\n",
            "  Filtered Response 2: Score = -91.89635467529297\n",
            "========================================\n",
            "Sentence (Good): Even many teenagers clearly boycott those legislatures.\n",
            "Sentence (Bad): Even many teenagers ever boycott those legislatures.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -108.20529174804688\n",
            "  Response 2: Score = -103.70183563232422\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -108.20529174804688\n",
            "  Filtered Response 2: Score = -103.70183563232422\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_npi_present_2_filtered_results.jsonl\n",
            "Sentence (Good): Tamara really exited those mountains.\n",
            "Sentence (Bad): Tamara ever exited those mountains.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -70.23802185058594\n",
            "  Response 2: Score = -74.46456909179688\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -70.23802185058594\n",
            "  Filtered Response 2: Score = -74.46456909179688\n",
            "========================================\n",
            "Sentence (Good): Karen could certainly boycott this association.\n",
            "Sentence (Bad): Karen could ever boycott this association.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -74.02774047851562\n",
            "  Response 2: Score = -72.98263549804688\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -74.02774047851562\n",
            "  Filtered Response 2: Score = -72.98263549804688\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_only_npi_licensor_present_filtered_results.jsonl\n",
            "Sentence (Good): Only Bill would ever complain.\n",
            "Sentence (Bad): Even Bill would ever complain.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -66.83091735839844\n",
            "  Response 2: Score = -68.32489013671875\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -66.83091735839844\n",
            "  Filtered Response 2: Score = -68.32489013671875\n",
            "========================================\n",
            "Sentence (Good): Only Lori had ever healed Carl.\n",
            "Sentence (Bad): Even Lori had ever healed Carl.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -100.91043090820312\n",
            "  Response 2: Score = -100.40814208984375\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -100.91043090820312\n",
            "  Filtered Response 2: Score = -100.40814208984375\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_only_npi_scope_filtered_results.jsonl\n",
            "Sentence (Good): Only that story about Monet that Mark would research does ever worry Richard.\n",
            "Sentence (Bad): That story about Monet that only Mark would research does ever worry Richard.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -161.60072326660156\n",
            "  Response 2: Score = -164.18353271484375\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -161.60072326660156\n",
            "  Filtered Response 2: Score = -164.18353271484375\n",
            "========================================\n",
            "Sentence (Good): Only a popsicle that Danielle admires ever freezes.\n",
            "Sentence (Bad): A popsicle that only Danielle admires ever freezes.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -127.75532531738281\n",
            "  Response 2: Score = -132.58160400390625\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -127.75532531738281\n",
            "  Filtered Response 2: Score = -132.58160400390625\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_passive_1_filtered_results.jsonl\n",
            "Sentence (Good): Lucille's sisters are confused by Amy.\n",
            "Sentence (Bad): Lucille's sisters are communicated by Amy.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -86.65486145019531\n",
            "  Response 2: Score = -89.65422821044922\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -86.65486145019531\n",
            "  Filtered Response 2: Score = -89.65422821044922\n",
            "========================================\n",
            "Sentence (Good): A lot of hospitals were astounded by some actress.\n",
            "Sentence (Bad): A lot of hospitals were cooperated by some actress.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -87.54402160644531\n",
            "  Response 2: Score = -80.64081573486328\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -87.54402160644531\n",
            "  Filtered Response 2: Score = -80.64081573486328\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_passive_2_filtered_results.jsonl\n",
            "Sentence (Good): A lot of nieces of some actor aren't scared.\n",
            "Sentence (Bad): A lot of nieces of some actor aren't wept.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -93.74897766113281\n",
            "  Response 2: Score = -98.57749938964844\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -93.74897766113281\n",
            "  Filtered Response 2: Score = -98.57749938964844\n",
            "========================================\n",
            "Sentence (Good): Mitchell's grandfathers are forgotten.\n",
            "Sentence (Bad): Mitchell's grandfathers are concurred.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -74.17264556884766\n",
            "  Response 2: Score = -78.90625\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -74.17264556884766\n",
            "  Filtered Response 2: Score = -78.90625\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_principle_A_c_command_filtered_results.jsonl\n",
            "Sentence (Good): A lot of patients who can sell some couch didn't investigate themselves.\n",
            "Sentence (Bad): A lot of patients who can sell some couch didn't investigate itself.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -102.76801300048828\n",
            "  Response 2: Score = -103.96766662597656\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -102.76801300048828\n",
            "  Filtered Response 2: Score = -103.96766662597656\n",
            "========================================\n",
            "Sentence (Good): A lot of actresses that thought about Alice healed themselves.\n",
            "Sentence (Bad): A lot of actresses that thought about Alice healed herself.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -108.65715789794922\n",
            "  Response 2: Score = -107.5182876586914\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -108.65715789794922\n",
            "  Filtered Response 2: Score = -107.5182876586914\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_principle_A_case_1_filtered_results.jsonl\n",
            "Sentence (Good): The teenagers explain that they aren't breaking all glasses.\n",
            "Sentence (Bad): The teenagers explain that themselves aren't breaking all glasses.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -87.30258178710938\n",
            "  Response 2: Score = -95.81526947021484\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -87.30258178710938\n",
            "  Filtered Response 2: Score = -95.81526947021484\n",
            "========================================\n",
            "Sentence (Good): Carl can't imagine that he complained about Lisa.\n",
            "Sentence (Bad): Carl can't imagine that himself complained about Lisa.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -76.18037414550781\n",
            "  Response 2: Score = -83.89236450195312\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -76.18037414550781\n",
            "  Filtered Response 2: Score = -83.89236450195312\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_principle_A_case_2_filtered_results.jsonl\n",
            "Sentence (Good): Eric imagines himself taking every rug.\n",
            "Sentence (Bad): Eric imagines himself took every rug.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -70.8356704711914\n",
            "  Response 2: Score = -70.66544342041016\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -70.8356704711914\n",
            "  Filtered Response 2: Score = -70.66544342041016\n",
            "========================================\n",
            "Sentence (Good): Stacy imagines herself praising this actress.\n",
            "Sentence (Bad): Stacy imagines herself praises this actress.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -84.41539764404297\n",
            "  Response 2: Score = -87.22415161132812\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -84.41539764404297\n",
            "  Filtered Response 2: Score = -87.22415161132812\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_principle_A_domain_1_filtered_results.jsonl\n",
            "Sentence (Good): Carla had explained that Samuel has discussed her.\n",
            "Sentence (Bad): Carla had explained that Samuel has discussed herself.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -92.3412857055664\n",
            "  Response 2: Score = -95.30757904052734\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -92.3412857055664\n",
            "  Filtered Response 2: Score = -95.30757904052734\n",
            "========================================\n",
            "Sentence (Good): Alice hadn't said that some people weren't escaping from her.\n",
            "Sentence (Bad): Alice hadn't said that some people weren't escaping from herself.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -81.13373565673828\n",
            "  Response 2: Score = -84.35564422607422\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -81.13373565673828\n",
            "  Filtered Response 2: Score = -84.35564422607422\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_principle_A_domain_2_filtered_results.jsonl\n",
            "Sentence (Good): Donald can imagine those college campuses are boring themselves.\n",
            "Sentence (Bad): Donald can imagine those college campuses are boring himself.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -92.03740692138672\n",
            "  Response 2: Score = -94.29401397705078\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -92.03740692138672\n",
            "  Filtered Response 2: Score = -94.29401397705078\n",
            "========================================\n",
            "Sentence (Good): Gerald was explaining Patricia was revealing herself.\n",
            "Sentence (Bad): Gerald was explaining Patricia was revealing himself.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -90.95425415039062\n",
            "  Response 2: Score = -91.81813049316406\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -90.95425415039062\n",
            "  Filtered Response 2: Score = -91.81813049316406\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_principle_A_domain_3_filtered_results.jsonl\n",
            "Sentence (Good): Steven explains Kayla won't hurt herself.\n",
            "Sentence (Bad): Kayla explains Steven won't hurt herself.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -87.88106536865234\n",
            "  Response 2: Score = -90.7484130859375\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -87.88106536865234\n",
            "  Filtered Response 2: Score = -90.7484130859375\n",
            "========================================\n",
            "Sentence (Good): Gina explains Alan fires himself.\n",
            "Sentence (Bad): Alan explains Gina fires himself.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -74.31083679199219\n",
            "  Response 2: Score = -76.85281372070312\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -74.31083679199219\n",
            "  Filtered Response 2: Score = -76.85281372070312\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_principle_A_reconstruction_filtered_results.jsonl\n",
            "Sentence (Good): It's himself that this cashier attacked.\n",
            "Sentence (Bad): It's himself that attacked this cashier.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -77.77303314208984\n",
            "  Response 2: Score = -72.20669555664062\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -77.77303314208984\n",
            "  Filtered Response 2: Score = -72.20669555664062\n",
            "========================================\n",
            "Sentence (Good): It's herself that Andrea attacked.\n",
            "Sentence (Bad): It's herself that attacked Andrea.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -89.68766784667969\n",
            "  Response 2: Score = -87.81752014160156\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -89.68766784667969\n",
            "  Filtered Response 2: Score = -87.81752014160156\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_regular_plural_subject_verb_agreement_1_filtered_results.jsonl\n",
            "Sentence (Good): Paula references Robert.\n",
            "Sentence (Bad): Paula reference Robert.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -66.84180450439453\n",
            "  Response 2: Score = -63.04234313964844\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -66.84180450439453\n",
            "  Filtered Response 2: Score = -63.04234313964844\n",
            "========================================\n",
            "Sentence (Good): Most legislatures haven't disliked children.\n",
            "Sentence (Bad): Most legislatures hasn't disliked children.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -78.9950180053711\n",
            "  Response 2: Score = -80.88774108886719\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -78.9950180053711\n",
            "  Filtered Response 2: Score = -80.88774108886719\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_regular_plural_subject_verb_agreement_2_filtered_results.jsonl\n",
            "Sentence (Good): The students perform.\n",
            "Sentence (Bad): The student perform.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -47.302635192871094\n",
            "  Response 2: Score = -46.50165557861328\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -47.302635192871094\n",
            "  Filtered Response 2: Score = -46.50165557861328\n",
            "========================================\n",
            "Sentence (Good): The associations talk about Stacey.\n",
            "Sentence (Bad): The association talk about Stacey.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -87.11956787109375\n",
            "  Response 2: Score = -82.09849548339844\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -87.11956787109375\n",
            "  Filtered Response 2: Score = -82.09849548339844\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_sentential_negation_npi_licensor_present_filtered_results.jsonl\n",
            "Sentence (Good): Teresa had not ever sold a movie theater.\n",
            "Sentence (Bad): Teresa had probably ever sold a movie theater.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -79.07635498046875\n",
            "  Response 2: Score = -81.02762603759766\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -79.07635498046875\n",
            "  Filtered Response 2: Score = -81.02762603759766\n",
            "========================================\n",
            "Sentence (Good): Allison has not ever taken that ice cream.\n",
            "Sentence (Bad): Allison has fortunately ever taken that ice cream.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -59.21613311767578\n",
            "  Response 2: Score = -70.67961883544922\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -59.21613311767578\n",
            "  Filtered Response 2: Score = -70.67961883544922\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_sentential_negation_npi_scope_filtered_results.jsonl\n",
            "Sentence (Good): The associations that had worried Cynthia have not ever planned to shock every actress.\n",
            "Sentence (Bad): The associations that had not worried Cynthia have ever planned to shock every actress.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -153.87799072265625\n",
            "  Response 2: Score = -153.31431579589844\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -153.87799072265625\n",
            "  Filtered Response 2: Score = -153.31431579589844\n",
            "========================================\n",
            "Sentence (Good): Every son of Jerry who has insulted Jerry can not ever die.\n",
            "Sentence (Bad): Every son of Jerry who has not insulted Jerry can ever die.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -122.67073059082031\n",
            "  Response 2: Score = -123.55692291259766\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -122.67073059082031\n",
            "  Filtered Response 2: Score = -123.55692291259766\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_sentential_subject_island_filtered_results.jsonl\n",
            "Sentence (Good): Who had the patients' cleaning those banks upset.\n",
            "Sentence (Bad): Who had the patients' cleaning upset those banks.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -87.96707153320312\n",
            "  Response 2: Score = -88.01204681396484\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -87.96707153320312\n",
            "  Filtered Response 2: Score = -88.01204681396484\n",
            "========================================\n",
            "Sentence (Good): Who has the waitress's observing Christine bothered.\n",
            "Sentence (Bad): Who has the waitress's observing bothered Christine.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -101.64955139160156\n",
            "  Response 2: Score = -104.66534423828125\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -101.64955139160156\n",
            "  Filtered Response 2: Score = -104.66534423828125\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_superlative_quantifiers_1_filtered_results.jsonl\n",
            "Sentence (Good): No girl attacked fewer than two waiters.\n",
            "Sentence (Bad): No girl attacked at most two waiters.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -76.3647232055664\n",
            "  Response 2: Score = -80.05152130126953\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -76.3647232055664\n",
            "  Filtered Response 2: Score = -80.05152130126953\n",
            "========================================\n",
            "Sentence (Good): No person would bring fewer than three gates.\n",
            "Sentence (Bad): No person would bring at most three gates.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -77.02040100097656\n",
            "  Response 2: Score = -78.57962799072266\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -77.02040100097656\n",
            "  Filtered Response 2: Score = -78.57962799072266\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_superlative_quantifiers_2_filtered_results.jsonl\n",
            "Sentence (Good): The teenager does tour at most nine restaurants.\n",
            "Sentence (Bad): No teenager does tour at most nine restaurants.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -88.93063354492188\n",
            "  Response 2: Score = -88.52898406982422\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -88.93063354492188\n",
            "  Filtered Response 2: Score = -88.52898406982422\n",
            "========================================\n",
            "Sentence (Good): That car looks like at least seven prints.\n",
            "Sentence (Bad): No car looks like at least seven prints.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -65.5179672241211\n",
            "  Response 2: Score = -65.99455261230469\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -65.5179672241211\n",
            "  Filtered Response 2: Score = -65.99455261230469\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_supplement_hypernym_results.jsonl\n",
            "Sentence (Good): If she has a dog, it must be the case that she has a mammal.\n",
            "Sentence (Bad): If she has a dog, it must be the case that she has a chihuahua.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -91.93763732910156\n",
            "  Response 2: Score = -90.09261322021484\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -91.93763732910156\n",
            "  Filtered Response 2: Score = -90.09261322021484\n",
            "========================================\n",
            "Sentence (Good): She doesn't have a dog, so she doesn't have a chihuahua.\n",
            "Sentence (Bad): She doesn't have a chihuahua, so she doesn't have a dog.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -67.60074615478516\n",
            "  Response 2: Score = -68.43138122558594\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -67.60074615478516\n",
            "  Filtered Response 2: Score = -68.43138122558594\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_supplement_qa_congruence_easy_results.jsonl\n",
            "Sentence (Good): What did you get?\n",
            "I got a chair.\n",
            "Sentence (Bad): What did you get?\n",
            "I got a teacher.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -94.76325988769531\n",
            "  Response 2: Score = -96.82717895507812\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -94.76325988769531\n",
            "  Filtered Response 2: Score = -96.82717895507812\n",
            "========================================\n",
            "Sentence (Good): A: What did you sell?\n",
            "B: A chair.\n",
            "Sentence (Bad): A: What did you sell?\n",
            "B: Sarah.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -145.27706909179688\n",
            "  Response 2: Score = -136.2298126220703\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -145.27706909179688\n",
            "  Filtered Response 2: Score = -136.2298126220703\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_supplement_qa_congruence_tricky_results.jsonl\n",
            "Sentence (Good): Who cleaned?\n",
            "David cleaned.\n",
            "Sentence (Bad): Who cleaned?\n",
            "The patio cleaned.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -95.30577087402344\n",
            "  Response 2: Score = -112.02981567382812\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -95.30577087402344\n",
            "  Filtered Response 2: Score = -112.02981567382812\n",
            "========================================\n",
            "Sentence (Good): A: Who cleaned?\n",
            "B: Sarah.\n",
            "Sentence (Bad): A: Who cleaned?\n",
            "B: The patio.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -127.90410614013672\n",
            "  Response 2: Score = -144.58880615234375\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -127.90410614013672\n",
            "  Filtered Response 2: Score = -144.58880615234375\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_supplement_subject_aux_inversion_results.jsonl\n",
            "Sentence (Good): Is the novel he is putting away from the library?\n",
            "Sentence (Bad): Is the novel he putting away is from the library?\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -71.28730773925781\n",
            "  Response 2: Score = -82.25486755371094\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -71.28730773925781\n",
            "  Filtered Response 2: Score = -82.25486755371094\n",
            "========================================\n",
            "Sentence (Good): Has every possibility she has ever tested failed miserably?\n",
            "Sentence (Bad): Has every possibility she ever tested has failed miserably?\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -92.98622131347656\n",
            "  Response 2: Score = -97.68853759765625\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -92.98622131347656\n",
            "  Filtered Response 2: Score = -97.68853759765625\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_supplement_turn_taking_results.jsonl\n",
            "Sentence (Good): David: Should you quit?\n",
            "Sarah: No, I shouldn't.\n",
            "Sentence (Bad): David: Should she quit?\n",
            "Sarah: No, I shouldn't.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -188.6990509033203\n",
            "  Response 2: Score = -192.83828735351562\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -188.6990509033203\n",
            "  Filtered Response 2: Score = -192.83828735351562\n",
            "========================================\n",
            "Sentence (Good): David: Should you meet him?\n",
            "Sarah: Yes, I should.\n",
            "Sentence (Bad): David: Should she meet him?\n",
            "Sarah: Yes, I should.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -192.462158203125\n",
            "  Response 2: Score = -197.35723876953125\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -192.462158203125\n",
            "  Filtered Response 2: Score = -197.35723876953125\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_tough_vs_raising_1_filtered_results.jsonl\n",
            "Sentence (Good): James is pleasant to flee from.\n",
            "Sentence (Bad): James is apt to flee from.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -57.319244384765625\n",
            "  Response 2: Score = -56.7142448425293\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -57.319244384765625\n",
            "  Filtered Response 2: Score = -56.7142448425293\n",
            "========================================\n",
            "Sentence (Good): Samuel's lawyer was easy to reference.\n",
            "Sentence (Bad): Samuel's lawyer was certain to reference.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -70.68089294433594\n",
            "  Response 2: Score = -77.19178009033203\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -70.68089294433594\n",
            "  Filtered Response 2: Score = -77.19178009033203\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_tough_vs_raising_2_filtered_results.jsonl\n",
            "Sentence (Good): Every hospital isn't about to tempt Tiffany to reference Matt.\n",
            "Sentence (Bad): Every hospital isn't fun to tempt Tiffany to reference Matt.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -131.6604766845703\n",
            "  Response 2: Score = -137.8477020263672\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -131.6604766845703\n",
            "  Filtered Response 2: Score = -137.8477020263672\n",
            "========================================\n",
            "Sentence (Good): Rachel was apt to talk to Alicia.\n",
            "Sentence (Bad): Rachel was exciting to talk to Alicia.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -82.65782165527344\n",
            "  Response 2: Score = -83.49813079833984\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -82.65782165527344\n",
            "  Filtered Response 2: Score = -83.49813079833984\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_transitive_filtered_results.jsonl\n",
            "Sentence (Good): Some turtles alarm Kimberley.\n",
            "Sentence (Bad): Some turtles come here Kimberley.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -90.47206115722656\n",
            "  Response 2: Score = -92.07476806640625\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -90.47206115722656\n",
            "  Filtered Response 2: Score = -92.07476806640625\n",
            "========================================\n",
            "Sentence (Good): Diane watched Alan.\n",
            "Sentence (Bad): Diane screamed Alan.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -68.54937744140625\n",
            "  Response 2: Score = -67.74076080322266\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -68.54937744140625\n",
            "  Filtered Response 2: Score = -67.74076080322266\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_wh_island_filtered_results.jsonl\n",
            "Sentence (Good): Who have those men revealed they helped?\n",
            "Sentence (Bad): Who have those men revealed who helped?\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -72.99333953857422\n",
            "  Response 2: Score = -72.85346984863281\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -72.99333953857422\n",
            "  Filtered Response 2: Score = -72.85346984863281\n",
            "========================================\n",
            "Sentence (Good): Who isn't Craig realizing he kisses?\n",
            "Sentence (Bad): Who isn't Craig realizing who kisses?\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -89.60424041748047\n",
            "  Response 2: Score = -88.5322265625\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -89.60424041748047\n",
            "  Filtered Response 2: Score = -88.5322265625\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_wh_questions_object_gap_filtered_results.jsonl\n",
            "Sentence (Good): Joel discovered the vase that Patricia might take.\n",
            "Sentence (Bad): Joel discovered what Patricia might take the vase.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -94.1142349243164\n",
            "  Response 2: Score = -93.19279479980469\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -94.1142349243164\n",
            "  Filtered Response 2: Score = -93.19279479980469\n",
            "========================================\n",
            "Sentence (Good): Rodney thought about many paintings that Wendy had thought about.\n",
            "Sentence (Bad): Rodney thought about what Wendy had thought about many paintings.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -99.28485870361328\n",
            "  Response 2: Score = -100.19953155517578\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -99.28485870361328\n",
            "  Filtered Response 2: Score = -100.19953155517578\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_wh_questions_subject_gap_filtered_results.jsonl\n",
            "Sentence (Good): Brian had questioned an association that can astound Diana.\n",
            "Sentence (Bad): Brian had questioned who an association can astound Diana.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -101.31950378417969\n",
            "  Response 2: Score = -106.27391815185547\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -101.31950378417969\n",
            "  Filtered Response 2: Score = -106.27391815185547\n",
            "========================================\n",
            "Sentence (Good): Leslie remembered some guest that has bothered women.\n",
            "Sentence (Bad): Leslie remembered who some guest has bothered women.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -81.1717758178711\n",
            "  Response 2: Score = -86.30223083496094\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -81.1717758178711\n",
            "  Filtered Response 2: Score = -86.30223083496094\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_wh_questions_subject_gap_long_distance_filtered_results.jsonl\n",
            "Sentence (Good): Dennis has seen this tooth that Kristin wasn't concealing that is astounding men.\n",
            "Sentence (Bad): Dennis has seen who this tooth that Kristin wasn't concealing is astounding men.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -132.22244262695312\n",
            "  Response 2: Score = -137.34817504882812\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -132.22244262695312\n",
            "  Filtered Response 2: Score = -137.34817504882812\n",
            "========================================\n",
            "Sentence (Good): Renee investigates these offspring that some drivers boast about that would heal some dog.\n",
            "Sentence (Bad): Renee investigates what these offspring that some drivers boast about would heal some dog.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -145.32269287109375\n",
            "  Response 2: Score = -149.6088409423828\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -145.32269287109375\n",
            "  Filtered Response 2: Score = -149.6088409423828\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_wh_vs_that_no_gap_filtered_results.jsonl\n",
            "Sentence (Good): Mark figured out that most governments appreciate Steve.\n",
            "Sentence (Bad): Mark figured out who most governments appreciate Steve.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -90.88096618652344\n",
            "  Response 2: Score = -94.47200012207031\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -90.88096618652344\n",
            "  Filtered Response 2: Score = -94.47200012207031\n",
            "========================================\n",
            "Sentence (Good): Danielle finds out that many organizations have alarmed Chad.\n",
            "Sentence (Bad): Danielle finds out who many organizations have alarmed Chad.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -114.33009338378906\n",
            "  Response 2: Score = -117.05484771728516\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -114.33009338378906\n",
            "  Filtered Response 2: Score = -117.05484771728516\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_wh_vs_that_no_gap_long_distance_filtered_results.jsonl\n",
            "Sentence (Good): Every association figured out that most drivers that forfeit investigated Irene.\n",
            "Sentence (Bad): Every association figured out who most drivers that forfeit investigated Irene.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -128.08615112304688\n",
            "  Response 2: Score = -128.9561309814453\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -128.08615112304688\n",
            "  Filtered Response 2: Score = -128.9561309814453\n",
            "========================================\n",
            "Sentence (Good): Kathleen was revealing that this actress that can sit down was skated around this museum.\n",
            "Sentence (Bad): Kathleen was revealing what this actress that can sit down was skated around this museum.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -130.887451171875\n",
            "  Response 2: Score = -134.16883850097656\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -130.887451171875\n",
            "  Filtered Response 2: Score = -134.16883850097656\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_wh_vs_that_with_gap_filtered_results.jsonl\n",
            "Sentence (Good): A lady has remembered who the actors conceal.\n",
            "Sentence (Bad): A lady has remembered that the actors conceal.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -80.00672912597656\n",
            "  Response 2: Score = -77.5322036743164\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -80.00672912597656\n",
            "  Filtered Response 2: Score = -77.5322036743164\n",
            "========================================\n",
            "Sentence (Good): Teenagers know what all ladies haven't examined.\n",
            "Sentence (Bad): Teenagers know that all ladies haven't examined.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -86.76231384277344\n",
            "  Response 2: Score = -84.82877349853516\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -86.76231384277344\n",
            "  Filtered Response 2: Score = -84.82877349853516\n",
            "========================================\n",
            "\n",
            "Subtask: blimp_wh_vs_that_with_gap_long_distance_filtered_results.jsonl\n",
            "Sentence (Good): Kayla concealed who a lot of guests that were scaring many people complain about.\n",
            "Sentence (Bad): Kayla concealed that a lot of guests that were scaring many people complain about.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -120.69482421875\n",
            "  Response 2: Score = -115.53009033203125\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -120.69482421875\n",
            "  Filtered Response 2: Score = -115.53009033203125\n",
            "========================================\n",
            "Sentence (Good): Martin did find out what every cashier that shouldn't drink wore.\n",
            "Sentence (Bad): Martin did find out that every cashier that shouldn't drink wore.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -100.45903778076172\n",
            "  Response 2: Score = -97.38048553466797\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -100.45903778076172\n",
            "  Filtered Response 2: Score = -97.38048553466797\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iR-vOJOEwV_W"
      },
      "outputs": [],
      "source": [
        "def print_ewok_samples(samples):\n",
        "\n",
        "    for sample in samples:\n",
        "        doc = sample.get(\"doc\", {})\n",
        "        domain = doc.get(\"Domain\", \"N/A\")\n",
        "        concept_a = doc.get(\"ConceptA\", \"N/A\")\n",
        "        concept_b = doc.get(\"ConceptB\", \"N/A\")\n",
        "        context1 = doc.get(\"Context1\", \"N/A\")\n",
        "        context2 = doc.get(\"Context2\", \"N/A\")\n",
        "        target1 = doc.get(\"Target1\", \"N/A\")\n",
        "        target2 = doc.get(\"Target2\", \"N/A\")\n",
        "        acc = sample.get(\"acc\", \"N/A\")\n",
        "        resps = sample.get(\"resps\", [])\n",
        "        filtered_resps = sample.get(\"filtered_resps\", [])\n",
        "\n",
        "        print(\"Domain:\", domain)\n",
        "        print(\"Concept A:\", concept_a)\n",
        "        print(\"Concept B:\", concept_b)\n",
        "        print(\"Context 1:\", context1)\n",
        "        print(\"Context 2:\", context2)\n",
        "        print(\"Target 1:\", target1)\n",
        "        print(\"Target 2:\", target2)\n",
        "        print(\"Accuracy:\", acc)\n",
        "\n",
        "        if resps:\n",
        "            print(\"Predictions (resps):\")\n",
        "            for i, resp in enumerate(resps):\n",
        "                score, correct = resp[0][0], resp[0][1]\n",
        "                print(f\"  Response {i + 1}: Score = {score}\")\n",
        "\n",
        "        if filtered_resps:\n",
        "            print(\"Filtered Predictions (filtered_resps):\")\n",
        "            for i, filtered_resp in enumerate(filtered_resps):\n",
        "                score, correct = filtered_resp\n",
        "                print(f\"  Filtered Response {i + 1}: Score = {score}\")\n",
        "\n",
        "        print(\"=\" * 40)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ewok_path = '/content/drive/MyDrive/new_evaluation_pipeline/results/ewok/babylama-scratch'\n",
        "# Process and print ewok samples\n",
        "print(\"\\nProcessing Ewok Tasks\\n\" + \"=\"*60)\n",
        "for subtask_file in os.listdir(ewok_path):\n",
        "    if subtask_file.endswith('.jsonl'):\n",
        "        file_path = os.path.join(ewok_path, subtask_file)\n",
        "        print(f\"\\nSubtask: {subtask_file}\")\n",
        "        samples = load_jsonl_or_json_array(file_path)\n",
        "        print_ewok_samples(samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxenNzSXlK4K",
        "outputId": "6db424fb-c4fb-4210-9326-ff3691112cb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing Ewok Tasks\n",
            "============================================================\n",
            "\n",
            "Subtask: ewok_agent-properties_filtered_results.jsonl\n",
            "Domain: agent-properties\n",
            "Concept A: believe\n",
            "Concept B: doubt\n",
            "Context 1: Ali is in the bakery. Ali sees the candle inside.\n",
            "Context 2: Ali is in the bakery. Ali sees the candle outside.\n",
            "Target 1: Ali believes that the candle is in the bakery.\n",
            "Target 2: Ali doubts that the candle is in the bakery.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -60.72251510620117\n",
            "  Response 2: Score = -63.611351013183594\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -60.72251510620117\n",
            "  Filtered Response 2: Score = -63.611351013183594\n",
            "========================================\n",
            "Domain: agent-properties\n",
            "Concept A: believe\n",
            "Concept B: doubt\n",
            "Context 1: Ali is in the bakery. Ali sees the candle outside.\n",
            "Context 2: Ali is in the bakery. Ali sees the candle inside.\n",
            "Target 1: Ali doubts that the candle is in the bakery.\n",
            "Target 2: Ali believes that the candle is in the bakery.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -63.09640884399414\n",
            "  Response 2: Score = -60.202964782714844\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -63.09640884399414\n",
            "  Filtered Response 2: Score = -60.202964782714844\n",
            "========================================\n",
            "\n",
            "Subtask: ewok_material-properties_filtered_results.jsonl\n",
            "Domain: material-properties\n",
            "Concept A: bouncy\n",
            "Concept B: not bouncy\n",
            "Context 1: Ali dropped the volleyball, and saw it jumping off the floor.\n",
            "Context 2: Ali dropped the volleyball, and saw it lying on the floor.\n",
            "Target 1: The volleyball is bouncy.\n",
            "Target 2: The volleyball is not bouncy.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -49.1243896484375\n",
            "  Response 2: Score = -53.29707336425781\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -49.1243896484375\n",
            "  Filtered Response 2: Score = -53.29707336425781\n",
            "========================================\n",
            "Domain: material-properties\n",
            "Concept A: bouncy\n",
            "Concept B: not bouncy\n",
            "Context 1: Ali dropped the volleyball, and saw it lying on the floor.\n",
            "Context 2: Ali dropped the volleyball, and saw it jumping off the floor.\n",
            "Target 1: The volleyball is not bouncy.\n",
            "Target 2: The volleyball is bouncy.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -53.13057327270508\n",
            "  Response 2: Score = -49.07527542114258\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -53.13057327270508\n",
            "  Filtered Response 2: Score = -49.07527542114258\n",
            "========================================\n",
            "\n",
            "Subtask: ewok_physical-dynamics_filtered_results.jsonl\n",
            "Domain: physical-dynamics\n",
            "Concept A: accelerate\n",
            "Concept B: slow down\n",
            "Context 1: The speed of the balloon is increasing.\n",
            "Context 2: The speed of the balloon is decreasing.\n",
            "Target 1: The balloon is accelerating.\n",
            "Target 2: The balloon is slowing down.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -41.53487777709961\n",
            "  Response 2: Score = -45.24725341796875\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -41.53487777709961\n",
            "  Filtered Response 2: Score = -45.24725341796875\n",
            "========================================\n",
            "Domain: physical-dynamics\n",
            "Concept A: accelerate\n",
            "Concept B: slow down\n",
            "Context 1: The speed of the balloon is decreasing.\n",
            "Context 2: The speed of the balloon is increasing.\n",
            "Target 1: The balloon is slowing down.\n",
            "Target 2: The balloon is accelerating.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -45.29166030883789\n",
            "  Response 2: Score = -41.935211181640625\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -45.29166030883789\n",
            "  Filtered Response 2: Score = -41.935211181640625\n",
            "========================================\n",
            "\n",
            "Subtask: ewok_physical-interactions_filtered_results.jsonl\n",
            "Domain: physical-interactions\n",
            "Concept A: attract\n",
            "Concept B: repel\n",
            "Context 1: The magnet is moving closer to the knife.\n",
            "Context 2: The magnet is moving away from the knife.\n",
            "Target 1: The knife is attracting the magnet.\n",
            "Target 2: The knife is repelling the magnet.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -54.437232971191406\n",
            "  Response 2: Score = -60.06100845336914\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -54.437232971191406\n",
            "  Filtered Response 2: Score = -60.06100845336914\n",
            "========================================\n",
            "Domain: physical-interactions\n",
            "Concept A: attract\n",
            "Concept B: repel\n",
            "Context 1: The magnet is moving away from the knife.\n",
            "Context 2: The magnet is moving closer to the knife.\n",
            "Target 1: The knife is repelling the magnet.\n",
            "Target 2: The knife is attracting the magnet.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -60.875450134277344\n",
            "  Response 2: Score = -55.061851501464844\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -60.875450134277344\n",
            "  Filtered Response 2: Score = -55.061851501464844\n",
            "========================================\n",
            "\n",
            "Subtask: ewok_physical-relations_filtered_results.jsonl\n",
            "Domain: physical-relations\n",
            "Concept A: attached\n",
            "Concept B: connected\n",
            "Context 1: The airplane is next to the rock.\n",
            "Context 2: The airplane is some distance away from the rock.\n",
            "Target 1: The airplane is attached to the rock.\n",
            "Target 2: The airplane is connected to the rock.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -51.11558532714844\n",
            "  Response 2: Score = -49.80268096923828\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -51.11558532714844\n",
            "  Filtered Response 2: Score = -49.80268096923828\n",
            "========================================\n",
            "Domain: physical-relations\n",
            "Concept A: attached\n",
            "Concept B: connected\n",
            "Context 1: The airplane is some distance away from the rock.\n",
            "Context 2: The airplane is next to the rock.\n",
            "Target 1: The airplane is connected to the rock.\n",
            "Target 2: The airplane is attached to the rock.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -50.29541778564453\n",
            "  Response 2: Score = -51.60762023925781\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -50.29541778564453\n",
            "  Filtered Response 2: Score = -51.60762023925781\n",
            "========================================\n",
            "\n",
            "Subtask: ewok_quantitative-properties_filtered_results.jsonl\n",
            "Domain: quantitative-properties\n",
            "Concept A: a lot of\n",
            "Concept B: a little\n",
            "Context 1: Ali has a large amount of ketchup.\n",
            "Context 2: Ali has a small amount of ketchup.\n",
            "Target 1: There is a lot of ketchup.\n",
            "Target 2: There is a little ketchup.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -43.96683120727539\n",
            "  Response 2: Score = -43.71029281616211\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -43.96683120727539\n",
            "  Filtered Response 2: Score = -43.71029281616211\n",
            "========================================\n",
            "Domain: quantitative-properties\n",
            "Concept A: a lot of\n",
            "Concept B: a little\n",
            "Context 1: Ali has a small amount of ketchup.\n",
            "Context 2: Ali has a large amount of ketchup.\n",
            "Target 1: There is a little ketchup.\n",
            "Target 2: There is a lot of ketchup.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -43.111629486083984\n",
            "  Response 2: Score = -43.77790832519531\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -43.111629486083984\n",
            "  Filtered Response 2: Score = -43.77790832519531\n",
            "========================================\n",
            "\n",
            "Subtask: ewok_social-interactions_filtered_results.jsonl\n",
            "Domain: social-interactions\n",
            "Concept A: cooperate\n",
            "Concept B: compete\n",
            "Context 1: Ali and Wei are helping each other.\n",
            "Context 2: Ali and Wei are hindering each other.\n",
            "Target 1: Ali is cooperating with Wei.\n",
            "Target 2: Ali is competing with Wei.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -60.73151397705078\n",
            "  Response 2: Score = -60.99415969848633\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -60.73151397705078\n",
            "  Filtered Response 2: Score = -60.99415969848633\n",
            "========================================\n",
            "Domain: social-interactions\n",
            "Concept A: cooperate\n",
            "Concept B: compete\n",
            "Context 1: Ali and Wei are hindering each other.\n",
            "Context 2: Ali and Wei are helping each other.\n",
            "Target 1: Ali is competing with Wei.\n",
            "Target 2: Ali is cooperating with Wei.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -62.1353759765625\n",
            "  Response 2: Score = -61.85875701904297\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -62.1353759765625\n",
            "  Filtered Response 2: Score = -61.85875701904297\n",
            "========================================\n",
            "\n",
            "Subtask: ewok_social-properties_filtered_results.jsonl\n",
            "Domain: social-properties\n",
            "Concept A: boastful\n",
            "Concept B: humble\n",
            "Context 1: Ali talks a lot about past accomplishments.\n",
            "Context 2: Ali talks little about past accomplishments.\n",
            "Target 1: Ali is boastful.\n",
            "Target 2: Ali is humble.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -43.98914337158203\n",
            "  Response 2: Score = -37.245445251464844\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -43.98914337158203\n",
            "  Filtered Response 2: Score = -37.245445251464844\n",
            "========================================\n",
            "Domain: social-properties\n",
            "Concept A: boastful\n",
            "Concept B: humble\n",
            "Context 1: Ali talks little about past accomplishments.\n",
            "Context 2: Ali talks a lot about past accomplishments.\n",
            "Target 1: Ali is humble.\n",
            "Target 2: Ali is boastful.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -36.934814453125\n",
            "  Response 2: Score = -43.66315460205078\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -36.934814453125\n",
            "  Filtered Response 2: Score = -43.66315460205078\n",
            "========================================\n",
            "\n",
            "Subtask: ewok_social-relations_filtered_results.jsonl\n",
            "Domain: social-relations\n",
            "Concept A: boss\n",
            "Concept B: subordinate\n",
            "Context 1: Ali gives orders to Wei.\n",
            "Context 2: Ali gets orders from Wei.\n",
            "Target 1: Ali is Wei's boss.\n",
            "Target 2: Ali is Wei's subordinate.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -59.63770294189453\n",
            "  Response 2: Score = -65.91144561767578\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -59.63770294189453\n",
            "  Filtered Response 2: Score = -65.91144561767578\n",
            "========================================\n",
            "Domain: social-relations\n",
            "Concept A: boss\n",
            "Concept B: subordinate\n",
            "Context 1: Ali gets orders from Wei.\n",
            "Context 2: Ali gives orders to Wei.\n",
            "Target 1: Ali is Wei's subordinate.\n",
            "Target 2: Ali is Wei's boss.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -65.13140869140625\n",
            "  Response 2: Score = -58.081787109375\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -65.13140869140625\n",
            "  Filtered Response 2: Score = -58.081787109375\n",
            "========================================\n",
            "\n",
            "Subtask: ewok_spatial-relations_filtered_results.jsonl\n",
            "Domain: spatial-relations\n",
            "Concept A: above\n",
            "Concept B: below\n",
            "Context 1: The baseball is below the candle.\n",
            "Context 2: The baseball is above the candle.\n",
            "Target 1: The candle is above the baseball.\n",
            "Target 2: The candle is below the baseball.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -55.87158966064453\n",
            "  Response 2: Score = -57.705989837646484\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -55.87158966064453\n",
            "  Filtered Response 2: Score = -57.705989837646484\n",
            "========================================\n",
            "Domain: spatial-relations\n",
            "Concept A: above\n",
            "Concept B: below\n",
            "Context 1: The baseball is above the candle.\n",
            "Context 2: The baseball is below the candle.\n",
            "Target 1: The candle is below the baseball.\n",
            "Target 2: The candle is above the baseball.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -58.39472579956055\n",
            "  Response 2: Score = -55.32872772216797\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -58.39472579956055\n",
            "  Filtered Response 2: Score = -55.32872772216797\n",
            "========================================\n",
            "\n",
            "Subtask: ewok_material-dynamics_filtered_results.jsonl\n",
            "Domain: material-dynamics\n",
            "Concept A: break\n",
            "Concept B: drip\n",
            "Context 1: Ali sees something that is rigid.\n",
            "Context 2: Ali sees something that is liquid.\n",
            "Target 1: It breaks.\n",
            "Target 2: It drips.\n",
            "Accuracy: 1.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -32.43087387084961\n",
            "  Response 2: Score = -36.39881134033203\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -32.43087387084961\n",
            "  Filtered Response 2: Score = -36.39881134033203\n",
            "========================================\n",
            "Domain: material-dynamics\n",
            "Concept A: break\n",
            "Concept B: drip\n",
            "Context 1: Ali sees something that is liquid.\n",
            "Context 2: Ali sees something that is rigid.\n",
            "Target 1: It drips.\n",
            "Target 2: It breaks.\n",
            "Accuracy: 0.0\n",
            "Predictions (resps):\n",
            "  Response 1: Score = -36.220726013183594\n",
            "  Response 2: Score = -32.49125671386719\n",
            "Filtered Predictions (filtered_resps):\n",
            "  Filtered Response 1: Score = -36.220726013183594\n",
            "  Filtered Response 2: Score = -32.49125671386719\n",
            "========================================\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "800f7e81fd5a4f0da26be8bd1ca04e76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5280d294d81047469d55a6db353ee2b6",
              "IPY_MODEL_862436529e4341499c5b5a173a9d26bb",
              "IPY_MODEL_16fd2be83c6741d99bf8fb55996f366d",
              "IPY_MODEL_89b25bf9c5d54e7fa1870b015830802f"
            ],
            "layout": "IPY_MODEL_6c9443fe9b9645d782860495bb788f33"
          }
        },
        "a7d073b4e0814af19d97bf5c8910ff7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a938e227e7ad426e9549c2bb135bf208",
            "placeholder": "​",
            "style": "IPY_MODEL_28e90b8800784b1a945807016c5f6e76",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "92f3c9bbd7104e43bd1f9e94184f0c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_2d36c46da9434f4abca468002f3cf107",
            "placeholder": "​",
            "style": "IPY_MODEL_9d7f19c4ed24427f940150e7df564baa",
            "value": ""
          }
        },
        "d143f2d43a09432485242b9acf7ff298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_444f1ee5626742c6b62092e97f43dad0",
            "style": "IPY_MODEL_d1fd7faa8c224ca29459277f4d7e927a",
            "value": true
          }
        },
        "736f1ac1122c45359837461f453cc450": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_b4408ae9e5324e4aa74abeaf3a4c50b3",
            "style": "IPY_MODEL_7e787def179a4f3aab09e49b1f800ed6",
            "tooltip": ""
          }
        },
        "4cc18c895a5e4f8990055aa333c2e703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f20757e38c57446db4022ed2cba5afd5",
            "placeholder": "​",
            "style": "IPY_MODEL_2612db66d16d49e095e02502205b224c",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "6c9443fe9b9645d782860495bb788f33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "a938e227e7ad426e9549c2bb135bf208": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28e90b8800784b1a945807016c5f6e76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d36c46da9434f4abca468002f3cf107": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d7f19c4ed24427f940150e7df564baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "444f1ee5626742c6b62092e97f43dad0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1fd7faa8c224ca29459277f4d7e927a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4408ae9e5324e4aa74abeaf3a4c50b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e787def179a4f3aab09e49b1f800ed6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "f20757e38c57446db4022ed2cba5afd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2612db66d16d49e095e02502205b224c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "214610c284534e75abd424dec12bf4e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59757a1390934b92b2917e61dd3382a8",
            "placeholder": "​",
            "style": "IPY_MODEL_ed8c814f6b344b818817a4025d3567f1",
            "value": "Connecting..."
          }
        },
        "59757a1390934b92b2917e61dd3382a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed8c814f6b344b818817a4025d3567f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5280d294d81047469d55a6db353ee2b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_573d206df27940d5aced2c17d4f7bed5",
            "placeholder": "​",
            "style": "IPY_MODEL_30db22f2f9d84a9cacc2671075493a7f",
            "value": "Token is valid (permission: write)."
          }
        },
        "862436529e4341499c5b5a173a9d26bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9da301dd2f984aca9cf67ee3723fef8d",
            "placeholder": "​",
            "style": "IPY_MODEL_8a143c24b7d04cdcbb62ad45dc724ad7",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "16fd2be83c6741d99bf8fb55996f366d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ce76d26d6714498b7a3a4294e9c0b6b",
            "placeholder": "​",
            "style": "IPY_MODEL_0e0f6cd89c4e4eeaaf5c771ee2bb5ac7",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "89b25bf9c5d54e7fa1870b015830802f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_337ba98e152b45669a99999c519b8591",
            "placeholder": "​",
            "style": "IPY_MODEL_f20bb026676d4eb181584f44ce6b5071",
            "value": "Login successful"
          }
        },
        "573d206df27940d5aced2c17d4f7bed5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30db22f2f9d84a9cacc2671075493a7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9da301dd2f984aca9cf67ee3723fef8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a143c24b7d04cdcbb62ad45dc724ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ce76d26d6714498b7a3a4294e9c0b6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e0f6cd89c4e4eeaaf5c771ee2bb5ac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "337ba98e152b45669a99999c519b8591": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f20bb026676d4eb181584f44ce6b5071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a8310f95a3845089e3b963371e9c5fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ad9bdb5e67b44f4bdc109087d55b68a",
              "IPY_MODEL_51fe802be83a43fcaaec3ae04dc991e8",
              "IPY_MODEL_c935b720382d4a4cbe682bf92bc820b6"
            ],
            "layout": "IPY_MODEL_0ffc16e45f814d8dbaf562ae09aaa158"
          }
        },
        "3ad9bdb5e67b44f4bdc109087d55b68a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0947e7fc3575485085f427f086d6f737",
            "placeholder": "​",
            "style": "IPY_MODEL_1cac48fce61144db8caa79baf043dcea",
            "value": "events.out.tfevents.1730821957.c6e2ac2101d4.6774.0: 100%"
          }
        },
        "51fe802be83a43fcaaec3ae04dc991e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5795c850cf2b4e65b9293ce2c84bf94d",
            "max": 597614,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9cea12baec374ea48f88f2d6a4e371a7",
            "value": 597614
          }
        },
        "c935b720382d4a4cbe682bf92bc820b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2caace1316db4adcbf1c3fec17a0ae65",
            "placeholder": "​",
            "style": "IPY_MODEL_1a3110f4d2664a3ba93e0bf04c97821f",
            "value": " 598k/598k [00:00&lt;00:00, 2.48MB/s]"
          }
        },
        "0ffc16e45f814d8dbaf562ae09aaa158": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0947e7fc3575485085f427f086d6f737": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cac48fce61144db8caa79baf043dcea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5795c850cf2b4e65b9293ce2c84bf94d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cea12baec374ea48f88f2d6a4e371a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2caace1316db4adcbf1c3fec17a0ae65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a3110f4d2664a3ba93e0bf04c97821f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}